{"./":{"url":"./","title":"前言","keywords":"","body":"linux-notes Linux 学习笔记 Summary 前言 Linux 文件系统 Linux 介绍 Linux 文件权限 Shell 脚本 Shell简介 运维工具 Ansible的使用 Supervisor的使用 Confd的使用 NFS的使用 Git Git 介绍 Git 常用命令 Git 命令分类 Nginx Nginx安装与配置 Nginx作为反向代理 Nginx http服务器 Keepalived Keepalived简介 Keepalived的安装与配置 Keepalived的相关操作 Keepalived的配置详解 TCP/IP TCP/IP基础 IP协议 TCP与UDP协议 Http基础 Http报文 Http状态码 Redis Redis介绍 Redis集群模式部署 Redis主从及哨兵模式部署 Redis配置详解(中文版) Redis配置详解(英文版) Memcached Memcached的使用 Mysql Mysql常用命令 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2019-03-25 17:41:02 "},"file/linux-introduction.html":{"url":"file/linux-introduction.html","title":"Linux 介绍","keywords":"","body":"1. Linux简介 严格来讲，Linux（内核）是计算机软件与硬件通信之间的平台，不是真正意义上的操作系统，而一些厂家将Linux内核和GNU软件（系统软件和工具）整合起来，并提供一些安装界面和系统设定与管理工具，就构成一些发行套件（系统），例如：Ubuntu、CentOS、Red Hat、Debian等。 Linux内核版本 Linux内核版本一般格式为：x.y.zz-www，例如：Kernel2.6.15 x.y：Linux内核主版本号，y若为奇数则表示是测试版 zz：次版本好 www：代表发行号 2. Linux体系结构 Linux体系结构如下： 几个重要概念： 内核：内核是操作系统的核心。内核直接与硬件交互，并处理大部分较低层的任务，如内存管理、进程调度、文件管理等。 Shell：Shell是一个处理用户请求的工具，它负责解释用户输入的命令，调用用户希望使用的程序。 命令和工具：日常工作中，你会用到很多系统命令和工具，如cp、mv、cat和grep等。 文件和目录：Linux系统中所有的数据都被存储到文件中，这些文件被分配到各个目录，构成文件系统。 3. 系统操作 3.1. 登录Linux 登录需要输入用户名和密码，用户名和密码是区分大小写。 login : amrood amrood's password: Last login: Sun Jun 14 09:32:32 2009 from 62.61.164.73 $ 3.2. 修改密码 输入password命令后，输入原密码和新密码，确认密码即可。 $ passwd Changing password for amrood (current) Linux password:****** New Linux password:******* Retype new Linux password:******* passwd: all authentication tokens updated successfully 3.3. 查看当前用户 1、查看自己的用户名 $ whoami amrood 2、查看当前在线用户 可以使用users 、who、w命令。 $ users amrood bablu qadir $ who amrood ttyp0 Oct 8 14:10 (limbo) bablu ttyp2 Oct 4 09:08 (calliope) qadir ttyp4 Oct 8 12:09 (dent) $ w 13:58:53 up 158 days, 22:07, 3 users, load average: 0.72, 0.99, 1.11 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/1 172.16.20.65 13:40 0.00s 0.22s 0.02s w root pts/2 172.16.20.65 Fri15 43:17m 1.04s 1.04s -bash 3.4. 关闭系统 关闭系统可以使用以下命令 命令 说明 halt 直接关闭系统 init 0 使用预先定义的脚本关闭系统，关闭前可以清理和更新有关信息 init 6 重新启动系统 poweroff 通过断电来关闭系统 reboot 重新启动系统 shutdown 安全关闭系统 一般只有root有关闭系统的权限，普通用户被赋予相应权限也可以关闭系统。 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"file/linux-file-permission.html":{"url":"file/linux-file-permission.html","title":"Linux 文件权限","keywords":"","body":"1. Linux文件管理 Linux中的所有数据都被保存在文件中，所有的文件被分配到不同的目录。目录是一种类似于树的结构，称为文件系统。 1.1. 文件类型 1、普通文件 普通文件是以字节为单位的数据流，包括文本文件、源码文件、可执行文件等。文本和二进制对Linux来说并无区别，对普通文件的解释由处理该文件的应用程序进行。 2、目录 目录可以包含普通文件和特殊文件，目录相当于Windows和Mac OS中的文件夹。 3、设备文件 Linux 与外部设备（例如光驱，打印机，终端，modern等）是通过一种被称为设备文件的文件来进行通信。Linux 输入输出到外部设备的方式和输入输出到一个文件的方式是相同的。Linux 和一个外部设备通讯之前，这个设备必须首先要有一个设备文件存在。 设备文件和普通文件不一样，设备文件中并不包含任何数据。 设备文件有两种类型：字符设备文件和块设备文件。 字符设备文件以字母\"c\"开头。字符设备文件向设备传送数据时，一次传送一个字符。典型的通过字符传送数据的设备有终端、打印机、绘图仪、modern等。字符设备文件有时也被称为\"raw\"设备文件。 块设备文件以字母\"b\"开头。块设备文件向设备传送数据时，先从内存中的buffer中读或写数据，而不是直接传送数据到物理磁盘。磁盘和CD-ROMS既可以使用字符设备文件也可以使用块设备文件。 1.2. 文件属性 可以使用ls -al来查看当前目录下的所有文件列表。 [root@www ~]# ls -al total 156 drwxr-x--- 4 root root 4096 Sep 8 14:06 . # 当前目录 drwxr-xr-x 23 root root 4096 Sep 8 14:21 .. # 父目录 -rw------- 1 root root 1474 Sep 4 18:27 anaconda-ks.cfg -rw------- 1 root root 199 Sep 8 17:14 .bash_history -rw-r--r-- 1 root root 24 Jan 6 2007 .bash_logout -rw-r--r-- 1 root root 191 Jan 6 2007 .bash_profile -rw-r--r-- 1 root root 176 Jan 6 2007 .bashrc -rw-r--r-- 1 root root 100 Jan 6 2007 .cshrc drwx------ 3 root root 4096 Sep 5 10:37 .gconf drwx------ 2 root root 4096 Sep 5 14:09 .gconfd -rw-r--r-- 1 root root 42304 Sep 4 18:26 install.log -rw-r--r-- 1 root root 5661 Sep 4 18:25 install.log.syslog [ 1 ] [ 2 ][ 3 ][ 4 ] [ 5 ] [ 6 ] [ 7 ] [ 权限 ][文件数][所有者] [用户组][文件容量][ 修改日期 ] [ 文件名 ] 每列含义说明： 第一列：文件类型。 第二列：表示文件个数。如果是文件，那么就是1；如果是目录，那么就是该目录中文件的数目。 第三列：文件的所有者，即文件的创建者。 第四列：文件所有者所在的用户组。在Linux中，每个用户都隶属于一个用户组。 第五列：文件大小（以字节计）。 第六列：文件被创建或上次被修改的时间。 第七列：文件名或目录名。 文件类型字符 前缀 描述 - 普通文件。如文本文件、二进制可执行文件、源代码等。 b 块设备文件。硬盘可以使用块设备文件。 c 字符设备文件。硬盘也可以使用字符设备文件。 d 目录文件。目录可以包含文件和其他目录。 l 符号链接（软链接）。可以链接任何普通文件，类似于 Windows 中的快捷方式。 p 具名管道。管道是进程间的一种通信机制。 s 用于进程间通信的套接字。 隐藏文件 隐藏文件的第一个字符为英文句号或点号(.)，Linux程序（包括Shell）通常使用隐藏文件来保存配置信息。可以通过ls -a来查看所有文件，即包含隐藏文件。 常见的隐藏文件： .profile：Bourne shell (sh) 初始化脚本 .kshrc：Korn shell (ksh) 初始化脚本 .cshrc：C shell (csh) 初始化脚本 .rhosts：Remote shell (rsh) 配置文件 1.3. 文件的操作 操作 命令 创建 touch filename 编辑 vi filename 查看 cat filename 复制 cp filename copyfile 重命名 mv filename newfile 删除 rm filename filename2 统计词数 wc filename 1.4. 标准的Linux流 一般情况下，每个Linux程序运行时都会创建三个文件流（三个文件）： 标准输入流(stdin)：stdin的文件描述符为0，Linux程序默认从stdin读取数据。 标准输出流(stdout)：stdout 的文件描述符为1，Linux程序默认向stdout输出数据。 标准错误流(stderr)：stderr的文件描述符为2，Linux程序会向stderr流中写入错误信息。 2. 文件权限和访问模式 2.1. 查看文件权限 Linux每个文件都有三类权限： 所有者权限(user)：文件所有者能够进行的操作 组权限(group)：文件所属用户组能够进行的操作 外部权限（other）：其他用户可以进行的操作。 通过ls -l的命令可以查看文件权限信息。 $ls -l /home/amrood -rwxr-xr-- 1 amrood users 1024 Nov 2 00:10 myfile drwxr-xr--- 1 amrood users 1024 Nov 2 00:10 mydir 第一列-rwxr-xr--包含了文件或目录的权限。 除了第一个字符-或d分别用来表示文件或目录外，其他的九个字符可以分为三组，分别对应所有者权限，用户组权限，其他用户权限，即-|user|group|other。 每组的权限又可分为三类： 读取（r），对应权限数字4 写入（w），对应权限数字2 执行（x），对应权限数字1 使用数字表示权限： 数字 说明 权限 0 没有任何权限 --- 1 执行权限 --x 2 写入权限 -w- 3 执行权限和写入权限：1 (执行) + 2 (写入) = 3 -wx 4 读取权限 r-- 5 读取和执行权限：4 (读取) + 1 (执行) = 5 r-x 6 读取和写入权限：4 (读取) + 2 (写入) = 6 rw- 7 所有权限: 4 (读取) + 2 (写入) + 1 (执行) = 7 rwx 2.2. 访问模式 2.2.1. 文件访问模式 基本的权限有读取(r)、写入(w)和执行(x)： 读取：用户能够读取文件信息，查看文件内容。 写入：用户可以编辑文件，可以向文件写入内容，也可以删除文件内容。 执行：用户可以将文件作为程序来运行。 2.2.2. 目录访问模式 目录的访问模式和文件类似，但是稍有不同： 读取：用户可以查看目录中的文件 写入：用户可以在当前目录中删除文件或创建文件 执行：执行权限赋予用户遍历目录的权利，例如执行 cd 和 ls 命令。 2.3. 权限的操作 2.3.1. chmod chmod (change mode) 命令来改变文件或目录的访问权限，权限可以使用符号或数字来表示。 1、通过符号方式 可以使用符号来改变文件或目录的权限，你可以增加(+)和删除(-)权限，也可以指定特定权限(=)。 指定权限范围 u (user)：所有者权限 g(group)：所属用户组权限 o(other)：其他用户权限 符号 说明 + 为文件或目录增加权限 - 删除文件或目录的权限 = 设置指定的权限 示例 # 查看权限 $ls -l testfile -rwxrwxr-- 1 amrood users 1024 Nov 2 00:10 testfile # 增加权限 $chmod o+wx testfile $ls -l testfile -rwxrwxrwx 1 amrood users 1024 Nov 2 00:10 testfile # 删除权限 $chmod u-x testfile $ls -l testfile -rw-rwxrwx 1 amrood users 1024 Nov 2 00:10 testfile # 指定权限 $chmod g=rx testfile $ls -l testfile -rw-r-xrwx 1 amrood users 1024 Nov 2 00:10 testfile # 同时使用多个符号 $chmod o+wx,u-x,g=rx testfile $ls -l testfile -rw-r-xrwx 1 amrood users 1024 Nov 2 00:10 testfile 2、通过数字权限方式 数字权限依照2.1的权限说明。 示例 $ls -l testfile -rwxrwxr-- 1 amrood users 1024 Nov 2 00:10 testfile $ chmod 755 testfile $ls -l testfile -rwxr-xr-x 1 amrood users 1024 Nov 2 00:10 testfile 2.3.2. chown chown 命令是\"change owner\"的缩写，用来改变文件的所有者。 # user可以是用户名或用户ID $ chown user filelist # 例如： $ chown amrood testfile 超级用户 root 可以不受限制的更改文件的所有者和用户组，但是普通用户只能更改所有者是自己的文件或目录。 2.3.3. chgrp chgrp 命令是\"change group\"的缩写，用来改变文件所在的群组。 # group可以是用户组名或用户组ID $ chgrp group filelist # 例如： $ chgrp special testfile 2.4. SUID和SGID位 在Linux中，一些程序需要特殊权限才能完成用户指定的操作。例如密码文件/etc/shadow。 Linux 通过给程序设置SUID(Set User ID)和SGID(Set Group ID)位来赋予普通用户特殊权限。当我们运行一个带有SUID位的程序时，就会继承该程序所有者的权限；如果程序不带SUID位，则会根据程序使用者的权限来运行。 例如： $ ls -l /usr/bin/passwd -r-sr-xr-x 1 root bin 19031 Feb 7 13:47 /usr/bin/passwd* 上面第一列第四个字符不是'x'或'-'，而是's'，说明 /usr/bin/passwd 文件设置了SUID位，这时普通用户会以root用户的权限来执行passwd程序。 小写字母's'说明文件所有者有执行权限(x)，大写字母'S'说明程序所有者没有执行权限(x)。 为一个目录设置SUID和SGID位可以使用下面的命令： $ chmod ug+s dirname $ ls -l drwsr-sr-x 2 root root 4096 Jun 19 06:45 dirname Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"shell/shell-introduction.html":{"url":"shell/shell-introduction.html","title":"Shell简介","keywords":"","body":"1. Shell简介 shell是用户和Linux内核之间的一层代理，解释用户输入的命令，传递给内核。 shell是一种脚本语言（解释性语言）。 1.1. 编译型语言 任何代码运行最终都需要被翻译成二进制的形式在计算机中执行。C/C++、Go语言等语言，需要在程序运行之前将代码编译成二进制形式，生成可执行文件，用户执行的是可执行文件，看不到源码。 这个过程叫编译，这类语言叫编译型语言，完成编译过程的软件叫编译器。 1.2. 脚本型语言 有的语言（例如： Shell、JavaScript、Python、PHP等）需要一边执行一边翻译，不会产生任何可执行文件，用户需要拿到源码才能运行程序。程序运行后会即时翻译，翻译一部分执行一部分，并不用等所有代码翻译完。 这个过程叫解释，这类语言叫解释型语言或脚本语言，完成解释过程的软件叫解释器。 2. 常见的Shell类型 shell类型 说明 sh sh 是 UNIX 上的标准 shell，很多 UNIX 版本都配有 sh。 bash bash shell 是 Linux 的默认 shell，bash 兼容 sh，但并不完全一致。 csh 语法有点类似C语言。 ... 2.1. 查看shell $ cat /etc/shells /bin/sh /bin/bash /sbin/nologin /usr/bin/sh /usr/bin/bash /usr/sbin/nologin /bin/tcsh /bin/csh 查看默认shell $ echo $SHELL /bin/bash sh 一般被 bash 代替，/bin/sh往往是指向/bin/bash的符号链接。 $ ls -l /bin/sh lrwxrwxrwx. 1 root root 4 Mar 8 2018 /bin/sh -> bash 3. 执行shell #!/bin/bash echo \"Hello World !\" #!/bin/bash表示使用的解释器是什么。 3.1. 作为可执行程序运行 chmod +x ./test.sh #使脚本具有执行权限 ./test.sh #执行脚本 3.2. 作为解释器参数运行 # 使用 sh 解释器 sh test.sh # 使用 bash 解释器 bash test.sh Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"tools/ansible-usage.html":{"url":"tools/ansible-usage.html","title":"Ansible的使用","keywords":"","body":"1. 安装 以centos为例。 yum install -y ansible 2. 配置 默认配置目录在/etc/ansible/，主要有以下两个配置： ansible.cfg：ansible的配置文件 hosts：配置ansible所连接的机器IP信息 2.1. ansible.cfg 2.2. hosts # This is the default ansible 'hosts' file. # # It should live in /etc/ansible/hosts # # - Comments begin with the '#' character # - Blank lines are ignored # - Groups of hosts are delimited by [header] elements # - You can enter hostnames or ip addresses # - A hostname/ip can be a member of multiple groups # Ex 1: Ungrouped hosts, specify before any group headers. # green.example.com # blue.example.com # 192.168.100.1 # 192.168.100.10 # Ex 2: A collection of hosts belonging to the 'webservers' group # [webservers] # alpha.example.org # beta.example.org # 192.168.1.100 # 192.168.1.110 # If you have multiple hosts following a pattern you can specify # them like this: # www[001:006].example.com # Ex 3: A collection of database servers in the 'dbservers' group # [dbservers] # # db01.intranet.mydomain.net # db02.intranet.mydomain.net # 10.25.1.56 # 10.25.1.57 # Here's another example of host ranges, this time there are no # leading 0s: # db-[99:101]-node.example.com [k8s] 192.168.201.52 192.168.201.53 192.168.201.54 192.168.201.55 192.168.201.56 192.168.201.57 3. ansible的命令 命令格式为：ansible [options] host-pattern：即hosts文件中配置的集群名称 options：命令操作符 例如：ansible k8s -a 'uname -r' [root@k8s-master ansible]# ansible k8s -a 'uname -r' 172.16.201.56 | SUCCESS | rc=0 >> 4.16.11-1.el7.elrepo.x86_64 172.16.201.55 | SUCCESS | rc=0 >> 4.16.11-1.el7.elrepo.x86_64 172.16.201.54 | SUCCESS | rc=0 >> 4.16.11-1.el7.elrepo.x86_64 172.16.201.53 | SUCCESS | rc=0 >> 4.16.11-1.el7.elrepo.x86_64 172.16.201.52 | SUCCESS | rc=0 >> 4.16.11-1.el7.elrepo.x86_64 172.16.201.57 | SUCCESS | rc=0 >> 4.16.11-1.el7.elrepo.x86_64 具体的命令信息： Usage: ansible [options] Define and run a single task 'playbook' against a set of hosts Options: -a MODULE_ARGS, --args=MODULE_ARGS module arguments --ask-vault-pass ask for vault password -B SECONDS, --background=SECONDS run asynchronously, failing after X seconds (default=N/A) -C, --check don't make any changes; instead, try to predict some of the changes that may occur -D, --diff when changing (small) files and templates, show the differences in those files; works great with --check -e EXTRA_VARS, --extra-vars=EXTRA_VARS set additional variables as key=value or YAML/JSON, if filename prepend with @ -f FORKS, --forks=FORKS specify number of parallel processes to use (default=5) -h, --help show this help message and exit -i INVENTORY, --inventory=INVENTORY, --inventory-file=INVENTORY specify inventory host path or comma separated host list. --inventory-file is deprecated -l SUBSET, --limit=SUBSET further limit selected hosts to an additional pattern --list-hosts outputs a list of matching hosts; does not execute anything else -m MODULE_NAME, --module-name=MODULE_NAME module name to execute (default=command) -M MODULE_PATH, --module-path=MODULE_PATH prepend colon-separated path(s) to module library (default=[u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']) -o, --one-line condense output --playbook-dir=BASEDIR Since this tool does not use playbooks, use this as a subsitute playbook directory.This sets the relative path for many features including roles/ group_vars/ etc. -P POLL_INTERVAL, --poll=POLL_INTERVAL set the poll interval if using -B (default=15) --syntax-check perform a syntax check on the playbook, but do not execute it -t TREE, --tree=TREE log output to this directory --vault-id=VAULT_IDS the vault identity to use --vault-password-file=VAULT_PASSWORD_FILES vault password file -v, --verbose verbose mode (-vvv for more, -vvvv to enable connection debugging) --version show program's version number and exit Connection Options: control as whom and how to connect to hosts -k, --ask-pass ask for connection password --private-key=PRIVATE_KEY_FILE, --key-file=PRIVATE_KEY_FILE use this file to authenticate the connection -u REMOTE_USER, --user=REMOTE_USER connect as this user (default=None) -c CONNECTION, --connection=CONNECTION connection type to use (default=smart) -T TIMEOUT, --timeout=TIMEOUT override the connection timeout in seconds (default=10) --ssh-common-args=SSH_COMMON_ARGS specify common arguments to pass to sftp/scp/ssh (e.g. ProxyCommand) --sftp-extra-args=SFTP_EXTRA_ARGS specify extra arguments to pass to sftp only (e.g. -f, -l) --scp-extra-args=SCP_EXTRA_ARGS specify extra arguments to pass to scp only (e.g. -l) --ssh-extra-args=SSH_EXTRA_ARGS specify extra arguments to pass to ssh only (e.g. -R) Privilege Escalation Options: control how and which user you become as on target hosts -s, --sudo run operations with sudo (nopasswd) (deprecated, use become) -U SUDO_USER, --sudo-user=SUDO_USER desired sudo user (default=root) (deprecated, use become) -S, --su run operations with su (deprecated, use become) -R SU_USER, --su-user=SU_USER run operations with su as this user (default=None) (deprecated, use become) -b, --become run operations with become (does not imply password prompting) --become-method=BECOME_METHOD privilege escalation method to use (default=sudo), valid choices: [ sudo | su | pbrun | pfexec | doas | dzdo | ksu | runas | pmrun | enable ] --become-user=BECOME_USER run operations as this user (default=root) --ask-sudo-pass ask for sudo password (deprecated, use become) --ask-su-pass ask for su password (deprecated, use become) -K, --ask-become-pass ask for privilege escalation password Some modules do not make sense in Ad-Hoc (include, meta, etc) 4. ansible-playbook Usage: ansible-playbook [options] playbook.yml [playbook2 ...] Runs Ansible playbooks, executing the defined tasks on the targeted hosts. Options: --ask-vault-pass ask for vault password -C, --check don't make any changes; instead, try to predict some of the changes that may occur -D, --diff when changing (small) files and templates, show the differences in those files; works great with --check -e EXTRA_VARS, --extra-vars=EXTRA_VARS set additional variables as key=value or YAML/JSON, if filename prepend with @ --flush-cache clear the fact cache for every host in inventory --force-handlers run handlers even if a task fails -f FORKS, --forks=FORKS specify number of parallel processes to use (default=5) -h, --help show this help message and exit -i INVENTORY, --inventory=INVENTORY, --inventory-file=INVENTORY specify inventory host path or comma separated host list. --inventory-file is deprecated -l SUBSET, --limit=SUBSET further limit selected hosts to an additional pattern --list-hosts outputs a list of matching hosts; does not execute anything else --list-tags list all available tags --list-tasks list all tasks that would be executed -M MODULE_PATH, --module-path=MODULE_PATH prepend colon-separated path(s) to module library (default=[u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']) --skip-tags=SKIP_TAGS only run plays and tasks whose tags do not match these values --start-at-task=START_AT_TASK start the playbook at the task matching this name --step one-step-at-a-time: confirm each task before running --syntax-check perform a syntax check on the playbook, but do not execute it -t TAGS, --tags=TAGS only run plays and tasks tagged with these values --vault-id=VAULT_IDS the vault identity to use --vault-password-file=VAULT_PASSWORD_FILES vault password file -v, --verbose verbose mode (-vvv for more, -vvvv to enable connection debugging) --version show program's version number and exit Connection Options: control as whom and how to connect to hosts -k, --ask-pass ask for connection password --private-key=PRIVATE_KEY_FILE, --key-file=PRIVATE_KEY_FILE use this file to authenticate the connection -u REMOTE_USER, --user=REMOTE_USER connect as this user (default=None) -c CONNECTION, --connection=CONNECTION connection type to use (default=smart) -T TIMEOUT, --timeout=TIMEOUT override the connection timeout in seconds (default=10) --ssh-common-args=SSH_COMMON_ARGS specify common arguments to pass to sftp/scp/ssh (e.g. ProxyCommand) --sftp-extra-args=SFTP_EXTRA_ARGS specify extra arguments to pass to sftp only (e.g. -f, -l) --scp-extra-args=SCP_EXTRA_ARGS specify extra arguments to pass to scp only (e.g. -l) --ssh-extra-args=SSH_EXTRA_ARGS specify extra arguments to pass to ssh only (e.g. -R) Privilege Escalation Options: control how and which user you become as on target hosts -s, --sudo run operations with sudo (nopasswd) (deprecated, use become) -U SUDO_USER, --sudo-user=SUDO_USER desired sudo user (default=root) (deprecated, use become) -S, --su run operations with su (deprecated, use become) -R SU_USER, --su-user=SU_USER run operations with su as this user (default=None) (deprecated, use become) -b, --become run operations with become (does not imply password prompting) --become-method=BECOME_METHOD privilege escalation method to use (default=sudo), valid choices: [ sudo | su | pbrun | pfexec | doas | dzdo | ksu | runas | pmrun | enable ] --become-user=BECOME_USER run operations as this user (default=root) --ask-sudo-pass ask for sudo password (deprecated, use become) --ask-su-pass ask for su password (deprecated, use become) -K, --ask-become-pass ask for privilege escalation password Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"tools/supervisor-usage.html":{"url":"tools/supervisor-usage.html","title":"Supervisor的使用","keywords":"","body":"1. Supervisor简介 Supervisord 是用 Python 实现的一款的进程管理工具，supervisord 要求管理的程序是非 daemon 程序，supervisord 会帮你把它转成 daemon 程序，因此如果用 supervisord 来管理进程，进程需要以非daemon的方式启动。 例如：管理nginx 的话，必须在 nginx 的配置文件里添加一行设置 daemon off 让 nginx 以非 daemon 方式启动。 2. Supervisor安装 以centos系统为例，以下两种方式选择其一。 # yum install 的方式 yum install -y supervisor # easy_install的方式 yum install -y python-setuptools easy_install supervisor echo_supervisord_conf >/etc/supervisord.conf 3. Supervisor的配置 3.1. supervisord.conf的配置 如果使用yum install -y supervisor的命令安装，会生成默认配置/etc/supervisord.conf和目录/etc/supervisord.d，如果没有则自行创建。 在/etc/supervisord.d的目录下创建conf和log两个目录，conf用于存放管理进程的配置，log用于存放管理进程的日志。 cd /etc/supervisord.d mkdir conf log 修改/etc/supervisord.conf的[include]部分，即载入/etc/supervisord.d/conf目录下的所有配置。 vi /etc/supervisord.conf ... [include] files = supervisord.d/conf/*.conf ... 也可以修改supervisor应用日志的目录，默认日志路径为/var/log/supervisor/supervisord.log。 vi /etc/supervisord.conf ... [supervisord] logfile=/var/log/supervisor/supervisord.log ; (main log file;default $CWD/supervisord.log) logfile_maxbytes=50MB ; (max main logfile bytes b4 rotation;default 50MB) logfile_backups=10 ; (num of main logfile rotation backups;default 10) loglevel=info ; (log level;default info; others: debug,warn,trace) pidfile=/var/run/supervisord.pid ; (supervisord pidfile;default supervisord.pid) ... 3.2. 管理应用的配置 进入到/etc/supervisord.d/conf目录，创建管理应用的配置，可以创建多个应用配置。 例如，创建confd.conf配置。 [program:confd] directory = /usr/local/bin ; 程序的启动目录 command = /usr/local/bin/confd -config-file /etc/confd/confd.toml ; 启动命令，与命令行启动的命令是一样的 autostart = true ; 在 supervisord 启动的时候也自动启动 startsecs = 5 ; 启动 5 秒后没有异常退出，就当作已经正常启动了 autorestart = true ; 程序异常退出后自动重启 startretries = 3 ; 启动失败自动重试次数，默认是 3 user = root ; 用哪个用户启动 redirect_stderr = true ; 把 stderr 重定向到 stdout，默认 false stdout_logfile_maxbytes = 20MB ; stdout 日志文件大小，默认 50MB stdout_logfile_backups = 20 ; stdout 日志文件备份数 ; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件） stdout_logfile = /etc/supervisord.d/log/confd.log ;日志统一放在log目录下 ; 可以通过 environment 来添加需要的环境变量，一种常见的用法是修改 PYTHONPATH ; environment=PYTHONPATH=$PYTHONPATH:/path/to/somewhere 4. Surpervisor的启动 # supervisord二进制启动 supervisord -c /etc/supervisord.conf # 检查进程 ps aux | grep supervisord 或者以systemd的方式管理 vi /etc/rc.d/init.d/supervisord #!/bin/sh # # /etc/rc.d/init.d/supervisord # # Supervisor is a client/server system that # allows its users to monitor and control a # number of processes on UNIX-like operating # systems. # # chkconfig: - 64 36 # description: Supervisor Server # processname: supervisord # Source init functions . /etc/rc.d/init.d/functions prog=\"supervisord\" prefix=\"/usr\" exec_prefix=\"${prefix}\" prog_bin=\"${exec_prefix}/bin/supervisord\" PIDFILE=\"/var/run/$prog.pid\" start() { echo -n $\"Starting $prog: \" daemon $prog_bin --pidfile $PIDFILE -c /etc/supervisord.conf [ -f $PIDFILE ] && success $\"$prog startup\" || failure $\"$prog startup\" echo } stop() { echo -n $\"Shutting down $prog: \" [ -f $PIDFILE ] && killproc $prog || success $\"$prog shutdown\" echo } case \"$1\" in start) start ;; stop) stop ;; status) status $prog ;; restart) stop start ;; *) echo \"Usage: $0 {start|stop|restart|status}\" ;; esac 设置开机启动及systemd方式启动。 sudo chmod +x /etc/rc.d/init.d/supervisord sudo chkconfig --add supervisord sudo chkconfig supervisord on sudo service supervisord start 5. supervisorctl&supervisord Supervisord 安装完成后有两个可用的命令行 supervisord 和 supervisorctl，命令使用解释如下： 5.1. supervisorctl supervisorctl stop programxxx，停止某一个进程(programxxx)，programxxx 为 [program:beepkg] 里配置的值，这个示例就是 beepkg。 supervisorctl start programxxx，启动某个进程。 supervisorctl restart programxxx，重启某个进程。 supervisorctl status，查看进程状态。 supervisorctl stop groupworker ，重启所有属于名为 groupworker 这个分组的进程(start,restart 同理)。 supervisorctl stop all，停止全部进程，注：start、restart、stop 都不会载入最新的配置文件。 supervisorctl reload，载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程。 supervisorctl update，根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启。 更多参考： $ supervisorctl --help supervisorctl -- control applications run by supervisord from the cmd line. Usage: /usr/bin/supervisorctl [options] [action [arguments]] Options: -c/--configuration -- configuration file path (default /etc/supervisord.conf) -h/--help -- print usage message and exit -i/--interactive -- start an interactive shell after executing commands -s/--serverurl URL -- URL on which supervisord server is listening (default \"http://localhost:9001\"). -u/--username -- username to use for authentication with server -p/--password -- password to use for authentication with server -r/--history-file -- keep a readline history (if readline is available) action [arguments] -- see below Actions are commands like \"tail\" or \"stop\". If -i is specified or no action is specified on the command line, a \"shell\" interpreting actions typed interactively is started. Use the action \"help\" to find out about available actions. 例如： # supervisorctl status confd RUNNING pid 31256, uptime 0:11:24 twemproxy RUNNING pid 31255, uptime 0:11:24 5.2. supervisord supervisord，初始启动 Supervisord，启动、管理配置中设置的进程。 $ supervisord --help supervisord -- run a set of applications as daemons. Usage: /usr/bin/supervisord [options] Options: -c/--configuration FILENAME -- configuration file -n/--nodaemon -- run in the foreground (same as 'nodaemon true' in config file) -h/--help -- print this usage message and exit -v/--version -- print supervisord version number and exit -u/--user USER -- run supervisord as this user (or numeric uid) -m/--umask UMASK -- use this umask for daemon subprocess (default is 022) -d/--directory DIRECTORY -- directory to chdir to when daemonized -l/--logfile FILENAME -- use FILENAME as logfile path -y/--logfile_maxbytes BYTES -- use BYTES to limit the max size of logfile -z/--logfile_backups NUM -- number of backups to keep when max bytes reached -e/--loglevel LEVEL -- use LEVEL as log level (debug,info,warn,error,critical) -j/--pidfile FILENAME -- write a pid file for the daemon process to FILENAME -i/--identifier STR -- identifier used for this instance of supervisord -q/--childlogdir DIRECTORY -- the log directory for child process logs -k/--nocleanup -- prevent the process from performing cleanup (removal of old automatic child log files) at startup. -a/--minfds NUM -- the minimum number of file descriptors for start success -t/--strip_ansi -- strip ansi escape codes from process output --minprocs NUM -- the minimum number of processes available for start success --profile_options OPTIONS -- run supervisord under profiler and output results based on OPTIONS, which is a comma-sep'd list of 'cumulative', 'calls', and/or 'callers', e.g. 'cumulative,callers') 6. Supervisor控制台 在/etc/supervisord.conf中修改[inet_http_server]的参数，具体如下： [inet_http_server] ; inet (TCP) server disabled by default port=*:9001 ; ip_address:port specifier, *:port for all iface username=root ; default is no username (open server) password=xxxx ; default is no password (open server) 修改后重启supervisor进程，在浏览器访问 http://:9001。 具体如下： 图片 - supervisor 7. supervisor.conf详细配置 cat /etc/supervisord.conf ; Sample supervisor config file. [unix_http_server] file=/var/run/supervisor/supervisor.sock ; (the path to the socket file) ;chmod=0700 ; sockef file mode (default 0700) ;chown=nobody:nogroup ; socket file uid:gid owner ;username=user ; (default is no username (open server)) ;password=123 ; (default is no password (open server)) ;[inet_http_server] ; inet (TCP) server disabled by default ;port=127.0.0.1:9001 ; (ip_address:port specifier, *:port for all iface) ;username=user ; (default is no username (open server)) ;password=123 ; (default is no password (open server)) [supervisord] logfile=/var/log/supervisor/supervisord.log ; (main log file;default $CWD/supervisord.log) logfile_maxbytes=50MB ; (max main logfile bytes b4 rotation;default 50MB) logfile_backups=10 ; (num of main logfile rotation backups;default 10) loglevel=info ; (log level;default info; others: debug,warn,trace) pidfile=/var/run/supervisord.pid ; (supervisord pidfile;default supervisord.pid) nodaemon=false ; (start in foreground if true;default false) minfds=1024 ; (min. avail startup file descriptors;default 1024) minprocs=200 ; (min. avail process descriptors;default 200) ;umask=022 ; (process file creation umask;default 022) ;user=chrism ; (default is current user, required if root) ;identifier=supervisor ; (supervisord identifier, default is 'supervisor') ;directory=/tmp ; (default is not to cd during start) ;nocleanup=true ; (don't clean up tempfiles at start;default false) ;childlogdir=/tmp ; ('AUTO' child log dir, default $TEMP) ;environment=KEY=value ; (key value pairs to add to environment) ;strip_ansi=false ; (strip ansi escape codes in logs; def. false) ; the below section must remain in the config file for RPC ; (supervisorctl/web interface) to work, additional interfaces may be ; added by defining them in separate rpcinterface: sections [rpcinterface:supervisor] supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface [supervisorctl] serverurl=unix:///var/run/supervisor/supervisor.sock ; use a unix:// URL for a unix socket ;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket ;username=chris ; should be same as http_username if set ;password=123 ; should be same as http_password if set ;prompt=mysupervisor ; cmd line prompt (default \"supervisor\") ;history_file=~/.sc_history ; use readline history if available ; The below sample program section shows all possible program subsection values, ; create one or more 'real' program: sections to be able to control them under ; supervisor. ;[program:theprogramname] ;command=/bin/cat ; the program (relative uses PATH, can take args) ;process_name=%(program_name)s ; process_name expr (default %(program_name)s) ;numprocs=1 ; number of processes copies to start (def 1) ;directory=/tmp ; directory to cwd to before exec (def no cwd) ;umask=022 ; umask for process (default None) ;priority=999 ; the relative start priority (default 999) ;autostart=true ; start at supervisord start (default: true) ;autorestart=true ; retstart at unexpected quit (default: true) ;startsecs=10 ; number of secs prog must stay running (def. 1) ;startretries=3 ; max # of serial start failures (default 3) ;exitcodes=0,2 ; 'expected' exit codes for process (default 0,2) ;stopsignal=QUIT ; signal used to kill process (default TERM) ;stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10) ;user=chrism ; setuid to this UNIX account to run the program ;redirect_stderr=true ; redirect proc stderr to stdout (default false) ;stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO ;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB) ;stdout_logfile_backups=10 ; # of stdout logfile backups (default 10) ;stdout_capture_maxbytes=1MB ; number of bytes in 'capturemode' (default 0) ;stdout_events_enabled=false ; emit events on stdout writes (default false) ;stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO ;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB) ;stderr_logfile_backups=10 ; # of stderr logfile backups (default 10) ;stderr_capture_maxbytes=1MB ; number of bytes in 'capturemode' (default 0) ;stderr_events_enabled=false ; emit events on stderr writes (default false) ;environment=A=1,B=2 ; process environment additions (def no adds) ;serverurl=AUTO ; override serverurl computation (childutils) ; The below sample eventlistener section shows all possible ; eventlistener subsection values, create one or more 'real' ; eventlistener: sections to be able to handle event notifications ; sent by supervisor. ;[eventlistener:theeventlistenername] ;command=/bin/eventlistener ; the program (relative uses PATH, can take args) ;process_name=%(program_name)s ; process_name expr (default %(program_name)s) ;numprocs=1 ; number of processes copies to start (def 1) ;events=EVENT ; event notif. types to subscribe to (req'd) ;buffer_size=10 ; event buffer queue size (default 10) ;directory=/tmp ; directory to cwd to before exec (def no cwd) ;umask=022 ; umask for process (default None) ;priority=-1 ; the relative start priority (default -1) ;autostart=true ; start at supervisord start (default: true) ;autorestart=unexpected ; restart at unexpected quit (default: unexpected) ;startsecs=10 ; number of secs prog must stay running (def. 1) ;startretries=3 ; max # of serial start failures (default 3) ;exitcodes=0,2 ; 'expected' exit codes for process (default 0,2) ;stopsignal=QUIT ; signal used to kill process (default TERM) ;stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10) ;user=chrism ; setuid to this UNIX account to run the program ;redirect_stderr=true ; redirect proc stderr to stdout (default false) ;stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO ;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB) ;stdout_logfile_backups=10 ; # of stdout logfile backups (default 10) ;stdout_events_enabled=false ; emit events on stdout writes (default false) ;stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO ;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB) ;stderr_logfile_backups ; # of stderr logfile backups (default 10) ;stderr_events_enabled=false ; emit events on stderr writes (default false) ;environment=A=1,B=2 ; process environment additions ;serverurl=AUTO ; override serverurl computation (childutils) ; The below sample group section shows all possible group values, ; create one or more 'real' group: sections to create \"heterogeneous\" ; process groups. ;[group:thegroupname] ;programs=progname1,progname2 ; each refers to 'x' in [program:x] definitions ;priority=999 ; the relative start priority (default 999) ; The [include] section can just contain the \"files\" setting. This ; setting can list multiple files (separated by whitespace or ; newlines). It can also contain wildcards. The filenames are ; interpreted as relative to this file. Included files *cannot* ; include files themselves. [include] files = supervisord.d/conf/*.conf 参考： http://supervisord.org/ Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"tools/confd-usage.html":{"url":"tools/confd-usage.html","title":"Confd的使用","keywords":"","body":" confd的源码参考：https://github.com/kelseyhightower/confd 1. confd的部署 以下Linux系统为例。 下载confd的二进制文件，下载地址为：https://github.com/kelseyhightower/confd/releases。例如： # Download the binary wget https://github.com/kelseyhightower/confd/releases/download/v0.16.0/confd-0.16.0-linux-amd64 # 重命名二进制文件，并移动到PATH的目录下 mv confd-0.16.0-linux-amd64 /usr/local/bin/confd chmod +x /usr/local/bin/confd # 验证是否安装成功 confd --help 2. confd的配置 Confd通过读取后端存储的配置信息来动态更新对应的配置文件，对应的后端存储可以是etcd，redis等，其中etcd的v3版本对应的存储后端为etcdv3。 2.1. confd.toml confd.toml为confd服务本身的配置文件，主要记录了使用的存储后端、协议、confdir等参数。 示例： 存储后端etcdv3： backend = \"etcdv3\" confdir = \"/etc/confd\" log-level = \"debug\" interval = 5 nodes = [ \"http://192.168.10.4:12379\", ] scheme = \"http\" watch = true 其中watch参数表示实时监听后端存储的变化，如有变化则更新confd管理的配置。 存储后端为redis backend = \"redis\" confdir = \"/etc/confd\" log-level = \"debug\" interval = 1 # 间隔 1 秒同步一次配置文件 nodes = [ \"127.0.0.1:6379\", ] scheme = \"http\" client_key = \"123456\" # redis的密码，不是 password 参数 #watch = true 如果没有启动watch参数，则会依据interval参数定期去redis存储后端拿取数据，并比较与当前配置数据是否有变化（主要比较md5值），如果有变化则更新配置，没有变化则定期再去拿取数据，以此循环。 如果启动了watch参数，则修改redis存储数据的同时，还要执行publish的操作，促使confd去触发比较配置并更新配置的操作。 publish的命令格式如下: publish __keyspace@0__:{prefix}/{key} set(or del) 2.2. 创建confdir confdir底下包含两个目录: conf.d:confd的配置文件，主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。 templates:配置模板Template，即基于不同组件的配置，修改为符合 Golang text templates的模板文件。 sudo mkdir -p /etc/confd/{conf.d,templates} 2.2.1. Template Resources 模板源配置文件是TOML格式的文件，主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。默认目录在/etc/confd/conf.d。 参数说明： 必要参数 dest (string) - The target file. keys (array of strings) - An array of keys. src (string) - The relative path of a configuration template. 可选参数 gid (int) - The gid that should own the file. Defaults to the effective gid. mode (string) - The permission mode of the file. uid (int) - The uid that should own the file. Defaults to the effective uid. reload_cmd (string) - The command to reload config. check_cmd (string) - The command to check config. Use `` to reference the rendered source template. prefix (string) - The string to prefix to keys. 例子 例如：/etc/confd/conf.d/myapp-nginx.toml [template] prefix = \"/myapp\" src = \"nginx.tmpl\" dest = \"/tmp/myapp.conf\" owner = \"nginx\" mode = \"0644\" keys = [ \"/services/web\" ] check_cmd = \"/usr/sbin/nginx -t -c {{.src}}\" reload_cmd = \"/usr/sbin/service nginx reload\" 2.2.2. Template Template定义了单一应用配置的模板，默认存储在/etc/confd/templates目录下，模板文件符合Go的text/template格式。 模板文件常用函数有base，get，gets，lsdir，json等。具体可参考https://github.com/kelseyhightower/confd/blob/master/docs/templates.md。 例子： /etc/confd/templates/nginx.tmpl {{range $dir := lsdir \"/services/web\"}} upstream {{base $dir}} { {{$custdir := printf \"/services/web/%s/*\" $dir}}{{range gets $custdir}} server {{$data := json .Value}}{{$data.IP}}:80; {{end}} } server { server_name {{base $dir}}.example.com; location / { proxy_pass {{base $dir}}; } } {{end}} 3. 创建后端存储的配置数据 以etcdv3存储为例，在etcd中创建以下数据。 etcdctl --endpoints=$endpoints put /services/web/cust1/2 '{\"IP\": \"10.0.0.2\"}' etcdctl --endpoints=$endpoints put /services/web/cust2/2 '{\"IP\": \"10.0.0.4\"}' etcdctl --endpoints=$endpoints put /services/web/cust2/1 '{\"IP\": \"10.0.0.3\"}' etcdctl --endpoints=$endpoints put /services/web/cust1/1 '{\"IP\": \"10.0.0.1\"}' 4. 启动confd的服务 confd支持以daemon或者onetime两种模式运行，当以daemon模式运行时，confd会监听后端存储的配置变化，并根据配置模板动态生成目标配置文件。 confd可以使用-config-file参数来指定confd的配置文件，而将其他参数写在配置文件中。 /usr/local/bin/confd -config-file /etc/confd/conf/confd.toml 如果以daemon模式运行，在命令后面添加&符号，例如： confd -watch -backend etcdv3 -node http://172.16.5.4:12379 & 以下以onetime模式运行为例。其中对应的后端存储类型是etcdv3。 # 执行命令 confd -onetime -backend etcdv3 -node http://172.16.5.4:12379 # output 2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Backend set to etcdv3 2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Starting confd 2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Backend source(s) set to http://172.16.5.4:12379 2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO /root/myapp/twemproxy/conf/twemproxy.conf has md5sum 6f0f43abede612c75cb840a4840fbea3 should be 32f48664266e3fd6b56ee73a314ee272 2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Target config /root/myapp/twemproxy/conf/twemproxy.conf out of sync 2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Target config /root/myapp/twemproxy/conf/twemproxy.conf has been updated 5. 查看生成的配置文件 在/etc/confd/conf.d/myapp-nginx.toml中定义的配置文件的生成路径为/tmp/myapp.conf。 [root@k8s-dbg-master-1 dest]# cat myapp.conf upstream cust1 { server 10.0.0.1:80; server 10.0.0.2:80; } server { server_name cust1.example.com; location / { proxy_pass cust1; } } upstream cust2 { server 10.0.0.3:80; server 10.0.0.4:80; } server { server_name cust2.example.com; location / { proxy_pass cust2; } } 6. confd动态更新twemproxy 6.1. twemproxy.toml confd的模板源文件配置：/etc/confd/conf.d/twemproxy.toml [template] src = \"twemproxy.tmpl\" dest = \"/root/myapp/twemproxy/conf/twemproxy.conf\" keys = [ \"/twemproxy/pool\" ] check_cmd = \"/usr/local/bin/nutcracker -t -c /root/myapp/twemproxy/conf/twemproxy.conf\" reload_cmd = \"bash /root/myapp/twemproxy/reload.sh\" 6.2. twemproxy.tmpl 模板文件：/etc/confd/templates/twemproxy.tmpl global: worker_processes: 4 # 并发进程数, 如果为0, 这 fallback 回原来的单进程模型(不支持 config reload!) user: nobody # worker 进程的用户, 默认 nobody. 只要主进程是 root 用户启动才生效. group: nobody # worker 进程的用户组 worker_shutdown_timeout: 30 # 单位为秒. 用于 reload 过程中在改时间段之后强制退出旧的 worker 进程. pools: {{range gets \"/twemproxy/pool/*\"}} {{base .Key}}: {{$pool := json .Value}} listen: {{$pool.ListenAddr.IP}}:{{$pool.ListenAddr.Port}} hash: fnv1a_64 # 选择实例的 hash 规则 distribution: ketama auto_eject_hosts: true # server 有问题是否剔除 redis: true # 是否为 Redis 协议 {{if $pool.Password}}redis_auth: {{$pool.Password}}{{end}} server_retry_timeout: 5000 # 被剔除多长时间后会重试 server_connections: 25 # NOTE: server 连接池的大小, 默认为 1, 建议调整 server_failure_limit: 5 # 失败多少次后暂时剔除 timeout: 1000 # Server 超时时间, 1 sec backlog: 1024 # 连接队列大小 preconnect: true # 预连接大小 servers:{{range $server := $pool.Servers}} - {{$server.IP}}:{{$server.Port}}:1 {{if $server.Master}}master{{end}} {{end}} {{end}} 6.3. etcd中的配置格式 etcd中的配置通过一个map来定义为完整的配置内容。其中key是twemproxy中pool的名称，value是pool的所有内容。 配置对应go结构体如下： type Pool struct{ ListenAddr ListenAddr `json:\"ListenAddr,omitempty\"` Servers []Server `json:\"Servers,omitempty\"` Password string `json:\"Password,omitempty\"` } type ListenAddr struct { IP string `json:\"IP,omitempty\"` Port string `json:\"Port,omitempty\"` } type Server struct { IP string `json:\"IP,omitempty\"` Port string `json:\"Port,omitempty\"` Master bool `json:\"Master,omitempty\"` } 配置对应JSON格式如下： { \"ListenAddr\": { \"IP\": \"192.168.5.7\", \"Port\": \"22225\" }, \"Servers\": [ { \"IP\": \"10.233.116.168\", \"Port\": \"6379\", \"Master\": true }, { \"IP\": \"10.233.110.207\", \"Port\": \"6379\", \"Master\": false } ], \"Password\": \"987654\" } 6.4. 生成twemproxy配置文件 global: worker_processes: 4 # 并发进程数, 如果为0, 这 fallback 回原来的单进程模型(不支持 config reload!) user: nobody # worker 进程的用户, 默认 nobody. 只要主进程是 root 用户启动才生效. group: nobody # worker 进程的用户组 worker_shutdown_timeout: 30 # 单位为秒. 用于 reload 过程中在改时间段之后强制退出旧的 worker 进程. pools: redis1: listen: 192.168.5.7:22223 hash: fnv1a_64 # 选择实例的 hash 规则 distribution: ketama auto_eject_hosts: true # server 有问题是否剔除 redis: true # 是否为 Redis 协议 redis_auth: 987654 server_retry_timeout: 5000 # 被剔除多长时间后会重试 server_connections: 25 # NOTE: server 连接池的大小, 默认为 1, 建议调整 server_failure_limit: 5 # 失败多少次后暂时剔除 timeout: 1000 # Server 超时时间, 1 sec backlog: 1024 # 连接队列大小 preconnect: true # 预连接大小 servers: - 10.233.116.169:6379:1 redis2: listen: 192.168.5.7:22224 hash: fnv1a_64 # 选择实例的 hash 规则 distribution: ketama auto_eject_hosts: true # server 有问题是否剔除 redis: true # 是否为 Redis 协议 redis_auth: 987654 server_retry_timeout: 5000 # 被剔除多长时间后会重试 server_connections: 25 # NOTE: server 连接池的大小, 默认为 1, 建议调整 server_failure_limit: 5 # 失败多少次后暂时剔除 timeout: 1000 # Server 超时时间, 1 sec backlog: 1024 # 连接队列大小 preconnect: true # 预连接大小 servers: - 10.233.110.223:6379:1 master - 10.233.111.21:6379:1 7. confd的命令 $ confd --help Usage of confd: -app-id string Vault app-id to use with the app-id backend (only used with -backend=vault and auth-type=app-id) -auth-token string Auth bearer token to use -auth-type string Vault auth backend type to use (only used with -backend=vault) -backend string backend to use (default \"etcd\") -basic-auth Use Basic Auth to authenticate (only used with -backend=consul and -backend=etcd) -client-ca-keys string client ca keys -client-cert string the client cert -client-key string the client key -confdir string confd conf directory (default \"/etc/confd\") -config-file string the confd config file (default \"/etc/confd/confd.toml\") -file value the YAML file to watch for changes (only used with -backend=file) -filter string files filter (only used with -backend=file) (default \"*\") -interval int backend polling interval (default 600) -keep-stage-file keep staged files -log-level string level which confd should log messages -node value list of backend nodes -noop only show pending changes -onetime run once and exit -password string the password to authenticate with (only used with vault and etcd backends) -path string Vault mount path of the auth method (only used with -backend=vault) -prefix string key path prefix -role-id string Vault role-id to use with the AppRole, Kubernetes backends (only used with -backend=vault and either auth-type=app-role or auth-type=kubernetes) -scheme string the backend URI scheme for nodes retrieved from DNS SRV records (http or https) (default \"http\") -secret-id string Vault secret-id to use with the AppRole backend (only used with -backend=vault and auth-type=app-role) -secret-keyring string path to armored PGP secret keyring (for use with crypt functions) -separator string the separator to replace '/' with when looking up keys in the backend, prefixed '/' will also be removed (only used with -backend=redis) -srv-domain string the name of the resource record -srv-record string the SRV record to search for backends nodes. Example: _etcd-client._tcp.example.com -sync-only sync without check_cmd and reload_cmd -table string the name of the DynamoDB table (only used with -backend=dynamodb) -user-id string Vault user-id to use with the app-id backend (only used with -backend=value and auth-type=app-id) -username string the username to authenticate as (only used with vault and etcd backends) -version print version and exit -watch enable watch support 参考文章： https://github.com/kelseyhightower/confd/blob/master/docs/installation.md https://github.com/kelseyhightower/confd/blob/master/docs/quick-start-guide.md https://github.com/kelseyhightower/confd/blob/master/docs/template-resources.md https://github.com/kelseyhightower/confd/blob/master/docs/templates.md Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-10-27 17:23:11 "},"tools/nfs-usage.html":{"url":"tools/nfs-usage.html","title":"NFS的使用","keywords":"","body":"1. NFS简介 NFS，是Network File System的简写，即网络文件系统。网络文件系统是FreeBSD支持的文件系统中的一种，也被称为NFS. NFS允许一个系统在网络上与他人共享目录和文件。 通过使用NFS，用户和程序可以像访问本地文件一样访问远端系统上的文件。 2. NFS的安装与配置 2.1 服务端 NFS需要安装nfs-utils、rpcbind两个包。 #可以先检查下本地是否已经安装，如果安装则无需重复安装包 [root@k8s-dbg-master-1 build]# rpm -qa|grep rpcbind rpcbind-0.2.0-42.el7.x86_64 [root@k8s-dbg-master-1 build]# rpm -qa|grep nfs libnfsidmap-0.25-17.el7.x86_64 nfs-utils-1.3.0-0.48.el7_4.x86_64 2.1.1. 安装nfs-utils、rpcbind两个包 #centos系统 yum -y install nfs-utils rpcbind #Ubuntu系统 #服务端 apt-get install nfs-kernel-server #客户端 apt-get install nfs-common 2.1.2. 创建共享目录 服务端共享目录：/data/nfs-storage/ mkdir /data/nfs-storage/ 2.1.3. NFS共享目录文件配置 vi /etc/exports #添加以下信息 /data/nfs-storage *(rw,insecure,sync,no_subtree_check,no_root_squash) 以上配置分为三个部分： 第一部分就是本地要共享出去的目录。 第二部分为允许访问的主机（可以是一个IP也可以是一个IP段），*代表允许所有的网段访问。 第三部分小括号里面的，为一些权限选项。 权限说明 rw ：读写； ro ：只读； sync ：同步模式，内存中数据时时写入磁盘； async ：不同步，把内存中数据定期写入磁盘中； secure ：nfs通过1024以下的安全TCP/IP端口发送 insecure ：nfs通过1024以上的端口发送 no_root_squash ：加上这个选项后，root用户就会对共享的目录拥有至高的权限控制，就像是对本机的目录操作一样。不安全，不建议使用； root_squash ：和上面的选项对应，root用户对共享目录的权限不高，只有普通用户的权限，即限制了root； subtree_check ：如果共享/usr/bin之类的子目录时，强制nfs检查父目录的权限（默认） no_subtree_check ：和上面相对，不检查父目录权限 all_squash ：不管使用NFS的用户是谁，他的身份都会被限定成为一个指定的普通用户身份； anonuid/anongid ：要和root_squash 以及 all_squash一同使用，用于指定使用NFS的用户限定后的uid和gid，前提是本机的/etc/passwd中存在这个uid和gid。 2.1.4. 启动NFS服务 #先启动rpcbind service rpcbind start #后启动nfs service nfs start #可以设置开机启动 chkconfig rpcbind on chkconfig nfs on 2.1.5. 服务端验证 通过showmount -e命令如果正常显示共享目录，表示安装正常。 [root@k8s-dbg-master-1 build]# showmount -e Export list for k8s-dbg-master-1: /data/nfs-storage * 2.2 客户端 2.2.1. 安装nfs-utils的包 yum install nfs-utils.x86_64 -y 2.2.2. 创建挂载点 客户端挂载目录：/mnt/store mkdir /mnt/store 2.2.3. 查看NFS服务器的共享 root@k8s-dbg-node-5:~# showmount -e 172.16.5.4 Export list for 172.16.5.4: /data/nfs-storage * 2.2.4. 挂载 mount -t nfs : #例如： mount -t nfs 172.16.5.4:/data/nfs-storage /mnt/store 2.2.5. 验证挂载信息 使用mount命令 root@k8s-dbg-node-5:~# mount |grep /mnt/store 172.16.5.4:/data/nfs-storage/k8s-storage/ssd on /mnt/store type nfs4 (rw,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,port=0,timeo=600,retrans=2,sec=sys,clientaddr=172.16.200.24,local_lock=none,addr=172.16.5.4) 使用df -h命令 root@k8s-dbg-node-5:~# df -h|grep nfs 172.16.5.4:/data/nfs-storage 40G 25G 13G 67% /mnt/store 创建文件测试 #进入客户端的挂载目录，创建文件 cd /mnt/store touch test.txt #进入服务端的共享目录，查看客户端创建的文件是否同步 cd /data/nfs-storage ls Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"git/git.html":{"url":"git/git.html","title":"Git 介绍","keywords":"","body":"1. Git是什么 1.1. 概述 Git是分布式版本控制系统，与SVN类似的集中化版本控制系统相比，集中化版本控制系统如果中央服务器宕机则会影响数据和协同开发。 Git是分布式的版本控制系统，客户端不只是提取最新版本的快照，而且将整个代码仓库镜像复制下来。如果任何协同工作用的服务器发生故障了，也可以用任何一个代码仓库来恢复。而且在协作服务器宕机期间，你也可以提交代码到本地仓库，当协作服务器正常工作后，你再将本地仓库同步到远程仓库。 1.2. 特性 能够对文件版本控制和多人协作开发 拥有强大的分支特性，所以能够灵活地以不同的工作流协同开发 分布式版本控制系统，即使协作服务器宕机，也能继续提交代码或文件到本地仓库，当协作服务器恢复正常工作时，再将本地仓库同步到远程仓库。 当团队中某个成员完成某个功能时，通过pull request操作来通知其他团队成员，其他团队成员能够review code后再合并代码。 2. 为什么要用Git 能够对文件版本控制和多人协作开发 拥有强大的分支特性，所以能够灵活地以不同的工作流协同开发 分布式版本控制系统，即使协作服务器宕机，也能继续提交代码或文件到本地仓库，当协作服务器恢复正常工作时，再将本地仓库同步到远程仓库。 当团队中某个成员完成某个功能时，通过pull request操作来通知其他团队成员，其他团队成员能够review code后再合并代码。 3. Git 命令思维导图 图片 - git-map Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 20:27:01 "},"git/git-common-cmd.html":{"url":"git/git-common-cmd.html","title":"Git 常用命令","keywords":"","body":"1. Git常用命令 分类 子类 git command zsh alias 分支 查看当前分支 git branch gb 创建新分支,仍停留在当前分支 git branch 创建并切换到新分支 git checkout -b gcb 切换分支 git checkout 合并分支 git checkout #切换到要合并的分支git merge –no-ff #合并指定分支到当前分支 提交 查看状态 git status gst 查看修改部分 git diff --color gd 添加文件到暂存区 git add --all 提交本地仓库 git commit -m \"\" 推送到指定分支 git push -u origin 查看提交日志 git log - 2. git rebase 如果信息修改无法生效，设置永久环境变量：export EDITOR=vim 帮助信息： # Rebase 67da308..6ef692b onto 67da308 (1 command) # # Commands: # p, pick = use commit # r, reword = use commit, but edit the commit message # e, edit = use commit, but stop for amending # s, squash = use commit, but meld into previous commit # f, fixup = like \"squash\", but discard this commit's log message # x, exec = run command (the rest of the line) using shell # d, drop = remove commit # # These lines can be re-ordered; they are executed from top to bottom. # # If you remove a line here THAT COMMIT WILL BE LOST. # # However, if you remove everything, the rebase will be aborted. # # Note that empty commits are commented out 2.1. 合并多余提交记录 #以交互的方式进行rebase git rebase -i master #合并多余提交记录：s, squash = use commit, but meld into previous commit pick 6ef692b FIX: Fix parsing docker image version error s 3df667y FIX: the second push s 3fds95t FIX: the third push 保存退出 # 进入修改交互界面 删除需要删除的提交记录，保存退出 #查看提交记录是否已被修改 git log #最后强制提交到分支 git commit --force -u origin fix/add-unit-test-for-global-role-revoking 2.2. 修改提交记录 #以交互的方式进行rebase git rebase -i master #修改提交记录：e, edit = use commit, but stop for amending e 6ef692b FIX: Fix parsing docker image version error e 5ty697u FIX: Fix parsing docker image version error #保存退出 git commit --amend #修改提交记录内容，保存退出 git rebase --continue git commit --amend #修改下一条提交记录，保存退出 git rebase --continue git status # 查看状态提示 #最后强制提交到分支 git commit --force -u origin fix/add-unit-test-for-global-role-revoking #查看提交记录是否已被修改 git log 3. git设置忽略特殊文件 3.1. 忽略文件的原则 忽略操作系统自动生成的文件，比如缩略图等； 忽略编译生成的中间文件、可执行文件等，也就是如果一个文件是通过另一个文件自动生成的，那自动生成的文件就没必要放进版本库，比如Java编译产生的.class文件； 忽略你自己的带有敏感信息的配置文件，比如存放口令的配置文件。 3.2. 设置的方法 在项目的workdir 下编辑 .gitignore 文件，文件的路径填写为workdir的相对路径。 .idea/ #IDE的配置文件 _build/ server/server #二进制文件 3.3. gitignore 不生效解决方法 原因是.gitignore只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。那么解决方法就是先把本地缓存删除（改变成未track状态），然后再提交： git rm -r --cached . git add . git commit -m 'update .gitignore' 4. Git分支重命名 假设分支名称为oldName 想要修改为 newName 1. 本地分支重命名(还没有推送到远程) git branch -m oldName newName 2. 远程分支重命名 (已经推送远程-假设本地分支和远程对应分支名称相同) a. 重命名远程分支对应的本地分支 git branch -m oldName newName b. 删除远程分支 git push --delete origin oldName c. 上传新命名的本地分支 git push origin newName d.把修改后的本地分支与远程分支关联 git branch --set-upstream-to origin/newName 5. 代码冲突 git checkout master git pull git checkout git rebase -i master fix conflict git rebase --continue git push --force -u origin 6. 修改历史提交的用户信息 1、克隆并进入你的仓库 git clone --bare https://github.com/user/repo.git cd repo.git 2、创建以下脚本，例如命名为rename.sh #!/bin/sh git filter-branch --env-filter ' OLD_EMAIL=\"your-old-email@example.com\" #修改参数为你的旧提交邮箱 CORRECT_NAME=\"Your Correct Name\" #修改参数为你新的用户名 CORRECT_EMAIL=\"your-correct-email@example.com\" #修改参数为你新的邮箱名 if [ \"$GIT_COMMITTER_EMAIL\" = \"$OLD_EMAIL\" ] then export GIT_COMMITTER_NAME=\"$CORRECT_NAME\" export GIT_COMMITTER_EMAIL=\"$CORRECT_EMAIL\" fi if [ \"$GIT_AUTHOR_EMAIL\" = \"$OLD_EMAIL\" ] then export GIT_AUTHOR_NAME=\"$CORRECT_NAME\" export GIT_AUTHOR_EMAIL=\"$CORRECT_EMAIL\" fi ' --tag-name-filter cat -- --branches --tags 3、执行脚本 chmod +x rename.sh sh rename.sh 4、查看新 Git 历史有没有错误。 #可以看到提交记录的用户信息已经修改为新的用户信息 git log 5、确认提交内容，重新提交（可以先把rename.sh移除掉） git push --force --tags origin 'refs/heads/*' 7. 撤销已经push的提交 # 本地仓库回退到某一版本 git reset -hard # 强制 PUSH，此时远程分支已经恢复成指定的 commit 了 git push origin master --force Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 21:10:18 "},"git/git-commands.html":{"url":"git/git-commands.html","title":"Git 命令分类","keywords":"","body":"Git 命令详解 1. 示意图 图片 - 这里写图片描述 Workspace：工作区 Index / Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 2. Git 命令分类 2.1. 新建代码库 # 在当前目录新建一个Git代码库 $ git init # 新建一个目录，将其初始化为Git代码库 $ git init [project-name] # 下载一个项目和它的整个代码历史 $ git clone [url] 2.2. 配置 Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 # 显示当前的Git配置 $ git config --list # 编辑Git配置文件 $ git config -e [--global] # 设置提交代码时的用户信息 $ git config [--global] user.name \"[name]\" $ git config [--global] user.email \"[email address]\" 2.3. 增加/删除文件 # 添加指定文件到暂存区 $ git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录 $ git add [dir] # 添加当前目录的所有文件到暂存区 $ git add . # 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 $ git add -p # 删除工作区文件，并且将这次删除放入暂存区 $ git rm [file1] [file2] ... # 停止追踪指定文件，但该文件会保留在工作区 $ git rm --cached [file] # 改名文件，并且将这个改名放入暂存区 $ git mv [file-original] [file-renamed] 2.4. 代码提交 # 提交暂存区到仓库区 $ git commit -m [message] # 提交暂存区的指定文件到仓库区 $ git commit [file1] [file2] ... -m [message] # 提交工作区自上次commit之后的变化，直接到仓库区 $ git commit -a # 提交时显示所有diff信息 $ git commit -v # 使用一次新的commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [message] # 重做上一次commit，并包括指定文件的新变化 $ git commit --amend [file1] [file2] ... 2.5. 分支 # 列出所有本地分支 $ git branch # 列出所有远程分支 $ git branch -r # 列出所有本地分支和远程分支 $ git branch -a # 新建一个分支，但依然停留在当前分支 $ git branch [branch-name] # 新建一个分支，并切换到该分支 $ git checkout -b [branch] # 新建一个分支，指向指定commit $ git branch [branch] [commit] # 新建一个分支，与指定的远程分支建立追踪关系 $ git branch --track [branch] [remote-branch] # 切换到指定分支，并更新工作区 $ git checkout [branch-name] # 切换到上一个分支 $ git checkout - # 建立追踪关系，在现有分支与指定的远程分支之间 $ git branch --set-upstream [branch] [remote-branch] # 合并指定分支到当前分支 $ git merge [branch] # 选择一个commit，合并进当前分支 $ git cherry-pick [commit] # 删除分支 $ git branch -d [branch-name] # 删除远程分支 $ git push origin --delete [branch-name] $ git branch -dr [remote/branch] 2.6. 标签 # 列出所有tag $ git tag # 新建一个tag在当前commit $ git tag [tag] # 新建一个tag在指定commit $ git tag [tag] [commit] # 删除本地tag $ git tag -d [tag] # 删除远程tag $ git push origin :refs/tags/[tagName] # 查看tag信息 $ git show [tag] # 提交指定tag $ git push [remote] [tag] # 提交所有tag $ git push [remote] --tags # 新建一个分支，指向某个tag $ git checkout -b [branch] [tag] 2.7. 查看信息 # 显示有变更的文件 $ git status # 显示当前分支的版本历史 $ git log # 显示commit历史，以及每次commit发生变更的文件 $ git log --stat # 搜索提交历史，根据关键词 $ git log -S [keyword] # 显示某个commit之后的所有变动，每个commit占据一行 $ git log [tag] HEAD --pretty=format:%s # 显示某个commit之后的所有变动，其\"提交说明\"必须符合搜索条件 $ git log [tag] HEAD --grep feature # 显示某个文件的版本历史，包括文件改名 $ git log --follow [file] $ git whatchanged [file] # 显示指定文件相关的每一次diff $ git log -p [file] # 显示过去5次提交 $ git log -5 --pretty --oneline # 显示所有提交过的用户，按提交次数排序 $ git shortlog -sn # 显示指定文件是什么人在什么时间修改过 $ git blame [file] # 显示暂存区和工作区的差异 $ git diff # 显示暂存区和上一个commit的差异 $ git diff --cached [file] # 显示工作区与当前分支最新commit之间的差异 $ git diff HEAD # 显示两次提交之间的差异 $ git diff [first-branch]...[second-branch] # 显示今天你写了多少行代码 $ git diff --shortstat \"@{0 day ago}\" # 显示某次提交的元数据和内容变化 $ git show [commit] # 显示某次提交发生变化的文件 $ git show --name-only [commit] # 显示某次提交时，某个文件的内容 $ git show [commit]:[filename] # 显示当前分支的最近几次提交 $ git reflog 2.8. 远程同步 # 下载远程仓库的所有变动 $ git fetch [remote] # 显示所有远程仓库 $ git remote -v # 显示某个远程仓库的信息 $ git remote show [remote] # 增加一个新的远程仓库，并命名 $ git remote add [shortname] [url] # 取回远程仓库的变化，并与本地分支合并 $ git pull [remote] [branch] # 上传本地指定分支到远程仓库 $ git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] --force # 推送所有分支到远程仓库 $ git push [remote] --all 2.9. 撤销 # 恢复暂存区的指定文件到工作区 $ git checkout [file] # 恢复某个commit的指定文件到暂存区和工作区 $ git checkout [commit] [file] # 恢复暂存区的所有文件到工作区 $ git checkout . # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 $ git reset [file] # 重置暂存区与工作区，与上一次commit保持一致 $ git reset --hard # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 $ git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 $ git reset --hard [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变 $ git reset --keep [commit] # 新建一个commit，用来撤销指定commit # 后者的所有变化都将被前者抵消，并且应用到当前分支 $ git revert [commit] # 暂时将未提交的变化移除，稍后再移入 $ git stash $ git stash pop 2.10. 其他 # 生成一个可供发布的压缩包 $ git archive # 设置换行符为LF git config --global core.autocrlf false #拒绝提交包含混合换行符的文件 git config --global core.safecrlf true 参考文章： http://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 20:39:00 "},"nginx/install-nginx.html":{"url":"nginx/install-nginx.html","title":"Nginx安装与配置","keywords":"","body":"1. 部署 1.1. 使用安装包的方式 rpm -ivh nginx-xxx.rpm 1.2. 使用源代码安装 1.2.1. 下载源码包 wget http://blob.wae.haplat.net/nginx/nginx-1.9.13.tar.gz 1.2.2. 创建临时目录并解压源码包 mkdir $HOME/build cd $HOME/build && tar zxvf nginx-.tar.gz 1.2.3. 编译并安装 cd $HOME/build/nginx- ./configure \\ --prefix=/etc/nginx \\ --sbin-path=/usr/sbin/nginx \\ --conf-path=/etc/nginx/nginx.conf \\ ... # make && make install 1.2.4. 配置项 1.2.4.1. 通用配置项 配置选项 说明 --prefix= nginx安装的根路径，所有其他的路径都要依赖与该选项 --sbin-path= nginx二进制文件的路径，如果没有指定则会依赖于--prefix --conf-path= 如果在命令行中没有指定配置文件，则通过该配置项去查找配置文件 --error-log-path= 指定错误文件的路径 --pid-path= 指定的文件将会写入nginx master进程的pid，通常在/var/run下 --lock-path= 共享存储器互斥锁文件的路径 --user= worker进程运行的用户 --group= worker进程运行的组 --with-file-aio 启动异步I/O --with-debug 启用调试日志，生产环境不推荐配置 1.2.4.2. 优化配置项 配置选项 说明 --with-cc= 如果想设置一个不在默认PATH下的C编译器 --with-cpp= 设置C预处理器的相应路径 --with-cc-opt= 指定必要的include文件路径 --with-ld-opt= 包含连接器库的路径和运行路径 --with-cpu-opt= 通过该选项为特定的CPU构建nginx 1.2.4.3. http模块的配置项 配置选项 说明 --without-http-cache 在使用upstream模块时，nginx能够配置本地缓存内容，该选项可以禁用缓存 --with-http_perl_module nginx配置能够扩展使用perl代码。该项启用这个模块，但会降低性能 --with-perl_modules_path= 对于额外嵌入的perl模块，该选项指定该perl解析器的路径 --with-perl= 如果在默认的路径中找不到perl则指定perl（5.6版本以上）的路径 --http-log-path= http访问日志的默认路径 --http-client-body-temp-path= 从客户端收到请求后，该项用于作为请求体临时存放的目录 --http-proxy-temp-path= 在使用代理后，通过该项设置存放临时文件路径 --http-fastcgi-temp-path= 设置FastCGI临时文件的目录 --http-uwsgi-temp-path= 设置uWSGI临时文件的目录 --http-scgi-temp-path= 设置SCGI临时文件的目录 1.2.4.4. 其他模块额外配置项 默认没有安装这些模块，可以通过--with-_module来启用相应的模块功能。 配置选项 说明 --with-http_ssl_module 如果需要对流量进行加密，可以使用该选项，再URLs中开始部分将会是https(需要OpenSSL库) --with-http_realip_module 如果nginx在七层负载均衡器或者其他设备之后，它们将Http头中的客户端IP地址传递，则需要启用该模块，再多个客户处于一个IP地址的情况下使用 --with-http_addition_module 该模块作为输出过滤器，使能够在请求经过一个location前或后时在该location本身添加内容 --with-http_xslt_module 该模块用于处理XML响应转换，基于一个或多个XSLT格式 --with-http_image_filter_module 该模块被作为图像过滤器使用，在将图像投递到客户之前进行处理（需要libgd库） --with-http_geoip_module 使用该模块，能够设置各种变量以便在配置文件中的区段使用，基于地理位置查找客户端IP地址 --with-http_sub_module 该模块实现替代过滤，在响应中用一个字符串替代另一个字符串 --with-heep_dav_module 启用这个模块将激活使用WebDAV的配置指令。 --with-http_flv_module 如果需要提供Flash流媒体视频文件，那么该模块将会提供伪流媒体 --with-http_mp4_module 这个模块支持H.264/AAC文件伪流媒体 --with-http_gzip_static_module 当被调用的资源没有.gz结尾格式的文件时，如果想支持发送预压缩版本的静态文件，那么使用该模块 --with-http_gunzip_module 对于不支持gzip编码的客户，该模块用于为客户解压缩预压缩内容 --with-http_random_index_module 如果你想提供从一个目录中随机选择文件的索引文件，那么该模块需要激活 --with-http_secure_link_module 该模块提供一种机制，它会将一个哈希值链接到一个URL中，因此只有那些使用正确密码能够计算链接 --with-http_stub_status_module 启用这个模块后会收集Nginx自身的状态信息。输出的状态信息可以使用RRDtool或类似的东西绘制成图 2. 配置 配置文件一般为/etc/nginx/nginx.conf或/usr/local/nginx/conf/nginx.conf。 2.1. 基本配置格式 { ; } 每一个指令行由分号结束，大括号{}表示一个新的上下文。 2.2. Nginx全局配置参数 全局配置指令 模块 配置项 说明 main模块 user 配置worker进程的用户和组，如果忽略group，则group等于指定的用户的所属组 worker_processes 指定worker进程的启动数量，可将其设置为可用的CPU内核数，若为auto为自动检测 error_log 所有错误的写入文件，第二个参数指定错误的级别（debug，info，notice，warn，error，crit，alert，emerg） pid 设置主进程IP的文件 events模块 use 用于设置使用什么样的连接方法 worker_connections 用于配置一个工作进程能够接受的并发连接最大数。包括客户连接和向上游服务器的连接。 2.3. 使用include文件 include文件可以在任何地方以增强配置文件的可读性，使用include文件要确保被包含文件自身正确的nginx语法，即配置指令和块，然后指定这些文件的路径。 include /etc/nginx/mime.types; 若使用通配符则表示通配的多个文件，若没有给定全路径则依据主配置文件路径进行搜索。 include /etc/nginx/conf.d/*.conf 测试配置文件(包括include的配置文件)语法： nginx -t -c {path-to-nginx.conf} 2.4. 配置说明 2.4.1. main模块 #main模块类似main函数包含其他子模块，非模块配置项(包括模块内)分号结尾，子模块配置花括号结尾 user nobady; #一般按默认设置 pid /var/run/nginx.pid; #进程标识符存放路径，一般按默认设置 worker_processes auto; #nginx对外提供web服务时的worder进程数，可将其设置为可用的CPU内核数，auto为自动检测 worker_rlimit_nofile 100000; # 更改worker进程的最大打开文件数限制 error_log logs/error.log info; #错误日志存放路径 keepalive_timeout 60; #keepalive_timeout 60; events{ #见events模块 } http{ #见http模块 server{ ... location /{ } } } mail{ #见mail模块 } 2.4.2. events模块 events { worker_connections 2048; #设置可由一个worker进程同时打开的最大连接数 multi_accept on; #告诉nginx收到一个新连接通知后接受尽可能多的连接 use epoll; #设置用于复用客户端线程的轮询方法。Linux 2.6+：使用epoll；*BSD：使用kqueue。 } 2.4.3. http模块 http { #http模块 server { #server模块，http服务上的虚拟主机， server 当做对应一个域名进行的配置 listen 80; #配置监听端口 server_name www.linuxidc.com; #配置访问域名 access_log logs/linuxidc.access.log main; #指定日志文件的存放路径 index index.html; #默认访问页面 root /var/www/androidj.com/htdocs; # root 是指将本地的一个文件夹作为所有 url 请求的根路径 upstream backend { #反向代理的后端机器，实现负载均衡 ip_hash; #指明了我们均衡的方式是按照用户的 ip 地址进行分配 server backend1.example.com; server backend2.example.com; server backend3.example.com; server backend4.example.com; } location / { #location 是在一个域名下对更精细的路径进行配置 proxy_pass http://backend; #反向代理到后端机器 } } server { listen 80; server_name www.Androidj.com; access_log logs/androidj.access.log main; location / { index index.html; root /var/www/androidj.com/htdocs; } } } 2.4.4. mail模块 mail { auth_http 127.0.0.1:80/auth.php; pop3_capabilities \"TOP\" \"USER\"; imap_capabilities \"IMAP4rev1\" \"UIDPLUS\"; server { listen 110; protocol pop3; proxy on; } server { listen 25; protocol smtp; proxy on; smtp_auth login plain; xclient off; } } Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:56:15 "},"nginx/nginx-proxy.html":{"url":"nginx/nginx-proxy.html","title":"Nginx作为反向代理","keywords":"","body":"1. 反向代理简介 Nginx可以作为反向代理，接收客户端的请求，并向上游服务器发起新的请求。该请求可以根据客户端请求的URI，客户机参数或其他逻辑进行拆分，原始URL中的任何部分可以以这种方式进行转换。 1.1. 代理模块指令 指令 说明 proxy_connect_timeout Nginx从接受到请求到连接至上游服务器的最长等待时间 proxy_cookie_domain 替代从上游服务器来的Set-Cookie头的域domain proxy_cookie_path 替代从上游服务器来的Set-Cookie头的path属性 proxy_headers_hash_bucket_size 头名字的最大值 proxy_headers_hash_max_size 从上游服务器接收到头的总大小 proxy_hide_header 不应该传递给客户端头的列表 proxy_http_version 用于通上游服务器通信的Http协议版本 proxy_ignore_client_abort 如果设置为ON，那么客户端放弃连接后，nginx将不会放弃同上游服务器的连接 proxy_ignore_headers 当处理来自上游服务器的响应时，设置哪些头可以被忽略 proxy_intercept_errors 如果启用该选项，Nginx将会显示配置的error_page错误，而不是来自于上游服务器的直接响应 proxy_max_temp_file_size 在写入内存缓冲区时响应与内存不匹配时使用时，给出溢出文件的最大值 proxy_pass 指定请求被传递到的上游服务器，格式为URL proxy_pass_header 覆盖掉在proxy_hide_header指令中设置的头，允许这些头传递到客户端 proxy_pass_request_body 如果设置为off，将会阻止请求体传递到客户端 proxy_pass_request_headers 如果设置为on,则阻止请求头发送到上游服务器 proxy_read_timeout 给出连接关闭前从上游服务器两次成功的读操作耗时，如果上游服务器处理请求比较慢，那么该值需设置较高些 proxy_redirect 重写来自于上游服务器的Location和Refresh头 proxy_send_timeout 给出连接关闭前从上游服务器两次成功的写操作耗时，如果上游服务器处理请求比较慢，那么该值需设置较高些 proxy_set_body 发送到上游服务器的请求体可能会被该指令的设置值修改 proxy_set_header 重写发送到上游服务器头的内容，也可以通过将某种头的值设置为空字符，而不是发送某种头的方法实现 proxy_temp_file_write_size 在同一时间内限制缓冲到一个临时文件的数据量，以使得Nginx不会过长地阻止单个请求 proxy_temp_path 设定临时文件的缓冲，用于缓冲从上游服务器来的文件，可以设定目录的层次 1.2. upstream模块 upstream指令将会启用一个新的配置区域，在该区域定义了一组上游服务器，这些服务器可以被设置为不同的权重（权重高的服务器将会被Nginx传递越多的连接）。 指令 说明 ip_hash 通过IP地址的哈希值确保客户端均匀地连接所有的服务器，键值基于C类地址 keepalive 每一个worker进程缓存的到上游服务器的连接数。再使用Http连接时，proxy_http_verison设置1.1，并将proxy_set_header设置为Connection \"\" least_conn 激活负载均衡算法，将请求发送到活跃连接数最少的那台服务器 server 为upstream定义一个服务器地址（带有端口号的域名、IP地址，或者是UNIX套接字）和一个可选的参数，参数如下：weight：设置一个服务器的优先级优于其他服务器。max_fails：设置在fail_timeout时间之内尝试对一个服务器连接的最大次数，如果超过这个次数，那么就会被标记为down。fail_timeout：在这个指定的时间内服务器必须提供响应，如果在这个时间内没有收到响应，那么服务器就会被标记为down状态。backup：一旦其他服务器宕机，那么有该标记的机器就会接收请求。down：标记为一个服务器不再接受任何请求。 1.2.1. 负载均衡算法 upstream模块能够使用轮询、IP hash和最少连接数三种负载均衡算法之一来选择哪个上游服务器将会被在下一步中连接。 1.2.1.1. 轮询 默认情况使用轮询，不需要配置指令来设置，该算法选择下一个服务器，基于先前选择，再配置文件中哪一个是下一个服务器，以及每个服务器的负载。轮询算法是基于在队列中谁是下一个的原理确保将访问量均匀的分配给每一个上游服务器。 1.2.1.2. IP 哈希 通过ip_hash指令激活使用，从而将某些IP地址映射到同一个上游服务器。 1.2.1.3. 最少连接数 通过least_conn指令启用，该算法通过选择一个活跃的最少连接数服务器，然后将负载均匀分配给上游服务器。如果上游服务器的处理器能力不同，那么可以为server指令使用weight来指示说明。该算法将考虑到不同服务器的加权最小连接数。 2. Upstream服务器类型 上游服务器是Ngixn代理连接的一个服务器，可以是物理机或虚拟机。 2.1. 单个upstream服务器 指令try_files(包括http core模块内)意味着按顺序尝试，直到找到一个匹配为止。Nginx将会投递与客户端给定URI匹配的任何文件，如果没有找到任何配置文件，将会把请求代理到Apache作进一步处理。 2.2. 多个upstream服务器 Nginx将会通过轮询的方式将连续请求传递给3个上游服务器。这样应用程序不会过载。 图片 - 这里写图片描述 3. 负载均衡特别说明 如果客户端希望总是访问同一个上游服务器，可以使用ip_hash指令； 如果请求响应时间长短不一，可以使用least_conn指令； 默认为轮询。 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 18:02:10 "},"nginx/nginx-http.html":{"url":"nginx/nginx-http.html","title":"Nginx http服务器","keywords":"","body":"1. Nginx的系统架构 Nginx包含一个单一的master进程和多个worker进程，每个进程都是单进程，并且设计为同时处理成千上万个连接。 worker进程是处理连接的地方，Nginx使用了操作系统事件机制来快速响应这些请求。 master进程负责读取配置文件、处理套接字、派生worker进程、打开日志文件和编译嵌入式的perl脚本。master进程是一个可以通过处理信号量来管理请求的进程。 worker进程运行在一个忙碌的事件循环处理中，用于处理进入的连接。每一个nginx模块被构筑在worker中。任何请求处理、过滤、处理代理的连接和更多操作都在worker中完成。 如果没有阻塞worker进程的进程（例如磁盘I/O），那么需要配置的worker进程要多于CPU内核数，以便处理负载。 2. Http核心模块 2.1.1. server 指令server开始一个新的上下文（context）。 http server指令 指令 说明 port_in_redirect 确认nginx是否对端口指定重定向 server 创建一个新的配置区域，定义一个虚拟主机。listen指令指定IP和端口；server_name列举用于匹配的Host头值 server_name 配置用于响应请求的虚拟主机名称 server_name_in_redirect server_tokens 在错误信息中禁止发送nginx的版本号和server响应头 2.1.2. 日志格式 参数 说明 示例 $remote_addr 客户端地址 211.28.65.253 $remote_user 客户端用户名称 -- $time_local 访问时间和时区 18/Jul/2012:17:00:01 +0800 $request 请求的URI和HTTP协议 \"GET /article-10000.html HTTP/1.1\" $http_host 请求地址，即浏览器中你输入的地址（IP或域名） www.it300.com192.168.100.100 $status HTTP请求状态 200 $upstream_status upstream状态 200 $body_bytes_sent 发送给客户端文件内容大小 1547 $http_referer url跳转来源 https://www.baidu.com/ $http_user_agent 用户终端浏览器等信息 \"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; SV1; GTB7.0; .NET4.0C; $ssl_protocol SSL协议版本 TLSv1 $ssl_cipher 交换数据中的算法 RC4-SHA $upstream_addr 后台upstream的地址，即真正提供服务的主机地址 10.10.10.100:80 $request_time 整个请求的总时间 0.205 $upstream_response_time 请求过程中，upstream响应时间 0.002 日志切割 # vim /etc/logrotate.d/nginx /usr/local/nginx/logs/*.log{ #指定转储周期为每天 daily #保留30个备份 rotate 30 #需要压缩 delaycompress #YYYYMMDD日期格式 dateext #忽略错误 missingok #如果日志为空则不做轮询 notifempty #只为整个日志组运行一次的脚本 sharedscripts #日志轮询后执行的脚本 postrotate service nginx reload endscript } Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:57:42 "},"keepalived/keepalived-introduction.html":{"url":"keepalived/keepalived-introduction.html","title":"Keepalived简介","keywords":"","body":"1. Keepalived简介 1.1. 概述 Keepalived一个基于VRRP协议来实现的LVS服务高可用方案，可以利用其来避免单点故障。一个LVS服务会有2台服务器运行Keepalived，一台为主服务器（MASTER），一台为备份服务器（BACKUP），但是对外表现为一个虚拟IP，主服务器会发送特定的消息给备份服务器，当备份服务器收不到这个消息的时候，即主服务器宕机的时候， 备份服务器就会接管虚拟IP，继续提供服务，从而保证了高可用性。 1.2. keepalived的作用 Keepalived的作用是检测服务器的状态，如果有一台web服务器死机，或工作出现故障，Keepalived将检测到，并将有故障的服务器从系统中剔除，同时使用其他服务器代替该服务器的工作，当服务器工作正常后Keepalived自动将服务器加入到服务器群中。 2. 如何实现Keepalived 2.1. 基于VRRP协议的理解 Keepalived是以VRRP协议为实现基础的，VRRP全称Virtual Router Redundancy Protocol，即虚拟路由冗余协议。 虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，master上面有一个对外提供服务的vip（该路由器所在局域网内其他机器的默认路由为该vip），master会发组播，当backup收不到vrrp包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。 keepalived主要有三个模块，分别是core、check和vrrp。core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。check负责健康检查，包括常见的各种检查方式。vrrp模块是来实现VRRP协议的。 2.2. 基于TCP/IP协议的理解 Layer3,4&7工作在IP/TCP协议栈的IP层，TCP层，及应用层,原理分别如下： Layer3： Keepalived使用Layer3的方式工作式时，Keepalived会定期向服务器群中的服务器发送一个ICMP的数据包（既我们平时用的Ping程序）,如果发现某台服务的IP地址没有激活，Keepalived便报告这台服务器失效，并将它从服务器群中剔除，这种情况的典型例子是某台服务器被非法关机。Layer3的方式是以服务器的IP地址是否有效作为服务器工作正常与否的标准。 Layer4: 如果您理解了Layer3的方式，Layer4就容易了。Layer4主要以TCP端口的状态来决定服务器工作正常与否。如web server的服务端口一般是80，如果Keepalived检测到80端口没有启动，则Keepalived将把这台服务器从服务器群中剔除。 Layer7： Layer7就是工作在具体的应用层了，比Layer3,Layer4要复杂一点，在网络上占用的带宽也要大一些。Keepalived将根据用户的设定检查服务器程序的运行是否正常，如果与用户的设定不相符，则Keepalived将把服务器从服务器群中剔除。 3. Keepalived选举策略 3.1. 选举策略 首先，每个节点有一个初始优先级，由配置文件中的priority配置项指定，MASTER节点的priority应比BAKCUP高。运行过程中keepalived根据vrrp_script的weight设定，增加或减小节点优先级。规则如下： “weight”值为正时,脚本检测成功时”weight”值会加到”priority”上,检测失败是不加 主失败: 主priority 主成功: 主priority+weight之和>备priority+weight之和时,主依然为主,即不发生切换 “weight”为负数时,脚本检测成功时”weight”不影响”priority”,检测失败时,Master节点的权值将是“priority“值与“weight”值之差 主失败: 主priotity-abs(weight) 主成功: 主priority > 备priority 不切换 当两个节点的优先级相同时，以节点发送VRRP通告的IP作为比较对象，IP较大者为MASTER。 3.2. priority和weight的设定 主从的优先级初始值priority和变化量weight设置非常关键，配错的话会导致无法进行主从切换。比如，当MASTER初始值定得太高，即使script脚本执行失败，也比BACKUP的priority + weight大，就没法进行VIP漂移了。 所以priority和weight值的设定应遵循: abs(MASTER priority - BAKCUP priority) Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2019-03-05 14:55:59 "},"keepalived/install-keepalived.html":{"url":"keepalived/install-keepalived.html","title":"Keepalived的安装与配置","keywords":"","body":"1. Keepalived的安装 1.1. yum install方式 yum install -y keepalived 1.2. 安装包编译方式 更多安装包参考：http://www.keepalived.org/download.html wget http://www.keepalived.org/software/keepalived-2.0.7.tar.gz tar zxvf keepalived-2.0.7.tar.gz cd keepalived-2.0.7 ./configure --bindir=/usr/bin --sbindir=/usr/sbin --sysconfdir=/etc --mandir=/usr/share make && make install 2. 常用配置 keepalived配置文件路径：/etc/keepalived/keepalived。 2.1. MASTER（主机配置） global_defs { router_id proxy-keepalived } vrrp_script check_nginx { script \"/etc/keepalived/scripts/check_nginx.sh\" interval 3 weight 2 } vrrp_instance VI_1 { state BACKUP interface eth2 virtual_router_id 15 priority 100 advert_int 1 authentication { auth_type PASS auth_pass xxx } track_script { check_nginx } virtual_ipaddress { 180.101.115.139 218.98.38.29 } nopreempt notify_master \"/etc/keepalived/keepalived_notify.sh master\" notify_backup \"/etc/keepalived/keepalived_notify.sh backup\" notify_fault \"/etc/keepalived/keepalived_notify.sh fault\" notify_stop \"/etc/keepalived/keepalived_notify.sh stop\" } 2.2. BACKUP（备机配置） global_defs { router_id proxy-keepalived } vrrp_script check_nginx { script \"/etc/keepalived/scripts/check_nginx.sh\" interval 3 weight 2 } vrrp_instance VI_1 { state BACKUP interface eth2 virtual_router_id 15 priority 99 advert_int 1 authentication { auth_type PASS auth_pass xxx } track_script { check_nginx } virtual_ipaddress { 180.101.115.139 218.98.38.29 } nopreempt notify_master \"/etc/keepalived/keepalived_notify.sh master\" notify_backup \"/etc/keepalived/keepalived_notify.sh backup\" notify_fault \"/etc/keepalived/keepalived_notify.sh fault\" notify_stop \"/etc/keepalived/keepalived_notify.sh stop\" } 3. 注意事项 1、指定Nginx健康检测脚本：/etc/keepalived/scripts/check_nginx.sh 2、主备配置差别主要为（建议这么配置）： 以下两种方式的配置，当其中一台机器keepalived挂掉后会自动VIP切到另一台机器，当挂掉机器keepalived恢复后不会抢占VIP，该方式可以避免机器恢复再次切VIP所带来的影响。 主机:(state BACKUP;priority 100) 备机：(state BACKUP;priority 99) 非抢占：nopreempt 或者： 主机:(state MASTER;priority 100) 备机：(state BACKUP;priority 100) 默认抢占 3、指定VIP virtual_ipaddress { 180.101.115.139 218.98.38.29 } 4、可以指定为非抢占：nopreempt，即priority高不会抢占已经绑定VIP的机器。 5、制定绑定IP的网卡： interface eth2 6、可以指定keepalived状态变化通知 notify_master \"/etc/keepalived/keepalived_notify.sh master\" notify_backup \"/etc/keepalived/keepalived_notify.sh backup\" notify_fault \"/etc/keepalived/keepalived_notify.sh fault\" notify_stop \"/etc/keepalived/keepalived_notify.sh stop\" 7、virtual_router_id 15值，主备值一致，但建议不应与集群中其他Nginx机器上的相同，如果同一个网段配置的virtual_router_id 重复则会报错，选择一个不重复的0~255之间的值，可以用以下命令查看已存在的vrid。 tcpdump -nn -i any net 224.0.0.0/8 4. 常用脚本 4.1. Nginx健康检测脚本 在Nginx配置目录下（/etc/nginx/conf.d/）增加health.conf的配置文件,该配置文件用于配置Nginx health的接口。 server { listen 80 default_server; server_name localhost; default_type text/html; return 200 'Health'; } Nginx健康检测脚本：/etc/keepalived/scripts/check_nginx.sh 4.1.1. 检查接口调用是否为200 #!/bin/sh set -x timeout=30 #指定默认30秒没返回200则为非健康，该值可根据实际调整 if [ -n ${timeout} ];then httpcode=`curl -sL -w %{http_code} -m ${timeout} http://localhost -o /dev/null` else httpcode=`curl -sL -w %{http_code} http://localhost -o /dev/null` fi if [ ${httpcode} -ne 200 ];then echo `date`': nginx is not healthy, return http_code is '${httpcode} >> /etc/keeperalived/keepalived.log killall keepalived exit 1 else exit 0 fi 4.1.2. 检查Nginx进程是否运行 #!/bin/sh if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then echo \"$(date) nginx pid not found\">>/etc/keepalived/keepalived.log killall keepalived fi 4.2. Keepalived状态通知脚本 #!/bin/bash set -x warn_receiver=$1 ip=$(ifconfig bond0|grep inet |awk '{print $2}') warningInfo=\"${ip}_keepalived_changed_status_to_$1\" warn-report --user admin --key=xxxx --target=${warn_receiver} ${warningInfo} echo $(date) $1 >> /etc/keepalived/status 说明： ip获取本机IP，本例中IP获取是bond0的IP，不同机器网卡名称不同需要修改为对应网卡名称。 告警工具根据自己指定。 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2019-03-25 17:53:29 "},"keepalived/keepalived-operation.html":{"url":"keepalived/keepalived-operation.html","title":"Keepalived的相关操作","keywords":"","body":"1. 常用命令 1.1. 查看当前VIP在哪个节点上 # 查看VIP是否在筛选结果中 ip addr show|grep \"scope global\" # 或者 ip addr show|grep {vip} 1.2. 查看keepalived的日志 tail /var/log/messages 1.3. 抓包命令 # 抓包 tcpdump -nn vrrp # 可以用这条命令来查看该网络中所存在的vrid tcpdump -nn -i any net 224.0.0.0/8 # tcpdump -nn -i any net 224.0.0.0/8 # tcpdump -nn vrrp tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes 14:40:00.576387 IP 192.168.98.57 > 224.0.0.18: VRRPv2, Advertisement, vrid 9, prio 99, authtype simple, intvl 1s, length 20 14:40:01.577605 IP 192.168.98.57 > 224.0.0.18: VRRPv2, Advertisement, vrid 9, prio 99, authtype simple, intvl 1s, length 20 14:40:02.578429 IP 192.168.98.57 > 224.0.0.18: VRRPv2, Advertisement, vrid 9, prio 99, authtype simple, intvl 1s, length 20 14:40:03.579605 IP 192.168.98.57 > 224.0.0.18: VRRPv2, Advertisement, vrid 9, prio 99, authtype simple, intvl 1s, length 20 14:40:04.580443 IP 192.168.98.57 > 224.0.0.18: VRRPv2, Advertisement, vrid 9, prio 99, authtype simple, intvl 1s, length 20 1.4. VIP操作 # 解绑VIP ip addr del dev # 绑定VIP ip addr add dev 1.5. keepalived 切 VIP 例如将 A 机器上的 VIP 迁移到B 机器上。 1.5.1. 停止keepalived服务 停止被迁移的机器（A机器）的keepalived服务。 systemctl stop keepalived 1.5.2. 查看日志 解绑 A机器 VIP的日志 Sep 19 14:28:09 localhost systemd: Stopping LVS and VRRP High Availability Monitor... Sep 19 14:28:09 localhost Keepalived[45705]: Stopping Sep 19 14:28:09 localhost Keepalived_vrrp[45707]: VRRP_Instance(twemproxy) sent 0 priority Sep 19 14:28:09 localhost Keepalived_vrrp[45707]: VRRP_Instance(twemproxy) removing protocol VIPs. Sep 19 14:28:09 localhost Keepalived_healthcheckers[45706]: Stopped Sep 19 14:28:10 localhost Keepalived_vrrp[45707]: Stopped Sep 19 14:28:10 localhost Keepalived[45705]: Stopped Keepalived v1.3.5 (03/19,2017), git commit v1.3.5-6-g6fa32f2 Sep 19 14:28:10 localhost systemd: Stopped LVS and VRRP High Availability Monitor. Sep 19 14:28:10 localhost ntpd[1186]: Deleting interface #10 bond0, 192.168.99.9#123, interface stats: received=0, sent=0, dropped=0, active_time=6755768 secs 绑定 B 机器 VIP的日志 Sep 17 17:20:25 localhost systemd: Starting LVS and VRRP High Availability Monitor... Sep 17 17:20:26 localhost Keepalived[34566]: Starting Keepalived v1.3.5 (03/19,2017), git commit v1.3.5-6-g6fa32f2 Sep 17 17:20:26 localhost Keepalived[34566]: Opening file '/etc/keepalived/keepalived.conf'. Sep 17 17:20:26 localhost Keepalived[34568]: Starting Healthcheck child process, pid=34569 Sep 17 17:20:26 localhost Keepalived[34568]: Starting VRRP child process, pid=34570 Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: Registering Kernel netlink reflector Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: Registering Kernel netlink command channel Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: Registering gratuitous ARP shared channel Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: Opening file '/etc/keepalived/keepalived.conf'. Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: Truncating auth_pass to 8 characters Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: VRRP_Instance(twemproxy) removing protocol VIPs. Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: Using LinkWatch kernel netlink reflector... Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: VRRP_Instance(twemproxy) Entering BACKUP STATE Sep 17 17:20:26 localhost Keepalived_vrrp[34570]: VRRP sockpool: [ifindex(4), proto(112), unicast(0), fd(10,11)] Sep 17 17:20:26 localhost systemd: Started LVS and VRRP High Availability Monitor. Sep 17 17:20:26 localhost kernel: IPVS: Registered protocols (TCP, UDP, SCTP, AH, ESP) Sep 17 17:20:26 localhost kernel: IPVS: Connection hash table configured (size=4096, memory=64Kbytes) Sep 17 17:20:26 localhost kernel: IPVS: Creating netns size=2192 id=0 Sep 17 17:20:26 localhost kernel: IPVS: Creating netns size=2192 id=1 Sep 17 17:20:26 localhost kernel: IPVS: ipvs loaded. Sep 17 17:20:26 localhost Keepalived_healthcheckers[34569]: Opening file '/etc/keepalived/keepalived.conf'. 2. 指定keepalived的输出日志文件 2.1. 修改 /etc/sysconfig/keepalived 将KEEPALIVED_OPTIONS=\"-D\"改为KEEPALIVED_OPTIONS=\"-D -d -S 0\"。 # Options for keepalived. See `keepalived --help' output and keepalived(8) and # keepalived.conf(5) man pages for a list of all options. Here are the most # common ones : # # --vrrp -P Only run with VRRP subsystem. # --check -C Only run with Health-checker subsystem. # --dont-release-vrrp -V Dont remove VRRP VIPs & VROUTEs on daemon stop. # --dont-release-ipvs -I Dont remove IPVS topology on daemon stop. # --dump-conf -d Dump the configuration data. # --log-detail -D Detailed log messages. # --log-facility -S 0-7 Set local syslog facility (default=LOG_DAEMON) # KEEPALIVED_OPTIONS=\"-D -d -S 0\" 2.2. 修改rsyslog的配置 /etc/rsyslog.conf 在/etc/rsyslog.conf 添加 keepalived的日志路径 vi /etc/rsyslog.conf ... # keepalived log local0.* /etc/keepalived/keepalived.log 2.3. 重启rsyslog和keepalived # 重启rsyslog systemctl restart rsyslog # 重启keepalived systemctl restart keepalived 3. Troubleshooting 3.1. virtual_router_id 同网段重复 日志报错如下： Mar 09 21:28:28 k8s4 Keepalived_vrrp[8548]: bogus VRRP packet received on eth0 !!! Mar 09 21:28:28 k8s4 Keepalived_vrrp[8548]: VRRP_Instance(VI-kube-master) ignoring received advertisment... Mar 09 21:28:43 k8s4 Keepalived_vrrp[8548]: ip address associated with VRID not present in received packet : 192.168.1.10 Mar 09 21:28:43 k8s4 Keepalived_vrrp[8548]: one or more VIP associated with VRID mismatch actual MASTER advert 解决方法: 同一网段内LB节点配置的 virtual_router_id 值有重复了，选择一个不重复的0~255之间的值，可以用以下命令查看已存在的vrid。 tcpdump -nn -i any net 224.0.0.0/8 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2019-03-25 17:41:22 "},"keepalived/keepalived-conf.html":{"url":"keepalived/keepalived-conf.html","title":"Keepalived的配置详解","keywords":"","body":"详细配置说明 keepalived只有一个配置文件/etc/keepalived/keepalived.conf。 里面主要包括以下几个配置区域，分别是: global_defs static_ipaddress static_routes vrrp_script vrrp_instance virtual_server 1. global_defs区域 主要是配置故障发生时的通知对象以及机器标识。 global_defs { notification_email { # notification_email 故障发生时给谁发邮件通知 a@abc.com b@abc.com ... } notification_email_from alert@abc.com # notification_email_from 通知邮件从哪个地址发出 smtp_server smtp.abc.com # smpt_server 通知邮件的smtp地址 smtp_connect_timeout 30 # smtp_connect_timeout 连接smtp服务器的超时时间 enable_traps # enable_traps 开启SNMP陷阱（Simple Network Management Protocol） router_id host163 # router_id 标识本节点的字条串，通常为hostname，但不一定非得是hostname。故障发生时，邮件通知会用到。 } 2. static_ipaddress和static_routes区域[可忽略] static_ipaddress和static_routes区域配置的是是本节点的IP和路由信息。如果你的机器上已经配置了IP和路由，那么这两个区域可以不用配置。其实，一般情况下你的机器都会有IP地址和路由信息的，因此没必要再在这两个区域配置。 static_ipaddress { 10.210.214.163/24 brd 10.210.214.255 dev eth0 ... } static_routes { 10.0.0.0/8 via 10.210.214.1 dev eth0 ... } 3. vrrp_script区域 用来做健康检查的，当时检查失败时会将vrrp_instance的priority减少相应的值。 vrrp_script chk_http_port { script \" 4. vrrp_instance和vrrp_sync_group区域 vrrp_instance用来定义对外提供服务的VIP区域及其相关属性。 vrrp_rsync_group用来定义vrrp_intance组，使得这个组内成员动作一致。 vrrp_sync_group VG_1 { #监控多个网段的实例 group { inside_network # name of vrrp_instance (below) outside_network # One for each moveable IP. ... } notify_master /path/to_master.sh # notify_master表示切换为主机执行的脚本 notify_backup /path/to_backup.sh # notify_backup表示切换为备机师的脚本 notify_fault \"/path/fault.sh VG_1\" # notify_fault表示出错时执行的脚本 notify /path/notify.sh # notify表示任何一状态切换时都会调用该脚本，且在以上三个脚本执行完成之后进行调用 smtp_alert # smtp_alert 表示是否开启邮件通知（用全局区域的邮件设置来发通知） } vrrp_instance VI_1 { state MASTER # state MASTER或BACKUP，当其他节点keepalived启动时会将priority比较大的节点选举为MASTER，因此该项其实没有实质用途。 interface eth0 # interface 节点固有IP（非VIP）的网卡，用来发VRRP包 use_vmac dont_track_primary # use_vmac 是否使用VRRP的虚拟MAC地址，dont_track_primary 忽略VRRP网卡错误（默认未设置） track_interface {# track_interface 监控以下网卡，如果任何一个不通就会切换到FALT状态。（可选项） eth0 eth1 } #mcast_src_ip 修改vrrp组播包的源地址，默认源地址为master的IP mcast_src_ip lvs_sync_daemon_interface eth1 #lvs_sync_daemon_interface 绑定lvs syncd的网卡 garp_master_delay 10 # garp_master_delay 当切为主状态后多久更新ARP缓存，默认5秒 virtual_router_id 1 # virtual_router_id 取值在0-255之间，用来区分多个instance的VRRP组播， 同一网段中virtual_router_id的值不能重复，否则会出错 priority 100 #priority用来选举master的，根据服务是否可用，以weight的幅度来调整节点的priority，从而选取priority高的为master，该项取值范围是1-255（在此范围之外会被识别成默认值100） advert_int 1 # advert_int 发VRRP包的时间间隔，即多久进行一次master选举（可以认为是健康查检时间间隔） authentication { # authentication 认证区域，认证类型有PASS和HA（IPSEC），推荐使用PASS（密码只识别前8位） auth_type PASS #认证方式 auth_pass 12345678 #认证密码 } virtual_ipaddress { # 设置vip 10.210.214.253/24 brd 10.210.214.255 dev eth0 192.168.1.11/24 brd 192.168.1.255 dev eth1 } virtual_routes { # virtual_routes 虚拟路由，当IP漂过来之后需要添加的路由信息 172.16.0.0/12 via 10.210.214.1 192.168.1.0/24 via 192.168.1.1 dev eth1 default via 202.102.152.1 } track_script { chk_http_port } nopreempt # nopreempt 允许一个priority比较低的节点作为master，即使有priority更高的节点启动 preempt_delay 300 # preempt_delay master启动多久之后进行接管资源（VIP/Route信息等），并提是没有nopreempt选项 debug notify_master| notify_backup| notify_fault| notify| smtp_alert } 5. virtual_server_group和virtual_server区域 virtual_server_group一般在超大型的LVS中用到，一般LVS用不到这东西。 virtual_server IP Port { delay_loop # delay_loop 延迟轮询时间（单位秒） lb_algo rr|wrr|lc|wlc|lblc|sh|dh # lb_algo 后端调试算法（load balancing algorithm） lb_kind NAT|DR|TUN # lb_kind LVS调度类型NAT/DR/TUN persistence_timeout #会话保持时间 persistence_granularity #lvs会话保持粒度 protocol TCP #使用的协议 ha_suspend virtualhost # virtualhost 用来给HTTP_GET和SSL_GET配置请求header的 alpha omega quorum hysteresis quorum_up| quorum_down| sorry_server #备用机，所有realserver失效后启用 real_server{ # real_server 真正提供服务的服务器 weight 1 # 默认为1,0为失效 inhibit_on_failure #在服务器健康检查失效时，将其设为0，而不是直接从ipvs中删除 notify_up| # real server宕掉时执行的脚本 notify_down| # real server启动时执行的脚本 # HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|MISC_CHECK TCP_CHECK { connect_timeout 3 #连接超时时间 nb_get_retry 3 #重连次数 delay_before_retry 3 #重连间隔时间 connect_port 23 #健康检查的端口的端口 bindto } HTTP_GET|SSL_GET { url {# 检查url，可以指定多个 path # path 请求real serserver上的路径 digest # 用genhash算出的摘要信息 status_code # 检查的http状态码 } connect_port # connect_port 健康检查，如果端口通则认为服务器正常 connect_timeout # 超时时长 nb_get_retry # 重试次数 delay_before_retry # 下次重试的时间延迟 } SMTP_CHECK { host { connect_ip connect_port #默认检查25端口 bindto } connect_timeout 5 retry 3 delay_before_retry 2 helo_name | #smtp helo请求命令参数，可选 } MISC_CHECK { misc_path | #外部脚本路径 misc_timeout #脚本执行超时时间 misc_dynamic #如设置该项，则退出状态码会用来动态调整服务器的权重，返回0 正常，不修改；返回1， #检查失败，权重改为0；返回2-255，正常，权重设置为：返回状态码-2 } } } Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-09-23 17:44:10 "},"tcpip/tcpip-basics.html":{"url":"tcpip/tcpip-basics.html","title":"TCP/IP基础","keywords":"","body":"1. 基础知识 1.1. 协议 计算机与网络设备要相互通信，必须基于相同的方法。比如，如何探测到通信目标，使用哪种语言通信，如何结束通信等规则要事先确定。 不同硬件，操作系统之间的通信都需要一种规则，我们将这种事先约定好的规则称之为协议。 1.2. 地址 地址：在某一范围内确认的唯一标识符，即数据包传到某一个范围，需要有一个明确唯一的目标地址。 类型 层 地址 说明 端口号 传输层 程序地址 同一个计算机中不同的应用程序 IP地址 网络层 主机地址 识别TCP/IP网络中不同的主机或路由器 MAC地址 数据链路层 物理地址 在同一个数据链路中识别不同的计算机 1.3. 网络构成 构成要素 说明 网卡 连入网络必须使用网卡，又称网络接口卡。 中继器 OSI第1层，物理层上延长网络的设备，将电缆的信号放大传给另一个电缆。 网桥/2层交换机 OSI第2层，数据链路层面上连接两个网络的设备，识别数据帧的内容并转发给相邻的网段，根据MAC地址进行处理。 路由器/3层交换机 OSI第3层，网络层面连接两个网络并对分组报文进行转发，根据IP进行处理。 4-7层交换机 传输层到应用层，以TCP等协议分析收发数据，负载均衡器就是其中一种。 网关 对传输层到应用层的数据进行转换和转发的设备，通常会使用表示层或应用层的网关来处理不同协议之间的翻译和通信，代理服务器（proxy）就是应用网关的一种。 2. OSI与TCP/IP参考模型 2.1. OSI与TCP/IP参考模型图 2.2. OSI参考模型分层说明 2.3. OSI参考模型通信过程 1、打包数据时，每一层在处理上一层传过来的数据时，会在数据上附上当前层的首部信息后传给下一层； 2、解包数据时，每一层在处理下一层传过来的数据时，会将当前层的首部信息与数据分开，将数据传给上一层。 3、数据通信过程 分层 每层的操作 应用层 在数据前面加首部，首部包括数据内容、源地址和目标地址，同时也会处理异常的反馈信息。 表示层 将特有的数据格式转换为通用的数据格式，同时也会加上表示层的首部信息以供解析。 会话层 对何时连接，以何种方式连接，连接多久，何时断开等做记录。同时也会加会话层的首部信息。 传输层 建立连接，断开连接，确认数据是否发送成功和执行失败重发任务。 网络层 负责将数据发到目标地址，也包含首部信息。 数据链路层 通过物理的传输介质实现数据的传输。 物理层 将0/1转换成物理的传输介质，通过MAC地址进行传输。 2.4. TCP/IP应用层协议 2.4.1. 通信模型 2.4.2. 应用层协议说明 应用类型 协议 协议说明 WWW HTTP,HTML 电子邮件 SMTP，MIME 文件传输 FTP 远程登录 TELNET,SSH 网络管理 SNMP,MIB 3. TCP/IP通信过程 3.1. 数据包结构 3.2. 数据打包和解包过程 3.2.1. 包的封装 3.2.2. 发送与接收 3.3. 数据包传输过程 文章： 《图解TCP/IP》 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-10-27 16:30:09 "},"tcpip/ip.html":{"url":"tcpip/ip.html","title":"IP协议","keywords":"","body":"1. IP基础 TCP/IP的心脏是互联网层，这一层主要有IP和ICMP两个协议组成，在OSI参考模型中为第三层（网络层）。网络层的主要作用是实现终端节点之间的通信（点对点通信）。 1.1. 网络层与数据链路层的关系 图片 - 这里写图片描述 1.2. IP寻址 IP地址用于在“连接到网络中的所有主机中识别出进行通信的目标地址”。因此TCP/IP通信中所有主机或路由器必须设定自己的IP地址（每块网卡至少配置一个或以上的IP地址）。 图片 - 这里写图片描述 1.3. 路由控制 路由控制是指将分组数据发送到最终目标地址的功能。 图片 - 这里写图片描述 IP数据包类似快递中的包裹，送货车类似数据链路，包裹依赖送货车承载转运，而一辆送货车只能将包裹送到某个区间内，由新的快递点安排新的送货车来进行下一区间的运输。 图片 - 这里写图片描述 1.3.1. 路由控制表 为了将数据包发给目标主机，所有主机都维护一张路由控制表（Routing Table）,该表记录IP数据在下一步应该发给哪个路由器。IP包根据这个路由表在各个数据链路上传输。 图片 - 这里写图片描述 1.4. 数据链路的抽象化 IP是实现多个数据链路之间通信的协议。对不同数据链路的相异特性进行抽象化也是IP的重要作用之一。不同数据链路最大的区别在于它们各自的最大传输单位（MTU）不同，类似快递包裹有各自的大小限制。当数据包过大时，IP进行分片处理，即将大的IP包分成多个较小的IP包，当到目标地址后再被组合起来传给上一层。 1.5. IP是面向无连接型 IP发包之前不需要提前与目标建立连接。采用面向无连接的原因：为了简化和提速。面向连接型需要提前建立连接会降低处理速度。IP只负责将数据发给目标主机，但途中可能会发生丢包、错位、数据量翻倍等问题。TCP则是面向连接的协议，负责保证对端主机确实收到数据。 2. IP地址 在TCP/IP通信中，用IP地址识别主机和路由器。 2.1. IP地址的定义 IP地址（IPv4地址）由32位正整数来表示。IP地址在计算机内部以二进制方式被处理，但习惯将32位的IP地址以8位为一组，分成4组，每组以“.”隔开，转换成10进制来表示。IPv4地址为32位，最多允许43亿台计算机连接网络。 实际上，IP地址并非根据主机台数来分配而是每一台主机上的每一块网卡都得设置IP地址，一块网卡可以设置一个或以上个IP,路由器通常会配置两个以上的网卡。 2.2. IP地址由网络和主机两部分标识组成 IP地址由“网络地址”和“主机地址”两部分组成。 网络标识在数据链路的每个段配置不同的值，必须保证相互连接的每个段的地址不重复，相同段内连接的主机必须有相同的网络地址。主机标识则不允许同一个网段内重复出现。在某一范围内，IP地址需具有唯一性。 图片 - 这里写图片描述 IP包被转发到某个路由器时，是利用目标IP地址的网络标识进行路由，即使不看主机地址，由网络地址则可判断是否是该网段内的主机。 图片 - 这里写图片描述 2.3. IP地址的分类 IP地址分为A、B、C、D四类。 IP地址类别 地址开头 网络地址 主机地址 范围 一个网段内主机地址个数 备注 A类地址 0 第1-8位 后24位 0.0.0.0~127.0.0.0 2^24-2=16777214 B类地址 10 第1-16位 后16位 128.0.0.0~191.255.0.0 2^16-2=65534 C类地址 110 第1-24位 后8位 192.0.0.0~239.255.255.0 2^8-2=254 D类地址 1110 第1-32位 没有主机地址 224.0.0.0~239.255.255.255 常用于多播 注意：同一个网段中的主机地址分配，主机地址全为0表示对应的网络地址，主机地址全为1通常用于广播地址。因此一个网段内主机的个数去掉2个（例如2^8-2=254）。 图片 - 这里写图片描述 2.4. 子网隐码 用1表示网络地址的范围，用0表示主机地址的访问。因此A、B、C类可表示为 IP类别 表示 A类 255.0.0.0 B类 255.255.0.0 C类 255.255.255.0 按照以上的组合方式IP有点浪费，因此产生子网隐码的分类方法减少这种浪费。 引入子网后，IP地址由两种识别码组成：IP地址本身+表示网络地址的子网隐码。即将A,B,C类中的主机地址拆成网络部分和主机部分，重新分配网络地址和主机地址。子网隐码同样是用1表示网络地址的范围，用0表示主机地址的访问。 2.4.1. 子网隐码的表示方法 表示方法 地址 子网隐码 备注 数字 IP地址 172.20.100.52 255.255.255.192 网络地址 172.20.100.0 255.255.255.192 广播地址 172.20.100.63 255.255.255.192 “/26”，表示前26位为网络地址 IP地址 172.20.100.52/26 网络地址 172.20.100.0/26 广播地址 172.20.100.63/26 图片 - 这里写图片描述 3. 路由控制 发送数据包除了有目标IP地址外，还需要指明路由器和主机的信息，即路由控制表。 路由控制表的形成方式有两种： 1、静态路由 由管理员手动设置 2、动态路由 路由器与其他路由器相互交互信息时自动刷新。为了让动态路由及时刷新路由表，在网络上互联的路由器之间需设置路由协议，保证正常读取路由控制信息。 3.1. IP地址和路由控制 图片 - 这里写图片描述 IP地址的网络地址部分用于进行路由控制。路由控制表中记录着网络地址与下一步应该发送至路由器的地址。在发送IP包时，首先确认IP包首部中的目标地址，再从路由控制表中找到与该地址具有相同网络地址的记录，根据该记录将IP包转发给相应的下一个路由器。如果存在多条相同网络地址的记录，则选择最为吻合的网络地址（相同位数最多）。例如：172.20.100.52的网络地址与172.20.0/16和172.20.100.0/24都匹配，则选择匹配最长的172.20.100.0/24。 3.1.1. 默认路由 默认路由一般标记为0.0.0.0/0或default。当路由表中没有任何一个地址与之匹配的记录，则使用默认路由。 3.1.2. 主机路由 “IP地址/32”也被称为主机路由，即整个IP地址的所有位都参与路由。进行主机路由意味着基于主机上网卡配置的IP地址本身而不是基于该地址的网络地址进行路由。一般用于不希望通过网络地址路由的情况。使用主机路由会导致路由表膨大，路由负荷增加，网络性能下降。 3.1.3. 环回地址 环回地址是在同一台计算机上程序之间进行网络通信时所使用的一个默认地址。即IP地址为127.0.0.1，主机名为localhost。 3.2. 路由控制表的聚合 路由信息的聚合可以有效的减少路由表的条目。路由表越大，管理它所需要的内存和CPU就越多，查找路由表的时间越长，导致转发IP包性能下降。要构建高性能网络就需要尽可能减少路由表的大小。 图片 - 这里写图片描述 4. IP首部信息 IP进行通信时，需要在数据前面加入IP首部信息，IP首部包含着用于IP协议进行发包控制时所有的必要信息。 4.1. IPv4首部 图片 - 这里写图片描述 字段 说明 大小 版本 标识IP首部的版本号，IPv4，即版本号为4 4比特 首部长度 表示IP首部的大小，单位为4字节 4比特 区分服务 表示服务质量 8比特 DSCP段与ECN段 DSCP用来进行质量控制，值越大优先度越高；ECN用来报告网络拥堵情况 2比特 总长度 表示IP首部与数据部分合起来的总字节数 16比特 标识 用于分片重组，同一个分片标识值相同，不同分片的标识值不同 16比特 标志 表示包被分片的相关信息 3比特 片偏移 用来标识被分片的每一个分段相对于原始数据的位置。 13比特 生存时间（TTL） 本意为包的生存期限，一般表示可以中转多少个路由器，每经过一个路由器TTL减1，直到变为0则丢弃该包 8比特 协议 表示IP首部的下一个首部隶属于哪个协议。 8比特 首部校验和 IP首部校验和，用来确保IP数据报不被破坏。 16比特 源地址 发送端IP地址 32比特 目标地址 接收端IP地址 32比特 可选项 安全级别、源路径、路径记录、时间戳 填充 填补物，调整大小使用 数据 存入数据 4.2. IPv6首部 图片 - 这里写图片描述 字段 说明 版本 IPv6,版本为6 通信量类 相当于IPv4的TOS（Type Of Service）字段 流标号 用于服务质量控制 有效载荷长度 包的数据部分 下一个首部 相当于IPv4的协议字段 跳数限制 Hop Limit，同IPv4的TTL,表示可通过的路由器个数 源地址 发送端的IP地址 目标地址 接收端的IP地址 参考 《图解TCP/IP》 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-10-27 16:32:23 "},"tcpip/tcp-udp.html":{"url":"tcpip/tcp-udp.html","title":"TCP与UDP协议","keywords":"","body":"1. 传输层的作用 1.1. 传输层的定义 IP首部有个协议字段，用来标识传输层协议，识别数据是TCP的内容还是UDP的内容。同样，传输层，为了识别数据应该发给哪个应用也设定了这样的编号，即端口。 图片 - 这里写图片描述 1.2. 通信处理 应用协议大多以C/S形式运行，即服务端需提前启动服务，监听某个端口，当客户端往该端口发送数据时，可以及时处理请求。 服务端程序在UNIX系统中称为守护进程，例如HTTP的服务端程序为httpd；ssh的服务端程序为sshd。UNIX中不必要逐个启动这些守护进程，而是由超级守护进程inetd(互联网守护进程)启动，当收到客户端请求时会创建（fork）新的进程并转换（exec）为httpd等各个守护进程。根据请求端口分配到对应的服务端守护进程上处理。 图片 - 这里写图片描述 1.3. TCP和UDP 1.3.1. TCP TCP是面向连接、可靠的数据流。流就是不间断的数据结构，可理解为水管中的水流。虽然可以保证发送顺序，但犹如没有间隔的发送数据流给接收端。例如：发送10次100字节的消息，接收端可能会收到一个1000字节连续不断的数据。TCP为实现可靠传输，实行“顺序控制”和“重发控制”；还具备“流量控制”、“拥塞控制”、提高网络利用率等。TCP可以类比为“打电话”，有去有回。 1.3.2. UDP UDP是不具备可靠性的数据报协议，可以确保发送消息的大小，但不能保证消息一定到达，应用有时会根据自己的需要进行重发处理。UDP可以类比“发短信”，有去无回。 1.3.3. 套接字 应用在使用TCP或UDP时会用到系统提供的类库，即API（应用编程接口），通信时会用到套接字（socket）的API。应用程序利用套接字，可以设置对端的IP地址、端口号，并实现数据的发送与接收。 图片 - 这里写图片描述 2. 端口号 2.1. 端口号的定义 类别 地址 层 说明 端口号 程序地址 传输层 同一个计算机中不同的应用程序 IP地址 主机地址 网络层 识别TCP/IP网络中不同的主机或路由器 MAC地址 物理地址 数据链路层 在同一个数据链路中识别不同的计算机 把数据传输比作快递传递；IP地址就像你的家庭地址；那么端口号相当于你家具体的收件人；知道了家庭地址和收件人才能将快递准确送达。 2.2. 根据端口号识别应用 图片 - 这里写图片描述 图片 - 这里写图片描述 2.3. 通过IP地址、端口号、协议号进行通信 5个信息唯一标识一个通信：源地址IP、目标地址IP、协议号、源端口号、目标端口号。 图片 - 这里写图片描述 2.4. 端口号如何确定 2.4.1. 标准既定的端口号 该方法也叫静态方法，是指每个应用程序都有其指定的端口号。例如HTTP、FTP等应用协议使用的端口号，这类端口号称为知名端口号，一般由0-1023的数字分配而成。除知名端口号外，还有一些端口号也被正式注册，分布在1024-49151的数字之间。这些端口可用于任何通信用途。 2.4.2. 时序分配法 该方法也叫动态分配法，服务端有必要确定监听端口号，但接受服务的客户端没必要确定端口号。客户端可以不用自己设置端口号，由操作系统进行分配。操作系统为每个应用程序分配互不冲突的端口号。例如，新增一个端口号则在之前的端口号上加1，动态分配的端口号取值范围：49152-65535。 3. UDP UDP:User Datagram Protocol的缩写，提供面向无连接的通信服务，在应用程序发来数据收到那一刻则立即原样发送到网络上。即使出现丢包也不负责重发，包出现乱序也不能纠正。 UDP可以随时发送数据，本身处理简单高效，但不具备可靠性，适合以下场景： 包总量较少的通信（DNS、SNMP等） 视频、音频等多媒体通信（即使通信） 限定于LAN等特定网络中的应用通信 广播通信（广播、多播） 4. TCP TCP:Transmission Control Protocol (传输控制协议)，TCP实现了数据传输时的各种控制功能，可以进行丢包重发，乱序纠正，控制通信流量的浪费。 待续。。。 参考： 《图解TCP/IP》 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-10-27 16:30:50 "},"tcpip/http-basics.html":{"url":"tcpip/http-basics.html","title":"Http基础","keywords":"","body":"1. web及网络基础 1.1. 通过HTTP访问web[C/S] 1.2. TCP/IP四层模型 1.2.1. 数据包的封装 1.3. TCP/IP协议族 1.3.1. 负责传输的IP协议 使用ARP协议凭借MAC地址通信 1.3.2. 确保可靠的TCP协议 1.3.3. 负责域名解析的DNS服务 1.3.4. 各协议与HTTP的关系 1.4. URI与URL URI(Uniform Resource Identifier):统一资源标识符 URL(Uniform Resource Locator):统一资源定位符；URL是URI的子集 1.4.1. URI的格式 字段 说明 协议 http/https 登录信息（认证） user:pass@(一般没有) 服务器地址 域名或IP 服务器端口号 服务端口号，省略则取默认端口号 带层次的文件路径 指定服务器上的文件路径来定位特指的资源 查询字符串 使用查询字符串传入参数 片段标识符 标记以获取资源中的子资源（文档内的某个位置） 1.4.2. URI的示例 2. HTTP协议 2.1. 通过请求和响应的交换达成通信 2.1.1. 请求报文 2.1.2. 响应报文 2.2. HTTP请求方法 2.2.1. GET:获取资源 2.2.2. POST:传输实体主体 2.2.3. PUT:传输文件 PUT方法用来传输文件，像FTP协议一样，要求在请求报文的主体中包含文件内容，然后保存到请求URI指定的位置。 因为自身不带验证机制，有安全问题，因此一般不采用。若配合验证机制或者REST标准则可使用。 2.2.4. HEAD:获取报文头部 HEAD和GET一样但不返回报文主体部分，用于确认URI的有效性及资源的更新时间等。 2.2.5. DELETE:删除文件 DELETE与PUT作用相反，但不带安全验证机制一般不采用。 2.2.6. OPTIONS:询问支持的方法 OPTIONS用来查询针对请求URI指定的资源支持的方法 2.2.7. TRACE:追踪路径 TRACE用来查询发送出去的请求是怎样被加工修改/篡改的，因为易引发XST（跨站追踪）攻击，一般不使用。 2.2.8. CONNECT:要求用隧道协议连接代理 CONNECT要求在与代理服务器通信时建立隧道，实现用隧道协议进行TCP通信。主要使用SSL（Source Sockets Layer:安全套接字）和TLS（Transport Layer Security:传输层安全）协议把通信内容加密后经网络隧道传输。 方法格式如下： 2.3. 持久连接 2.3.1. keep-alive 为解决每进行一次HTTP通信就要断开一次TCP连接，增加了通信量的开销，HTTP/1.1通过keep-alive持久连接，只要任意一端没有明确提出断开连接，则保持TCP连接状态。 持久连接减少了TCP连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。 2.3.2. 管线化 持续连接使得多数请求以管线化（pipelining）方式发送成为可能。管线化即同时并行发送多个请求，而不需要一个接一个等待响应。管线化技术比持续连接速度快，请求数越多越明显。 2.3.3. 使用cookie的状态管理 HTTP是无状态协议，不对之前发生过的请求和响应的状态进行管理，即无法根据之前的状态进行本次的请求处理。无状态协议的优点在于不必保存状态，减少服务器CPU及内存资源的消耗。 cookie技术通过在请求和响应报文中写入cookie信息来控制客户端的状态。cookie会根据从服务端发送的响应报文内的一个叫做Set-Cookie的首部字段通知客户端保存Cookie；当客户端再往服务端发送请求时，客户端自动在请求报文中加入Cookie值后发送出去。服务器发现Cookie后会检查从哪个客户端发送来的连接请求，对比服务器上的记录，最后得到之前的状态信息。 参考： 《图解HTTP》 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-10-29 20:00:01 "},"tcpip/http-message.html":{"url":"tcpip/http-message.html","title":"Http报文","keywords":"","body":"3. HTTP报文 3.1. HTTP报文 用于HTTP协议交互的信息被称为HTTP报文，客户端的HTTP报文叫做请求报文，服务端的叫做响应报文。报文大致分为报文首部和报文主体，但并不一定要有报文主体。 图片 - img 3.2. 报文结构 图片 - img 图片 - img 字段 说明 请求行 请求方法，请求URI和HTTP版本 状态行 响应结果的状态码，原因短语和HTTP版本 首部字段 请求和响应的各种条件和属性的各类首部：通用首部、请求首部、响应首部、实体首部 其他 HTTP的RFC里未定义的首部（Cookie等） 3.3. 编码提升传输速率 HTTP在传输数据时可以按照数据原貌直接传输也可以在传输过程中编码提升传输速率；通过编码可以处理大量请求但会消耗更多的CPU等资源。 3.3.1. 报文主体和实体主体的差异 报文：是HTTP通信中的基本单位，由8位组字节流组成，通过HTTP通信传输。 实体：作为请求或响应的有效载荷数据被传输，其内容由实体首部和实体主体组成。 通常报文主体等于实体主体，但当传输中进行编码时，实体主体的内容发生变化才会与报文主体产生差异。 3.3.2. 压缩传输的内容编码 HTTP中的内容编码指明应用在实体内容上的编码格式，并保持实体信息原样压缩，内容编码后的实体由客户端接收并负责解码。 图片 - img 常用的内容编码： gzip(GNU ZIP) compress(UNIX系统的标准压缩) deflate(zlib) identity(不进行编码) 3.3.3. 分块传输编码 分块传输编码会将实体主体分成多个块，每一块都会用十六进制来标记快的大小，而实体的最后一块会使用“0（CR+LF）”来标记。 由接收的客户端负责解码，回复到编码前的实体主体。 图片 - img 3.4. 发送多种数据的多部分对象集合 HTTP中的多部分对象集合即发送一份报文主体内可含有多类型实体，通常是图片或文本文件上传等。 多部分对象集合包含的对象： multipart/form-data:在web表单文件上传时使用 multipart/byteranges：状态码206响应报文包含了多个范围的内容时使用 3.5. 获取部分内容的范围请求 指定范围发送的请求叫做范围请求，对于一份10000字节大小的资源，如果使用范围请求，可以只请求5001-10000字节内的资源。 图片 - img 执行范围请求时，会用到首部字段Range来指定资源的byte范围 图片 - img 3.6. 内容协商返回最合适的内容 内容协商机制是指客户端和服务端就响应的资源内容进行交涉，然后提供给客户端最合适的资源。内容协商会以响应资源的语言、编码方式等作为判断的基准。 内容协商类型： 服务器驱动协商 客户端驱动协商 透明协商 参考： 《图解HTTP》 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-10-29 20:14:46 "},"tcpip/http-code.html":{"url":"tcpip/http-code.html","title":"Http状态码","keywords":"","body":"4. HTTP状态码 状态码即服务器返回的请求结果。 状态码 类型 说明 1xx Informational(信息性状态码) 接收的请求正在处理 2xx Success(成功) 请求正常处理完毕 3xx Redirection(重定向) 需要进行附加操作以完成请求 4xx Client Error(客户端错误) 服务器无法处理请求 5xx Server Error(服务端错误) 服务器处理请求出错 图片 - img 4.1. 2XX成功 4.1.1. 200 OK 图片 - img 4.1.2. 204 No Content 图片 - img 表示请求已成功处理，但在返回的响应报文中不含实体的主体部分。 4.1.3. 206 Partial Content 图片 - img 该状态码表示客户端进行了范围请求，服务器成功执行了这部分的GET请求。响应报文中包含由Content-Range指定范围的实体内容。 4.2. 3XX 重定向 4.2.1. 301 Moved Permanently 永久性重定向，表示资源已被分配了新的URI，以后应使用新的URI。 图片 - img 4.2.2. 302 Found 临时性重定向，表示请求的资源已被分配了新的URI，但是临时性的。 图片 - img 4.2.3. 303 See Other 表示由于请求的资源存在另一个URI，应使用GET方法重定向获取请求的资源。 图片 - img 4.2.4. 304 Not Modified 表示客户端发送附带条件的请求时（GET中的If-Modified-Since等首部），服务器允许访问资源，但未满足附带条件因此直接返回304（服务器的资源未改变，可直接使用客户端未过期的缓存），不包含任何响应的主体部分。 图片 - img 4.2.5. 307 Temporary Redirect 临时重定向，该状态与302有相同的含义。 4.3. 4XX 客户端错误 4.3.1. 400 Bad Request 表示请求报文中存在语法错误，需修改内容重新发送请求。 图片 - img 4.3.2. 401 Unauthorized 表示需要通过HTTP认证。 图片 - img 4.3.3. 403 Forbidden 表示请求被服务器拒绝，未获得访问授权。 图片 - img 4.3.4. 404 No Found 表明服务器上找不到请求的资源，也可以在服务器拒绝请求且不想说明理由时使用。 图片 - img 4.4. 5XX 服务器错误 4.4.1. 500 Internal Server Error 表明服务器在执行请求时发生了错误，也可能是Web应用存在bug或临时故障等。 图片 - img 4.4.2. 503 Service Unavailable 表明服务器暂时处于超负荷或正在进行停机维护，现在不能处理请求。 图片 - img 参考： 《图解HTTP》 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-10-29 20:16:04 "},"redis/redis-introduction.html":{"url":"redis/redis-introduction.html","title":"Redis介绍","keywords":"","body":"1. redis是什么？（what） Redis是一个开源（BSD许可），内存存储的数据结构服务器，可用作数据库，高速缓存和消息队列代理。它支持字符串、哈希表、列表、集合、有序集合，位图，hyperloglogs等数据类型。内置复制、Lua脚本、LRU收回、事务以及不同级别磁盘持久化功能，同时通过Redis Sentinel提供高可用，通过Redis Cluster提供自动分区。 Redis是一个开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 2. 为什么使用redis？（why） 2.1. redis的特点 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 2.2. redis的优势 性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。 丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。 原子 – Redis的所有操作都是原子性的，同时Redis还支持对几个操作全并后的原子性执行。 丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。 2.3. redis与其他key-value存储有什么不同 Redis有着更为复杂的数据结构并且提供对他们的原子性操作，Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。 Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，应为数据量不能大于硬件内存。 相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。 在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。 3. 如何使用redis？（how） 3.1. redis的数据类型 数据类型 概念 常用命令 String(字符串) key-value型 SET ，GET Hash(哈希) field-value,适用于存储对象类型（对象名-对象属性值） HMSET，HEGTALL List(列表) string类型的有序列表，按照插入顺序排序 lpush，lrange Set(集合) string类型的无序集合 sadd，smembers zset(sorted set：有序集合) string类型元素的集合,且不允许重复的成员。每个元素关联一个double值来进行排序，double值可以重复但元素不能重复。 zadd，ZRANGEBYSCORE 3.2. redis常用命令 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-10-27 17:58:38 "},"redis/redis-cluster.html":{"url":"redis/redis-cluster.html","title":"Redis集群模式部署","keywords":"","body":"1. Redis部署 以下以Linux系统为例 1.1 下载和编译 $ wget http://download.redis.io/releases/redis-4.0.7.tar.gz $ tar xzf redis-4.0.7.tar.gz $ cd redis-4.0.7 $ make 编译完成后会在src目录下生成Redis服务端程序redis-server和客户端程序redis-cli。 1.2 启动服务 1、前台运行 src/redis-server 该方式启动默认为前台方式运行，使用默认配置。 2、后台运行 可以修改redis.conf文件的daemonize参数为yes，指定配置文件启动，例如： vi redis.conf # By default Redis does not run as a daemon. Use 'yes' if you need it. # Note that Redis will write a pid file in /var/run/redis.pid when daemonized. daemonize yes 指定配置文件启动。 src/redis-server redis.conf 例如： #指定配置文件后台启动 [root@kube-node-1 redis-4.0.7]# src/redis-server redis.conf 95778:C 30 Jan 00:44:37.633 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 95778:C 30 Jan 00:44:37.634 # Redis version=4.0.7, bits=64, commit=00000000, modified=0, pid=95778, just started 95778:C 30 Jan 00:44:37.634 # Configuration loaded #查看Redis进程 [root@kube-node-1 redis-4.0.7]# ps aux|grep redis root 95779 0.0 0.0 145268 468 ? Ssl 00:44 0:00 src/redis-server 127.0.0.1:6379 更多启动参数如下： [root@kube-node-1 src]# ./redis-server --help Usage: ./redis-server [/path/to/redis.conf] [options] ./redis-server - (read config from stdin) ./redis-server -v or --version ./redis-server -h or --help ./redis-server --test-memory Examples: ./redis-server (run the server with default conf) ./redis-server /etc/redis/6379.conf ./redis-server --port 7777 ./redis-server --port 7777 --slaveof 127.0.0.1 8888 ./redis-server /etc/myredis.conf --loglevel verbose Sentinel mode: ./redis-server /etc/sentinel.conf --sentinel 1.3 客户端测试 $ src/redis-cli redis> set foo bar OK redis> get foo \"bar\" 2. Redis集群部署 Redis的集群部署需要在每台集群部署的机器上安装Redis（可参考上述的[Redis安装] ），然后修改配置以集群的方式启动。 2.1 手动部署集群 2.1.1 设置配置文件及启动实例 修改配置文件redis.conf，集群模式的最小化配置文件如下： #可选操作，该项设置后台方式运行， daemonize yes port 7000 cluster-enabled yes cluster-config-file nodes.conf cluster-node-timeout 5000 appendonly yes 更多集群配置参数可参考默认配置文件redis.conf中Cluster模块的说明 最小集群模式需要三个master实例，一般建议起六个实例，即三主三从。因此我们创建6个以端口号命名的目录存放实例的配置文件和其他信息。 mkdir cluster-test cd cluster-test mkdir 7000 7001 7002 7003 7004 7005 在对应端口号的目录中创建redis.conf的文件，配置文件的内容可参考上述的集群模式配置。每个配置文件中的端口号port参数改为对应目录的端口号。 复制redis-server的二进制文件到cluster-test目录中，通过指定配置文件的方式启动redis服务，例如： cd 7000 ../redis-server ./redis.conf 如果是以前台方式运行，则会在控制台输出以下信息： [82462] 26 Nov 11:56:55.329 * No cluster configuration found, I'm 97a3a64667477371c4479320d683e4c8db5858b1 每个实例都会生成一个Node ID，类似97a3a64667477371c4479320d683e4c8db5858b1，用来作为Redis实例在集群中的唯一标识，而不是通过IP和Port，IP和Port可能会改变，该Node ID不会改变。 目录结构可参考： cluster-test/ ├── 7000 │ ├── appendonly.aof │ ├── dump.rdb │ ├── nodes.conf │ └── redis.conf ├── 7001 │ ├── appendonly.aof │ ├── dump.rdb │ ├── nodes.conf │ └── redis.conf ├── 7002 │ ├── appendonly.aof │ ├── dump.rdb │ ├── nodes.conf │ └── redis.conf ├── 7003 │ ├── appendonly.aof │ ├── dump.rdb │ ├── nodes.conf │ └── redis.conf ├── 7004 │ ├── appendonly.aof │ ├── dump.rdb │ ├── nodes.conf │ └── redis.conf ├── 7005 │ ├── appendonly.aof │ ├── dump.rdb │ ├── nodes.conf │ └── redis.conf ├── redis-cli └── redis-server 2.1.2 redis-trib创建集群 Redis的实例全部运行之后，还需要redis-trib.rb工具来完成集群的创建，redis-trib.rb二进制文件在Redis包主目录下的src目录中，运行该工具依赖Ruby环境和gem，因此需要提前安装。 1、安装Ruby yum -y install ruby rubygems 查看Ruby版本信息。 [root@kube-node-1 src]# ruby --version ruby 2.0.0p648 (2015-12-16) [x86_64-linux] 由于centos系统默认支持Ruby版本为2.0.0，因此执行gem install redis命令时会报以下错误。 [root@kube-node-1 src]# gem install redis Fetching: redis-4.0.1.gem (100%) ERROR: Error installing redis: redis requires Ruby version >= 2.2.2. 解决方法是先安装rvm，再升级ruby版本。 2、安装rvm curl -L get.rvm.io | bash -s stable 如果遇到以下报错，则执行报错中的gpg2 --recv-keys的命令。 [root@kube-node-1 ~]# curl -L get.rvm.io | bash -s stable % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 194 100 194 0 0 335 0 --:--:-- --:--:-- --:--:-- 335 100 24090 100 24090 0 0 17421 0 0:00:01 0:00:01 --:--:-- 44446 Downloading https://github.com/rvm/rvm/archive/1.29.3.tar.gz Downloading https://github.com/rvm/rvm/releases/download/1.29.3/1.29.3.tar.gz.asc gpg: 于 2017年09月11日 星期一 04时59分21秒 CST 创建的签名，使用 RSA，钥匙号 BF04FF17 gpg: 无法检查签名：没有公钥 Warning, RVM 1.26.0 introduces signed releases and automated check of signatures when GPG software found. Assuming you trust Michal Papis import the mpapis public key (downloading the signatures). GPG signature verification failed for '/usr/local/rvm/archives/rvm-1.29.3.tgz' - 'https://github.com/rvm/rvm/releases/download/1.29.3/1.29.3.tar.gz.asc'! Try to install GPG v2 and then fetch the public key: gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 or if it fails: command curl -sSL https://rvm.io/mpapis.asc | gpg2 --import - the key can be compared with: https://rvm.io/mpapis.asc https://keybase.io/mpapis NOTE: GPG version 2.1.17 have a bug which cause failures during fetching keys from remote server. Please downgrade or upgrade to newer version (if available) or use the second method described above. 执行报错中的gpg2 --recv-keys的命令。 例如： [root@kube-node-1 ~]# gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 gpg: 钥匙环‘/root/.gnupg/secring.gpg’已建立 gpg: 下载密钥‘D39DC0E3’，从 hkp 服务器 keys.gnupg.net gpg: /root/.gnupg/trustdb.gpg：建立了信任度数据库 gpg: 密钥 D39DC0E3：公钥“Michal Papis (RVM signing) ”已导入 gpg: 没有找到任何绝对信任的密钥 gpg: 合计被处理的数量：1 gpg: 已导入：1 (RSA: 1) 再次执行命令curl -L get.rvm.io | bash -s stable。例如： [root@kube-node-1 ~]# curl -L get.rvm.io | bash -s stable % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 194 100 194 0 0 310 0 --:--:-- --:--:-- --:--:-- 309 100 24090 100 24090 0 0 18230 0 0:00:01 0:00:01 --:--:-- 103k Downloading https://github.com/rvm/rvm/archive/1.29.3.tar.gz Downloading https://github.com/rvm/rvm/releases/download/1.29.3/1.29.3.tar.gz.asc gpg: 于 2017年09月11日 星期一 04时59分21秒 CST 创建的签名，使用 RSA，钥匙号 BF04FF17 gpg: 完好的签名，来自于“Michal Papis (RVM signing) ” gpg: 亦即“Michal Papis ” gpg: 亦即“[jpeg image of size 5015]” gpg: 警告：这把密钥未经受信任的签名认证！ gpg: 没有证据表明这个签名属于它所声称的持有者。 主钥指纹： 409B 6B17 96C2 7546 2A17 0311 3804 BB82 D39D C0E3 子钥指纹： 62C9 E5F4 DA30 0D94 AC36 166B E206 C29F BF04 FF17 GPG verified '/usr/local/rvm/archives/rvm-1.29.3.tgz' Creating group 'rvm' Installing RVM to /usr/local/rvm/ Installation of RVM in /usr/local/rvm/ is almost complete: * First you need to add all users that will be using rvm to 'rvm' group, and logout - login again, anyone using rvm will be operating with `umask u=rwx,g=rwx,o=rx`. * To start using RVM you need to run `source /etc/profile.d/rvm.sh` in all your open bash windows, in rare cases you need to reopen all bash windows. 以上表示执行成功， source /usr/local/rvm/scripts/rvm 查看rvm库中已知的ruby版本 rvm list known 例如： [root@kube-node-1 ~]# rvm list known # MRI Rubies [ruby-]1.8.6[-p420] [ruby-]1.8.7[-head] # security released on head [ruby-]1.9.1[-p431] [ruby-]1.9.2[-p330] [ruby-]1.9.3[-p551] [ruby-]2.0.0[-p648] [ruby-]2.1[.10] [ruby-]2.2[.7] [ruby-]2.3[.4] [ruby-]2.4[.1] ruby-head ... 3、升级Ruby #安装ruby rvm install 2.4.0 #使用新版本 rvm use 2.4.0 #移除旧版本 rvm remove 2.0.0 #查看当前版本 ruby --version 例如： [root@kube-node-1 ~]# rvm install 2.4.0 Searching for binary rubies, this might take some time. Found remote file https://rvm_io.global.ssl.fastly.net/binaries/centos/7/x86_64/ruby-2.4.0.tar.bz2 Checking requirements for centos. Installing requirements for centos. Installing required packages: autoconf, automake, bison, bzip2, gcc-c++, libffi-devel, libtool, readline-devel, sqlite-devel, zlib-devel, libyaml-devel, openssl-devel................................ Requirements installation successful. ruby-2.4.0 - #configure ruby-2.4.0 - #download % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 14.0M 100 14.0M 0 0 852k 0 0:00:16 0:00:16 --:--:-- 980k No checksum for downloaded archive, recording checksum in user configuration. ruby-2.4.0 - #validate archive ruby-2.4.0 - #extract ruby-2.4.0 - #validate binary ruby-2.4.0 - #setup ruby-2.4.0 - #gemset created /usr/local/rvm/gems/ruby-2.4.0@global ruby-2.4.0 - #importing gemset /usr/local/rvm/gemsets/global.gems.............................. ruby-2.4.0 - #generating global wrappers........ ruby-2.4.0 - #gemset created /usr/local/rvm/gems/ruby-2.4.0 ruby-2.4.0 - #importing gemsetfile /usr/local/rvm/gemsets/default.gems evaluated to empty gem list ruby-2.4.0 - #generating default wrappers........ [root@kube-node-1 ~]# rvm use 2.4.0 Using /usr/local/rvm/gems/ruby-2.4.0 [root@kube-node-1 ~]# rvm remove 2.0.0 ruby-2.0.0-p648 - #already gone Using /usr/local/rvm/gems/ruby-2.4.0 [root@kube-node-1 ~]# ruby --version ruby 2.4.0p0 (2016-12-24 revision 57164) [x86_64-linux] 4、安装gem gem install redis 例如： [root@kube-node-1 ~]# gem install redis Fetching: redis-4.0.1.gem (100%) Successfully installed redis-4.0.1 Parsing documentation for redis-4.0.1 Installing ri documentation for redis-4.0.1 Done installing documentation for redis after 2 seconds 1 gem installed 5、执行redis-trib.rb命令 以上表示安装成功，可以执行redis-trib.rb命令。 cd src #执行redis-trib.rb命令 ./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 \\ > 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 参数create表示创建一个新的集群，--replicas 1表示为每个master创建一个slave。 如果创建成功会显示以下信息 [OK] All 16384 slots covered 例如： [root@kube-node-1 src]# ./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 \\ > 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 >>> Creating cluster >>> Performing hash slots allocation on 6 nodes... Using 3 masters: 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 Adding replica 127.0.0.1:7004 to 127.0.0.1:7000 Adding replica 127.0.0.1:7005 to 127.0.0.1:7001 Adding replica 127.0.0.1:7003 to 127.0.0.1:7002 >>> Trying to optimize slaves allocation for anti-affinity [WARNING] Some slaves are in the same host as their master M: d5a834d075fd93eefab877c6ebb86efff680650f 127.0.0.1:7000 slots:0-5460 (5461 slots) master M: 13d0c397604a0b2644244c37b666fce83f29faa8 127.0.0.1:7001 slots:5461-10922 (5462 slots) master M: be2718476eba4e56f696e56b75e67df720b7fc24 127.0.0.1:7002 slots:10923-16383 (5461 slots) master S: 3d02f59b34047486faecc023685379de7b38076c 127.0.0.1:7003 replicates 13d0c397604a0b2644244c37b666fce83f29faa8 S: dedf672f0a75faf37407ac4edd5da23bc4651e25 127.0.0.1:7004 replicates be2718476eba4e56f696e56b75e67df720b7fc24 S: 99c07119a449a703583019f7699e15afa0e41952 127.0.0.1:7005 replicates d5a834d075fd93eefab877c6ebb86efff680650f Can I set the above configuration? (type 'yes' to accept): yes >>> Nodes configuration updated >>> Assign a different config epoch to each node >>> Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join.... >>> Performing Cluster Check (using node 127.0.0.1:7000) M: d5a834d075fd93eefab877c6ebb86efff680650f 127.0.0.1:7000 slots:0-5460 (5461 slots) master 1 additional replica(s) M: be2718476eba4e56f696e56b75e67df720b7fc24 127.0.0.1:7002 slots:10923-16383 (5461 slots) master 1 additional replica(s) M: 13d0c397604a0b2644244c37b666fce83f29faa8 127.0.0.1:7001 slots:5461-10922 (5462 slots) master 1 additional replica(s) S: 3d02f59b34047486faecc023685379de7b38076c 127.0.0.1:7003 slots: (0 slots) slave replicates 13d0c397604a0b2644244c37b666fce83f29faa8 S: 99c07119a449a703583019f7699e15afa0e41952 127.0.0.1:7005 slots: (0 slots) slave replicates d5a834d075fd93eefab877c6ebb86efff680650f S: dedf672f0a75faf37407ac4edd5da23bc4651e25 127.0.0.1:7004 slots: (0 slots) slave replicates be2718476eba4e56f696e56b75e67df720b7fc24 [OK] All nodes agree about slots configuration. >>> Check for open slots... >>> Check slots coverage... [OK] All 16384 slots covered. 2.1.3 部署结果验证 1、客户端访问 使用客户端redis-cli二进制访问某个实例，执行set和get的测试。 $ redis-cli -c -p 7000 redis 127.0.0.1:7000> set foo bar -> Redirected to slot [12182] located at 127.0.0.1:7002 OK redis 127.0.0.1:7002> set hello world -> Redirected to slot [866] located at 127.0.0.1:7000 OK redis 127.0.0.1:7000> get foo -> Redirected to slot [12182] located at 127.0.0.1:7002 \"bar\" redis 127.0.0.1:7000> get hello -> Redirected to slot [866] located at 127.0.0.1:7000 \"world\" 2、查看集群状态 使用cluster info命令查看集群状态。 127.0.0.1:7000> cluster info cluster_state:ok #集群状态 cluster_slots_assigned:16384 #被分配的槽位数 cluster_slots_ok:16384 #正确分配的槽位 cluster_slots_pfail:0 cluster_slots_fail:0 cluster_known_nodes:6 #当前节点 cluster_size:3 cluster_current_epoch:6 cluster_my_epoch:1 cluster_stats_messages_ping_sent:48273 cluster_stats_messages_pong_sent:49884 cluster_stats_messages_sent:98157 cluster_stats_messages_ping_received:49879 cluster_stats_messages_pong_received:48273 cluster_stats_messages_meet_received:5 cluster_stats_messages_received:98157 3、查看节点状态 使用cluster nodes命令查看节点状态。 127.0.0.1:7000> cluster nodes be2718476eba4e56f696e56b75e67df720b7fc24 127.0.0.1:7002@17002 master - 0 1517303607000 3 connected 10923-16383 13d0c397604a0b2644244c37b666fce83f29faa8 127.0.0.1:7001@17001 master - 0 1517303606000 2 connected 5461-10922 3d02f59b34047486faecc023685379de7b38076c 127.0.0.1:7003@17003 slave 13d0c397604a0b2644244c37b666fce83f29faa8 0 1517303606030 4 connected d5a834d075fd93eefab877c6ebb86efff680650f 127.0.0.1:7000@17000 myself,master - 0 1517303604000 1 connected 0-5460 99c07119a449a703583019f7699e15afa0e41952 127.0.0.1:7005@17005 slave d5a834d075fd93eefab877c6ebb86efff680650f 0 1517303607060 6 connected dedf672f0a75faf37407ac4edd5da23bc4651e25 127.0.0.1:7004@17004 slave be2718476eba4e56f696e56b75e67df720b7fc24 0 1517303608082 5 connected 参考文章： https://redis.io/download https://redis.io/topics/cluster-tutorial Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-10-27 18:02:35 "},"redis/redis-sentinel.html":{"url":"redis/redis-sentinel.html","title":"Redis主从及哨兵模式部署","keywords":"","body":"1. 部署Redis集群 redis的安装及配置参考[redis部署] 本文以创建一主二从的集群为例。 1.1 部署与配置 先创建sentinel目录，在该目录下创建8000，8001，8002三个以端口号命名的目录。 mkdir sentinel cd sentinel mkdir 8000 8001 8002 在对应端口号目录中创建redis.conf的文件，配置文件中的端口号port参数改为对应目录的端口号。配置如下： # 守护进程模式 daemonize yes # pid file pidfile /var/run/redis.pid # 监听端口 port 8000 # TCP接收队列长度，受/proc/sys/net/core/somaxconn和tcp_max_syn_backlog这两个内核参数的影响 tcp-backlog 511 # 一个客户端空闲多少秒后关闭连接(0代表禁用，永不关闭) timeout 0 # 如果非零，则设置SO_KEEPALIVE选项来向空闲连接的客户端发送ACK tcp-keepalive 60 # 指定服务器调试等级 # 可能值： # debug （大量信息，对开发/测试有用） # verbose （很多精简的有用信息，但是不像debug等级那么多） # notice （适量的信息，基本上是你生产环境中需要的） # warning （只有很重要/严重的信息会记录下来） loglevel notice # 指明日志文件名 logfile \"./redis8000.log\" # 设置数据库个数 databases 16 # 会在指定秒数和数据变化次数之后把数据库写到磁盘上 # 900秒（15分钟）之后，且至少1次变更 # 300秒（5分钟）之后，且至少10次变更 # 60秒之后，且至少10000次变更 save 900 1 save 300 10 save 60 10000 # 默认如果开启RDB快照(至少一条save指令)并且最新的后台保存失败，Redis将会停止接受写操作 # 这将使用户知道数据没有正确的持久化到硬盘，否则可能没人注意到并且造成一些灾难 stop-writes-on-bgsave-error yes # 当导出到 .rdb 数据库时是否用LZF压缩字符串对象 rdbcompression yes # 版本5的RDB有一个CRC64算法的校验和放在了文件的最后。这将使文件格式更加可靠。 rdbchecksum yes # 持久化数据库的文件名 dbfilename dump.rdb # 工作目录 dir ./ # 当master服务设置了密码保护时，slave服务连接master的密码 masterauth 0234kz9*l # 当一个slave失去和master的连接，或者同步正在进行中，slave的行为可以有两种： # # 1) 如果 slave-serve-stale-data 设置为 \"yes\" (默认值)，slave会继续响应客户端请求， # 可能是正常数据，或者是过时了的数据，也可能是还没获得值的空数据。 # 2) 如果 slave-serve-stale-data 设置为 \"no\"，slave会回复\"正在从master同步 # （SYNC with master in progress）\"来处理各种请求，除了 INFO 和 SLAVEOF 命令。 slave-serve-stale-data yes # 你可以配置salve实例是否接受写操作。可写的slave实例可能对存储临时数据比较有用(因为写入salve # 的数据在同master同步之后将很容易被删除 slave-read-only yes # 是否在slave套接字发送SYNC之后禁用 TCP_NODELAY？ # 如果你选择“yes”Redis将使用更少的TCP包和带宽来向slaves发送数据。但是这将使数据传输到slave # 上有延迟，Linux内核的默认配置会达到40毫秒 # 如果你选择了 \"no\" 数据传输到salve的延迟将会减少但要使用更多的带宽 repl-disable-tcp-nodelay no # slave的优先级是一个整数展示在Redis的Info输出中。如果master不再正常工作了，哨兵将用它来 # 选择一个slave提升=升为master。 # 优先级数字小的salve会优先考虑提升为master，所以例如有三个slave优先级分别为10，100，25， # 哨兵将挑选优先级最小数字为10的slave。 # 0作为一个特殊的优先级，标识这个slave不能作为master，所以一个优先级为0的slave永远不会被 # 哨兵挑选提升为master slave-priority 100 # 密码验证 # 警告：因为Redis太快了，所以外面的人可以尝试每秒150k的密码来试图破解密码。这意味着你需要 # 一个高强度的密码，否则破解太容易了 requirepass 0234kz9*l # redis实例最大占用内存，不要用比设置的上限更多的内存。一旦内存使用达到上限，Redis会根据选定的回收策略（参见： # maxmemmory-policy）删除key maxmemory 3gb # 最大内存策略：如果达到内存限制了，Redis如何选择删除key。你可以在下面五个行为里选： # volatile-lru -> 根据LRU算法删除带有过期时间的key。 # allkeys-lru -> 根据LRU算法删除任何key。 # volatile-random -> 根据过期设置来随机删除key, 具备过期时间的key。 # allkeys->random -> 无差别随机删, 任何一个key。 # volatile-ttl -> 根据最近过期时间来删除（辅以TTL）, 这是对于有过期时间的key # noeviction -> 谁也不删，直接在写操作时返回错误。 maxmemory-policy volatile-lru # 默认情况下，Redis是异步的把数据导出到磁盘上。这种模式在很多应用里已经足够好，但Redis进程 # 出问题或断电时可能造成一段时间的写操作丢失(这取决于配置的save指令)。 # # AOF是一种提供了更可靠的替代持久化模式，例如使用默认的数据写入文件策略（参见后面的配置） # 在遇到像服务器断电或单写情况下Redis自身进程出问题但操作系统仍正常运行等突发事件时，Redis # 能只丢失1秒的写操作。 # # AOF和RDB持久化能同时启动并且不会有问题。 # 如果AOF开启，那么在启动时Redis将加载AOF文件，它更能保证数据的可靠性。 appendonly no # aof文件名 appendfilename \"appendonly.aof\" # fsync() 系统调用告诉操作系统把数据写到磁盘上，而不是等更多的数据进入输出缓冲区。 # 有些操作系统会真的把数据马上刷到磁盘上；有些则会尽快去尝试这么做。 # # Redis支持三种不同的模式： # # no：不要立刻刷，只有在操作系统需要刷的时候再刷。比较快。 # always：每次写操作都立刻写入到aof文件。慢，但是最安全。 # everysec：每秒写一次。折中方案。 appendfsync everysec # 如果AOF的同步策略设置成 \"always\" 或者 \"everysec\"，并且后台的存储进程（后台存储或写入AOF # 日志）会产生很多磁盘I/O开销。某些Linux的配置下会使Redis因为 fsync()系统调用而阻塞很久。 # 注意，目前对这个情况还没有完美修正，甚至不同线程的 fsync() 会阻塞我们同步的write(2)调用。 # # 为了缓解这个问题，可以用下面这个选项。它可以在 BGSAVE 或 BGREWRITEAOF 处理时阻止主进程进行fsync()。 # # 这就意味着如果有子进程在进行保存操作，那么Redis就处于\"不可同步\"的状态。 # 这实际上是说，在最差的情况下可能会丢掉30秒钟的日志数据。（默认Linux设定） # # 如果你有延时问题把这个设置成\"yes\"，否则就保持\"no\"，这是保存持久数据的最安全的方式。 no-appendfsync-on-rewrite yes # 自动重写AOF文件 auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb # AOF文件可能在尾部是不完整的（这跟system关闭有问题，尤其是mount ext4文件系统时 # 没有加上data=ordered选项。只会发生在os死时，redis自己死不会不完整）。 # 那redis重启时load进内存的时候就有问题了。 # 发生的时候，可以选择redis启动报错，并且通知用户和写日志，或者load尽量多正常的数据。 # 如果aof-load-truncated是yes，会自动发布一个log给客户端然后load（默认）。 # 如果是no，用户必须手动redis-check-aof修复AOF文件才可以。 # 注意，如果在读取的过程中，发现这个aof是损坏的，服务器也是会退出的， # 这个选项仅仅用于当服务器尝试读取更多的数据但又找不到相应的数据时。 aof-load-truncated yes # Lua 脚本的最大执行时间，毫秒为单位 lua-time-limit 5000 # Redis慢查询日志可以记录超过指定时间的查询 slowlog-log-slower-than 10000 # 这个长度没有限制。只是要主要会消耗内存。你可以通过 SLOWLOG RESET 来回收内存。 slowlog-max-len 128 # redis延时监控系统在运行时会采样一些操作，以便收集可能导致延时的数据根源。 # 通过 LATENCY命令 可以打印一些图样和获取一些报告，方便监控 # 这个系统仅仅记录那个执行时间大于或等于预定时间（毫秒）的操作, # 这个预定时间是通过latency-monitor-threshold配置来指定的， # 当设置为0时，这个监控系统处于停止状态 latency-monitor-threshold 0 # Redis能通知 Pub/Sub 客户端关于键空间发生的事件，默认关闭 notify-keyspace-events \"\" # 当hash只有少量的entry时，并且最大的entry所占空间没有超过指定的限制时，会用一种节省内存的 # 数据结构来编码。可以通过下面的指令来设定限制 hash-max-ziplist-entries 512 hash-max-ziplist-value 64 # 与hash似，数据元素较少的list，可以用另一种方式来编码从而节省大量空间。 # 这种特殊的方式只有在符合下面限制时才可以用 list-max-ziplist-entries 512 list-max-ziplist-value 64 # set有一种特殊编码的情况：当set数据全是十进制64位有符号整型数字构成的字符串时。 # 下面这个配置项就是用来设置set使用这种编码来节省内存的最大长度。 set-max-intset-entries 512 # 与hash和list相似，有序集合也可以用一种特别的编码方式来节省大量空间。 # 这种编码只适合长度和元素都小于下面限制的有序集合 zset-max-ziplist-entries 128 zset-max-ziplist-value 64 # HyperLogLog稀疏结构表示字节的限制。该限制包括 # 16个字节的头。当HyperLogLog使用稀疏结构表示 # 这些限制，它会被转换成密度表示。 # 值大于16000是完全没用的，因为在该点 # 密集的表示是更多的内存效率。 # 建议值是3000左右，以便具有的内存好处, 减少内存的消耗 hll-sparse-max-bytes 3000 # 启用哈希刷新，每100个CPU毫秒会拿出1个毫秒来刷新Redis的主哈希表（顶级键值映射表） activerehashing yes # 客户端的输出缓冲区的限制，可用于强制断开那些因为某种原因从服务器读取数据的速度不够快的客户端 client-output-buffer-limit normal 0 0 0 client-output-buffer-limit slave 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 # 默认情况下，“hz”的被设定为10。提高该值将在Redis空闲时使用更多的CPU时，但同时当有多个key # 同时到期会使Redis的反应更灵敏，以及超时可以更精确地处理 hz 10 # 当一个子进程重写AOF文件时，如果启用下面的选项，则文件每生成32M数据会被同步 aof-rewrite-incremental-fsync yes 1.2 配置主从关系 1、启动实例 三个Redis实例配置相同，分别启动三个Redis实例。建议将redis-server、redis-cli、redis-sentinel的二进制复制到/usr/local/bin的目录下。 cd 8000 redis-server redis.conf 2、配置主从关系 例如，将8000端口实例设为主，8001和8002端口的实例设为从。 则分别登录8001和8002的实例，执行slaveof 命令。 例如： [root@kube-node-1 8000]# redis-cli -c -p 8001 -a 0234kz9*l 127.0.0.1:8001> slaveof 127.0.0.1 8000 OK 3、检查集群状态 登录master和slave实例，执行info replication查看集群状态。 Master [root@kube-node-1 8000]# redis-cli -c -p 8000 -a 0234kz9*l 127.0.0.1:8000> info replication # Replication role:master connected_slaves:2 slave0:ip=127.0.0.1,port=8001,state=online,offset=2853,lag=0 slave1:ip=127.0.0.1,port=8002,state=online,offset=2853,lag=0 master_replid:4f8331d5f180a4669241ab0dd97e43508abd6d8f master_replid2:0000000000000000000000000000000000000000 master_repl_offset:2853 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:2853 Slave [root@kube-node-1 8000]# redis-cli -c -p 8001 -a 0234kz9*l 127.0.0.1:8001> info replication # Replication role:slave master_host:127.0.0.1 master_port:8000 master_link_status:up master_last_io_seconds_ago:3 master_sync_in_progress:0 slave_repl_offset:2909 slave_priority:100 slave_read_only:1 connected_slaves:0 master_replid:4f8331d5f180a4669241ab0dd97e43508abd6d8f master_replid2:0000000000000000000000000000000000000000 master_repl_offset:2909 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:2909 也可以往master写数据，从slave读取数据来验证。 2. 部署sentinel集群 2.1 部署与配置 在之前创建的sentinel目录中场景sentinel端口号命名的目录28000，28001，28002。 cd sentinel mkdir 28000 28001 28002 在对应端口号目录中创建redis.conf的文件，配置文件中的端口号port参数改为对应目录的端口号。配置如下： port 28000 sentinel monitor mymaster 127.0.0.1 8000 2 sentinel down-after-milliseconds mymaster 60000 sentinel failover-timeout mymaster 180000 sentinel parallel-syncs mymaster 1 2.2 启动sentinel实例 #& 表示后台运行的方式 redis-sentinel sentinel.conf & 2.3 查看状态 使用sentinel masters命令查看监控的master节点。 [root@kube-node-1 28000]# redis-cli -c -p 28000 -a 0234kz9*l 127.0.0.1:28000> 127.0.0.1:28000> ping PONG 127.0.0.1:28000> 127.0.0.1:28000> sentinel masters 1) 1) \"name\" 1) \"mymaster\" 2) \"ip\" 3) \"127.0.0.1\" 4) \"port\" 5) \"8000\" 6) \"runid\" 7) \"\" 8) \"flags\" 1) \"s_down,master,disconnected\" 2) \"link-pending-commands\" 3) \"0\" 4) \"link-refcount\" 5) \"1\" 6) \"last-ping-sent\" 7) \"187539\" 8) \"last-ok-ping-reply\" 9) \"187539\" 10) \"last-ping-reply\" 11) \"3943\" 12) \"s-down-time\" 13) \"127491\" 14) \"down-after-milliseconds\" 15) \"60000\" 16) \"info-refresh\" 17) \"1517346914642\" 18) \"role-reported\" 19) \"master\" 20) \"role-reported-time\" 21) \"187539\" 22) \"config-epoch\" 23) \"0\" 24) \"num-slaves\" 25) \"0\" 26) \"num-other-sentinels\" 27) \"0\" 28) \"quorum\" 29) \"2\" 30) \"failover-timeout\" 31) \"180000\" 32) \"parallel-syncs\" 33) \"1\" 参考文章： https://redis.io/topics/sentinel Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-10-27 17:53:30 "},"redis/redis-conf-cn.html":{"url":"redis/redis-conf-cn.html","title":"Redis配置详解(中文版)","keywords":"","body":" 以下为redis.conf的文件的中文描述，整理于网络 # Redis 配置文件示例 # 注意单位: 当需要配置内存大小时, 可能需要指定像1k,5GB,4M等常见格式 # # 1k => 1000 bytes # 1kb => 1024 bytes # 1m => 1000000 bytes # 1mb => 1024*1024 bytes # 1g => 1000000000 bytes # 1gb => 1024*1024*1024 bytes # # 单位是对大小写不敏感的 1GB 1Gb 1gB 是相同的。 INCLUDES ################################## INCLUDES ################################### # 可以在这里包含一个或多个其他的配置文件。如果你有一个适用于所有Redis服务器的标准配置模板 # 但也需要一些每个服务器自定义的设置，这个功能将很有用。被包含的配置文件也可以包含其他配置文件， # 所以需要谨慎的使用这个功能。 # # 注意“inclue”选项不能被admin或Redis哨兵的\"CONFIG REWRITE\"命令重写。 # 因为Redis总是使用最后解析的配置行最为配置指令的值, 你最好在这个文件的开头配置includes来 # 避免它在运行时重写配置。 # 如果相反你想用includes的配置覆盖原来的配置，你最好在该文件的最后使用include # # include /path/to/local.conf # include /path/to/other.conf GENERAL ################################ GENERAL ##################################### # 默认Rdis不会作为守护进程运行。如果需要的话配置成'yes' # 注意配置成守护进程后Redis会将进程号写入文件/var/run/redis.pid daemonize no # 当以守护进程方式运行时，默认Redis会把进程ID写到 /var/run/redis.pid。你可以在这里修改路径。 pidfile /var/run/redis.pid # 接受连接的特定端口，默认是6379 # 如果端口设置为0，Redis就不会监听TCP套接字。 port 6379 # TCP listen() backlog. # # 在高并发环境下你需要一个高backlog值来避免慢客户端连接问题。注意Linux内核默默地将这个值减小 # 到/proc/sys/net/core/somaxconn的值，所以需要确认增大somaxconn和tcp_max_syn_backlog # 两个值来达到想要的效果。 tcp-backlog 511 # 默认Redis监听服务器上所有可用网络接口的连接。可以用\"bind\"配置指令跟一个或多个ip地址来实现 # 监听一个或多个网络接口 # # 示例: # # bind 192.168.1.100 10.0.0.1 # bind 127.0.0.1 # 指定用来监听Unix套套接字的路径。没有默认值， 所以在没有指定的情况下Redis不会监听Unix套接字 # # unixsocket /tmp/redis.sock # unixsocketperm 755 # 一个客户端空闲多少秒后关闭连接。(0代表禁用，永不关闭) timeout 0 # TCP keepalive. # # 如果非零，则设置SO_KEEPALIVE选项来向空闲连接的客户端发送ACK，由于以下两个原因这是很有用的： # # 1）能够检测无响应的对端 # 2）让该连接中间的网络设备知道这个连接还存活 # # 在Linux上，这个指定的值(单位：秒)就是发送ACK的时间间隔。 # 注意：要关闭这个连接需要两倍的这个时间值。 # 在其他内核上这个时间间隔由内核配置决定 # # 这个选项的一个合理值是60秒 tcp-keepalive 0 # 指定服务器调试等级 # 可能值： # debug （大量信息，对开发/测试有用） # verbose （很多精简的有用信息，但是不像debug等级那么多） # notice （适量的信息，基本上是你生产环境中需要的） # warning （只有很重要/严重的信息会记录下来） loglevel notice # 指明日志文件名。也可以使用\"stdout\"来强制让Redis把日志信息写到标准输出上。 # 注意:如果Redis以守护进程方式运行，而设置日志显示到标准输出的话，日志会发送到/dev/null logfile \"\" # 要使用系统日志记录器，只要设置 \"syslog-enabled\" 为 \"yes\" 就可以了。 # 然后根据需要设置其他一些syslog参数就可以了。 # syslog-enabled no # 指明syslog身份 # syslog-ident redis # 指明syslog的设备。必须是user或LOCAL0 ~ LOCAL7之一。 # syslog-facility local0 # 设置数据库个数。默认数据库是 DB 0， # 可以通过select (0 SNAPSHOTTING ################################ SNAPSHOTTING ################################ # # 把数据库存到磁盘上: # # save # # 会在指定秒数和数据变化次数之后把数据库写到磁盘上。 # # 下面的例子将会进行把数据写入磁盘的操作: # 900秒（15分钟）之后，且至少1次变更 # 300秒（5分钟）之后，且至少10次变更 # 60秒之后，且至少10000次变更 # # 注意：你要想不写磁盘的话就把所有 \"save\" 设置注释掉就行了。 # # 通过添加一条带空字符串参数的save指令也能移除之前所有配置的save指令 # 像下面的例子： # save \"\" save 900 1 save 300 10 save 60 10000 # 默认如果开启RDB快照(至少一条save指令)并且最新的后台保存失败，Redis将会停止接受写操作 # 这将使用户知道数据没有正确的持久化到硬盘，否则可能没人注意到并且造成一些灾难。 # # 如果后台保存进程能重新开始工作，Redis将自动允许写操作 # # 然而如果你已经部署了适当的Redis服务器和持久化的监控，你可能想关掉这个功能以便于即使是 # 硬盘，权限等出问题了Redis也能够像平时一样正常工作， stop-writes-on-bgsave-error yes # 当导出到 .rdb 数据库时是否用LZF压缩字符串对象？ # 默认设置为 \"yes\"，因为几乎在任何情况下它都是不错的。 # 如果你想节省CPU的话你可以把这个设置为 \"no\"，但是如果你有可压缩的key和value的话， # 那数据文件就会更大了。 rdbcompression yes # 因为版本5的RDB有一个CRC64算法的校验和放在了文件的最后。这将使文件格式更加可靠但在 # 生产和加载RDB文件时，这有一个性能消耗(大约10%)，所以你可以关掉它来获取最好的性能。 # # 生成的关闭校验的RDB文件有一个0的校验和，它将告诉加载代码跳过检查 rdbchecksum yes # 持久化数据库的文件名 dbfilename dump.rdb # 工作目录 # # 数据库会写到这个目录下，文件名就是上面的 \"dbfilename\" 的值。 # # 累加文件也放这里。 # # 注意你这里指定的必须是目录，不是文件名。 dir ./ REPLICATION ################################# REPLICATION ################################# # 主从同步。通过 slaveof 指令来实现Redis实例的备份。 # 注意，这里是本地从远端复制数据。也就是说，本地可以有不同的数据库文件、绑定不同的IP、监听 # 不同的端口。 # # slaveof # 如果master设置了密码保护（通过 \"requirepass\" 选项来配置），那么slave在开始同步之前必须 # 进行身份验证，否则它的同步请求会被拒绝。 # # masterauth # 当一个slave失去和master的连接，或者同步正在进行中，slave的行为有两种可能： # # 1) 如果 slave-serve-stale-data 设置为 \"yes\" (默认值)，slave会继续响应客户端请求， # 可能是正常数据，也可能是还没获得值的空数据。 # 2) 如果 slave-serve-stale-data 设置为 \"no\"，slave会回复\"正在从master同步 # （SYNC with master in progress）\"来处理各种请求，除了 INFO 和 SLAVEOF 命令。 # slave-serve-stale-data yes # 你可以配置salve实例是否接受写操作。可写的slave实例可能对存储临时数据比较有用(因为写入salve # 的数据在同master同步之后将很容被删除)，但是如果客户端由于配置错误在写入时也可能产生一些问题。 # # 从Redis2.6默认所有的slave为只读 # # 注意:只读的slave不是为了暴露给互联网上不可信的客户端而设计的。它只是一个防止实例误用的保护层。 # 一个只读的slave支持所有的管理命令比如config,debug等。为了限制你可以用'rename-command'来 # 隐藏所有的管理和危险命令来增强只读slave的安全性 slave-read-only yes # slave根据指定的时间间隔向master发送ping请求。 # 时间间隔可以通过 repl_ping_slave_period 来设置。 # 默认10秒。 # # repl-ping-slave-period 10 # 以下选项设置同步的超时时间 # # 1）slave在与master SYNC期间有大量数据传输，造成超时 # 2）在slave角度，master超时，包括数据、ping等 # 3）在master角度，slave超时，当master发送REPLCONF ACK pings # # 确保这个值大于指定的repl-ping-slave-period，否则在主从间流量不高时每次都会检测到超时 # # repl-timeout 60 # 是否在slave套接字发送SYNC之后禁用 TCP_NODELAY ？ # # 如果你选择“yes”Redis将使用更少的TCP包和带宽来向slaves发送数据。但是这将使数据传输到slave # 上有延迟，Linux内核的默认配置会达到40毫秒 # # 如果你选择了 \"no\" 数据传输到salve的延迟将会减少但要使用更多的带宽 # # 默认我们会为低延迟做优化，但高流量情况或主从之间的跳数过多时，把这个选项设置为“yes” # 是个不错的选择。 repl-disable-tcp-nodelay no # 设置数据备份的backlog大小。backlog是一个slave在一段时间内断开连接时记录salve数据的缓冲， # 所以一个slave在重新连接时，不必要全量的同步，而是一个增量同步就足够了，将在断开连接的这段 # 时间内slave丢失的部分数据传送给它。 # # 同步的backlog越大，slave能够进行增量同步并且允许断开连接的时间就越长。 # # backlog只分配一次并且至少需要一个slave连接 # # repl-backlog-size 1mb # 当master在一段时间内不再与任何slave连接，backlog将会释放。以下选项配置了从最后一个 # slave断开开始计时多少秒后，backlog缓冲将会释放。 # # 0表示永不释放backlog # # repl-backlog-ttl 3600 # slave的优先级是一个整数展示在Redis的Info输出中。如果master不再正常工作了，哨兵将用它来 # 选择一个slave提升=升为master。 # # 优先级数字小的salve会优先考虑提升为master，所以例如有三个slave优先级分别为10，100，25， # 哨兵将挑选优先级最小数字为10的slave。 # # 0作为一个特殊的优先级，标识这个slave不能作为master，所以一个优先级为0的slave永远不会被 # 哨兵挑选提升为master # # 默认优先级为100 slave-priority 100 # 如果master少于N个延时小于等于M秒的已连接slave，就可以停止接收写操作。 # # N个slave需要是“oneline”状态 # # 延时是以秒为单位，并且必须小于等于指定值，是从最后一个从slave接收到的ping（通常每秒发送） # 开始计数。 # # This option does not GUARANTEES that N replicas will accept the write, but # will limit the window of exposure for lost writes in case not enough slaves # are available, to the specified number of seconds. # # 例如至少需要3个延时小于等于10秒的slave用下面的指令： # # min-slaves-to-write 3 # min-slaves-max-lag 10 # # 两者之一设置为0将禁用这个功能。 # # 默认 min-slaves-to-write 值是0（该功能禁用）并且 min-slaves-max-lag 值是10。 SECURITY ################################## SECURITY ################################### # 要求客户端在处理任何命令时都要验证身份和密码。 # 这个功能在有你不信任的其它客户端能够访问redis服务器的环境里非常有用。 # # 为了向后兼容的话这段应该注释掉。而且大多数人不需要身份验证(例如:它们运行在自己的服务器上) # # 警告：因为Redis太快了，所以外面的人可以尝试每秒150k的密码来试图破解密码。这意味着你需要 # 一个高强度的密码，否则破解太容易了。 # # requirepass foobared # 命令重命名 # # 在共享环境下，可以为危险命令改变名字。比如，你可以为 CONFIG 改个其他不太容易猜到的名字， # 这样内部的工具仍然可以使用，而普通的客户端将不行。 # # 例如： # # rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 # # 也可以通过改名为空字符串来完全禁用一个命令 # # rename-command CONFIG \"\" # # 请注意：改变命令名字被记录到AOF文件或被传送到从服务器可能产生问题。 LIMITS ################################### LIMITS #################################### # 设置最多同时连接的客户端数量。默认这个限制是10000个客户端，然而如果Redis服务器不能配置 # 处理文件的限制数来满足指定的值，那么最大的客户端连接数就被设置成当前文件限制数减32（因 # 为Redis服务器保留了一些文件描述符作为内部使用） # # 一旦达到这个限制，Redis会关闭所有新连接并发送错误'max number of clients reached' # # maxclients 10000 # 不要用比设置的上限更多的内存。一旦内存使用达到上限，Redis会根据选定的回收策略（参见： # maxmemmory-policy）删除key # # 如果因为删除策略Redis无法删除key，或者策略设置为 \"noeviction\"，Redis会回复需要更 # 多内存的错误信息给命令。例如，SET,LPUSH等等，但是会继续响应像Get这样的只读命令。 # # 在使用Redis作为LRU缓存，或者为实例设置了硬性内存限制的时候（使用 \"noeviction\" 策略） # 的时候，这个选项通常事很有用的。 # # 警告：当有多个slave连上达到内存上限的实例时，master为同步slave的输出缓冲区所需 # 内存不计算在使用内存中。这样当驱逐key时，就不会因网络问题 / 重新同步事件触发驱逐key # 的循环，反过来slaves的输出缓冲区充满了key被驱逐的DEL命令，这将触发删除更多的key， # 直到这个数据库完全被清空为止 # # 总之...如果你需要附加多个slave，建议你设置一个稍小maxmemory限制，这样系统就会有空闲 # 的内存作为slave的输出缓存区(但是如果最大内存策略设置为\"noeviction\"的话就没必要了) # # maxmemory # 最大内存策略：如果达到内存限制了，Redis如何选择删除key。你可以在下面五个行为里选： # # volatile-lru -> 根据LRU算法生成的过期时间来删除。 # allkeys-lru -> 根据LRU算法删除任何key。 # volatile-random -> 根据过期设置来随机删除key。 # allkeys->random -> 无差别随机删。 # volatile-ttl -> 根据最近过期时间来删除（辅以TTL） # noeviction -> 谁也不删，直接在写操作时返回错误。 # # 注意：对所有策略来说，如果Redis找不到合适的可以删除的key都会在写操作时返回一个错误。 # # 目前为止涉及的命令：set setnx setex append # incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd # sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby # zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby # getset mset msetnx exec sort # # 默认值如下： # # maxmemory-policy volatile-lru # LRU和最小TTL算法的实现都不是很精确，但是很接近（为了省内存），所以你可以用样本量做检测。 # 例如：默认Redis会检查3个key然后取最旧的那个，你可以通过下面的配置指令来设置样本的个数。 # # maxmemory-samples 3 APPEND ONLY MODE ############################## APPEND ONLY MODE ############################### # 默认情况下，Redis是异步的把数据导出到磁盘上。这种模式在很多应用里已经足够好，但Redis进程 # 出问题或断电时可能造成一段时间的写操作丢失(这取决于配置的save指令)。 # # AOF是一种提供了更可靠的替代持久化模式，例如使用默认的数据写入文件策略（参见后面的配置） # 在遇到像服务器断电或单写情况下Redis自身进程出问题但操作系统仍正常运行等突发事件时，Redis # 能只丢失1秒的写操作。 # # AOF和RDB持久化能同时启动并且不会有问题。 # 如果AOF开启，那么在启动时Redis将加载AOF文件，它更能保证数据的可靠性。 # # 请查看 http://redis.io/topics/persistence 来获取更多信息. appendonly no # 纯累加文件名字（默认：\"appendonly.aof\"） appendfilename \"appendonly.aof\" # fsync() 系统调用告诉操作系统把数据写到磁盘上，而不是等更多的数据进入输出缓冲区。 # 有些操作系统会真的把数据马上刷到磁盘上；有些则会尽快去尝试这么做。 # # Redis支持三种不同的模式： # # no：不要立刻刷，只有在操作系统需要刷的时候再刷。比较快。 # always：每次写操作都立刻写入到aof文件。慢，但是最安全。 # everysec：每秒写一次。折中方案。 # # 默认的 \"everysec\" 通常来说能在速度和数据安全性之间取得比较好的平衡。根据你的理解来 # 决定，如果你能放宽该配置为\"no\" 来获取更好的性能(但如果你能忍受一些数据丢失，可以考虑使用 # 默认的快照持久化模式)，或者相反，用“always”会比较慢但比everysec要更安全。 # # 请查看下面的文章来获取更多的细节 # http://antirez.com/post/redis-persistence-demystified.html # # 如果不能确定，就用 \"everysec\" # appendfsync always appendfsync everysec # appendfsync no # 如果AOF的同步策略设置成 \"always\" 或者 \"everysec\"，并且后台的存储进程（后台存储或写入AOF # 日志）会产生很多磁盘I/O开销。某些Linux的配置下会使Redis因为 fsync()系统调用而阻塞很久。 # 注意，目前对这个情况还没有完美修正，甚至不同线程的 fsync() 会阻塞我们同步的write(2)调用。 # # 为了缓解这个问题，可以用下面这个选项。它可以在 BGSAVE 或 BGREWRITEAOF 处理时阻止fsync()。 # # 这就意味着如果有子进程在进行保存操作，那么Redis就处于\"不可同步\"的状态。 # 这实际上是说，在最差的情况下可能会丢掉30秒钟的日志数据。（默认Linux设定） # # 如果把这个设置成\"yes\"带来了延迟问题，就保持\"no\"，这是保存持久数据的最安全的方式。 no-appendfsync-on-rewrite no # 自动重写AOF文件 # 如果AOF日志文件增大到指定百分比，Redis能够通过 BGREWRITEAOF 自动重写AOF日志文件。 # # 工作原理：Redis记住上次重写时AOF文件的大小（如果重启后还没有写操作，就直接用启动时的AOF大小） # # 这个基准大小和当前大小做比较。如果当前大小超过指定比例，就会触发重写操作。你还需要指定被重写 # 日志的最小尺寸，这样避免了达到指定百分比但尺寸仍然很小的情况还要重写。 # # 指定百分比为0会禁用AOF自动重写特性。 auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb ################################ LUA SCRIPTING ############################### # Lua 脚本的最大执行时间，毫秒为单位 # # 如果达到了最大的执行时间，Redis将要记录在达到最大允许时间之后一个脚本仍然在执行，并且将 # 开始对查询进行错误响应。 # # 当一个长时间运行的脚本超过了最大执行时间，只有 SCRIPT KILL 和 SHUTDOWN NOSAVE 两个 # 命令可用。第一个可以用于停止一个还没有调用写命名的脚本。第二个是关闭服务器唯一方式，当 # 写命令已经通过脚本开始执行，并且用户不想等到脚本的自然终止。 # # 设置成0或者负值表示不限制执行时间并且没有任何警告 lua-time-limit 5000 SLOW LOG ################################## SLOW LOG ################################### # Redis慢查询日志可以记录超过指定时间的查询。运行时间不包括各种I/O时间，例如：连接客户端， # 发送响应数据等，而只计算命令执行的实际时间（这只是线程阻塞而无法同时为其他请求服务的命令执 # 行阶段） # # 你可以为慢查询日志配置两个参数:一个指明Redis的超时时间(单位为微秒)来记录超过这个时间的命令 # 另一个是慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录从队列中移除。 # # 下面的时间单位是微秒，所以1000000就是1秒。注意，负数时间会禁用慢查询日志，而0则会强制记录 # 所有命令。 slowlog-log-slower-than 10000 # 这个长度没有限制。只是要主要会消耗内存。你可以通过 SLOWLOG RESET 来回收内存。 slowlog-max-len 128 Event notification ############################# Event notification ############################## # Redis 能通知 Pub/Sub 客户端关于键空间发生的事件 # 这个功能文档位于http://redis.io/topics/keyspace-events # # 例如：如果键空间事件通知被开启，并且客户端对 0 号数据库的键 foo 执行 DEL 命令时，将通过 # Pub/Sub发布两条消息： # PUBLISH __keyspace@0__:foo del # PUBLISH __keyevent@0__:del foo # # 可以在下表中选择Redis要通知的事件类型。事件类型由单个字符来标识： # # K 键空间通知，以__keyspace@__为前缀 # E 键事件通知，以__keysevent@__为前缀 # g DEL , EXPIRE , RENAME 等类型无关的通用命令的通知, ... # $ String命令 # l List命令 # s Set命令 # h Hash命令 # z 有序集合命令 # x 过期事件（每次key过期时生成） # e 驱逐事件（当key在内存满了被清除时生成） # A g$lshzxe的别名，因此”AKE”意味着所有的事件 # # notify-keyspace-events 带一个由0到多个字符组成的字符串参数。空字符串意思是通知被禁用。 # # 例子：启用List和通用事件通知： # notify-keyspace-events Elg # # 例子2：为了获取过期key的通知订阅名字为 __keyevent@__:expired 的频道，用以下配置 # notify-keyspace-events Ex # # 默认所用的通知被禁用，因为用户通常不需要该特性，并且该特性会有性能损耗。 # 注意如果你不指定至少K或E之一，不会发送任何事件。 notify-keyspace-events \"\" ADVANCED CONFIG # 当hash只有少量的entry时，并且最大的entry所占空间没有超过指定的限制时，会用一种节省内存的 # 数据结构来编码。可以通过下面的指令来设定限制 hash-max-ziplist-entries 512 hash-max-ziplist-value 64 # 与hash似，数据元素较少的list，可以用另一种方式来编码从而节省大量空间。 # 这种特殊的方式只有在符合下面限制时才可以用： list-max-ziplist-entries 512 list-max-ziplist-value 64 # set有一种特殊编码的情况：当set数据全是十进制64位有符号整型数字构成的字符串时。 # 下面这个配置项就是用来设置set使用这种编码来节省内存的最大长度。 set-max-intset-entries 512 # 与hash和list相似，有序集合也可以用一种特别的编码方式来节省大量空间。 # 这种编码只适合长度和元素都小于下面限制的有序集合： zset-max-ziplist-entries 128 zset-max-ziplist-value 64 # HyperLogLog sparse representation bytes limit. The limit includes the # 16 bytes header. When an HyperLogLog using the sparse representation crosses # this limit, it is converted into the dense representation. # # A value greater than 16000 is totally useless, since at that point the # dense representation is more memory efficient. # # The suggested value is ~ 3000 in order to have the benefits of # the space efficient encoding without slowing down too much PFADD, # which is O(N) with the sparse encoding. The value can be raised to # ~ 10000 when CPU is not a concern, but space is, and the data set is # composed of many HyperLogLogs with cardinality in the 0 - 15000 range. hll-sparse-max-bytes 3000 # 启用哈希刷新，每100个CPU毫秒会拿出1个毫秒来刷新Redis的主哈希表（顶级键值映射表）。 # redis所用的哈希表实现（见dict.c）采用延迟哈希刷新机制：你对一个哈希表操作越多，哈希刷新 # 操作就越频繁；反之，如果服务器是空闲的，那么哈希刷新就不会完成，哈希表就会占用更多的一些 # 内存而已。 # # 默认是每秒钟进行10次哈希表刷新，用来刷新字典，然后尽快释放内存。 # # 建议： # 如果你对延迟比较在意，不能够接受Redis时不时的对请求有2毫秒的延迟的话，就用 # \"activerehashing no\"，如果不太在意延迟而希望尽快释放内存就设置\"activerehashing yes\" activerehashing yes # 客户端的输出缓冲区的限制，可用于强制断开那些因为某种原因从服务器读取数据的速度不够快的客户端， # （一个常见的原因是一个发布/订阅客户端消费消息的速度无法赶上生产它们的速度） # # 可以对三种不同的客户端设置不同的限制： # normal -> 正常客户端 # slave -> slave和 MONITOR 客户端 # pubsub -> 至少订阅了一个pubsub channel或pattern的客户端 # # 下面是每个client-output-buffer-limit语法: # client-output-buffer-limit # 一旦达到硬限制客户端会立即被断开，或者达到软限制并持续达到指定的秒数（连续的）。 # 例如，如果硬限制为32兆字节和软限制为16兆字节/10秒，客户端将会立即断开 # 如果输出缓冲区的大小达到32兆字节，或客户端达到16兆字节并连续超过了限制10秒，就将断开连接。 # # 默认normal客户端不做限制，因为他们在不主动请求时不接收数据（以推的方式），只有异步客户端 # 可能会出现请求数据的速度比它可以读取的速度快的场景。 # # pubsub和slave客户端会有一个默认值，因为订阅者和slaves以推的方式来接收数据 # # 把硬限制和软限制都设置为0来禁用该功能 client-output-buffer-limit normal 0 0 0 client-output-buffer-limit slave 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 # Redis调用内部函数来执行许多后台任务，如关闭客户端超时的连接，清除未被请求过的过期Key等等。 # # 不是所有的任务都以相同的频率执行，但Redis依照指定的“hz”值来执行检查任务。 # # 默认情况下，“hz”的被设定为10。提高该值将在Redis空闲时使用更多的CPU时，但同时当有多个key # 同时到期会使Redis的反应更灵敏，以及超时可以更精确地处理。 # # 范围是1到500之间，但是值超过100通常不是一个好主意。 # 大多数用户应该使用10这个默认值，只有在非常低的延迟要求时有必要提高到100。 hz 10 # 当一个子进程重写AOF文件时，如果启用下面的选项，则文件每生成32M数据会被同步。为了增量式的 # 写入硬盘并且避免大的延迟高峰这个指令是非常有用的 aof-rewrite-incremental-fsync yes Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-12-29 14:19:38 "},"redis/redis-conf-en.html":{"url":"redis/redis-conf-en.html","title":"Redis配置详解(英文版)","keywords":"","body":" 本文来自redis 官方配置文件 # Redis configuration file example. # # Note that in order to read the configuration file, Redis must be # started with the file path as first argument: # # ./redis-server /path/to/redis.conf # Note on units: when memory size is needed, it is possible to specify # it in the usual form of 1k 5GB 4M and so forth: # # 1k => 1000 bytes # 1kb => 1024 bytes # 1m => 1000000 bytes # 1mb => 1024*1024 bytes # 1g => 1000000000 bytes # 1gb => 1024*1024*1024 bytes # # units are case insensitive so 1GB 1Gb 1gB are all the same. INCLUDES ################################## INCLUDES ################################### # Include one or more other config files here. This is useful if you # have a standard template that goes to all Redis servers but also need # to customize a few per-server settings. Include files can include # other files, so use this wisely. # # Notice option \"include\" won't be rewritten by command \"CONFIG REWRITE\" # from admin or Redis Sentinel. Since Redis always uses the last processed # line as value of a configuration directive, you'd better put includes # at the beginning of this file to avoid overwriting config change at runtime. # # If instead you are interested in using includes to override configuration # options, it is better to use include as the last line. # # include /path/to/local.conf # include /path/to/other.conf MODULES ################################## MODULES ##################################### # Load modules at startup. If the server is not able to load modules # it will abort. It is possible to use multiple loadmodule directives. # # loadmodule /path/to/my_module.so # loadmodule /path/to/other_module.so NETWORK ################################## NETWORK ##################################### # By default, if no \"bind\" configuration directive is specified, Redis listens # for connections from all the network interfaces available on the server. # It is possible to listen to just one or multiple selected interfaces using # the \"bind\" configuration directive, followed by one or more IP addresses. # # Examples: # # bind 192.168.1.100 10.0.0.1 # bind 127.0.0.1 ::1 # # ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the # internet, binding to all the interfaces is dangerous and will expose the # instance to everybody on the internet. So by default we uncomment the # following bind directive, that will force Redis to listen only into # the IPv4 lookback interface address (this means Redis will be able to # accept connections only from clients running into the same computer it # is running). # # IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES # JUST COMMENT THE FOLLOWING LINE. # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ bind 127.0.0.1 # Protected mode is a layer of security protection, in order to avoid that # Redis instances left open on the internet are accessed and exploited. # # When protected mode is on and if: # # 1) The server is not binding explicitly to a set of addresses using the # \"bind\" directive. # 2) No password is configured. # # The server only accepts connections from clients connecting from the # IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain # sockets. # # By default protected mode is enabled. You should disable it only if # you are sure you want clients from other hosts to connect to Redis # even if no authentication is configured, nor a specific set of interfaces # are explicitly listed using the \"bind\" directive. protected-mode yes # Accept connections on the specified port, default is 6379 (IANA #815344). # If port 0 is specified Redis will not listen on a TCP socket. port 6379 # TCP listen() backlog. # # In high requests-per-second environments you need an high backlog in order # to avoid slow clients connections issues. Note that the Linux kernel # will silently truncate it to the value of /proc/sys/net/core/somaxconn so # make sure to raise both the value of somaxconn and tcp_max_syn_backlog # in order to get the desired effect. tcp-backlog 511 # Unix socket. # # Specify the path for the Unix socket that will be used to listen for # incoming connections. There is no default, so Redis will not listen # on a unix socket when not specified. # # unixsocket /tmp/redis.sock # unixsocketperm 700 # Close the connection after a client is idle for N seconds (0 to disable) timeout 0 # TCP keepalive. # # If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence # of communication. This is useful for two reasons: # # 1) Detect dead peers. # 2) Take the connection alive from the point of view of network # equipment in the middle. # # On Linux, the specified value (in seconds) is the period used to send ACKs. # Note that to close the connection the double of the time is needed. # On other kernels the period depends on the kernel configuration. # # A reasonable value for this option is 300 seconds, which is the new # Redis default starting with Redis 3.2.1. tcp-keepalive 300 GENERAL ################################# GENERAL ##################################### # By default Redis does not run as a daemon. Use 'yes' if you need it. # Note that Redis will write a pid file in /var/run/redis.pid when daemonized. daemonize yes # If you run Redis from upstart or systemd, Redis can interact with your # supervision tree. Options: # supervised no - no supervision interaction # supervised upstart - signal upstart by putting Redis into SIGSTOP mode # supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET # supervised auto - detect upstart or systemd method based on # UPSTART_JOB or NOTIFY_SOCKET environment variables # Note: these supervision methods only signal \"process is ready.\" # They do not enable continuous liveness pings back to your supervisor. supervised no # If a pid file is specified, Redis writes it where specified at startup # and removes it at exit. # # When the server runs non daemonized, no pid file is created if none is # specified in the configuration. When the server is daemonized, the pid file # is used even if not specified, defaulting to \"/var/run/redis.pid\". # # Creating a pid file is best effort: if Redis is not able to create it # nothing bad happens, the server will start and run normally. pidfile /var/run/redis_6379.pid # Specify the server verbosity level. # This can be one of: # debug (a lot of information, useful for development/testing) # verbose (many rarely useful info, but not a mess like the debug level) # notice (moderately verbose, what you want in production probably) # warning (only very important / critical messages are logged) loglevel notice # Specify the log file name. Also the empty string can be used to force # Redis to log on the standard output. Note that if you use standard # output for logging but daemonize, logs will be sent to /dev/null logfile \"\" # To enable logging to the system logger, just set 'syslog-enabled' to yes, # and optionally update the other syslog parameters to suit your needs. # syslog-enabled no # Specify the syslog identity. # syslog-ident redis # Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7. # syslog-facility local0 # Set the number of databases. The default database is DB 0, you can select # a different one on a per-connection basis using SELECT where # dbid is a number between 0 and 'databases'-1 databases 16 # By default Redis shows an ASCII art logo only when started to log to the # standard output and if the standard output is a TTY. Basically this means # that normally a logo is displayed only in interactive sessions. # # However it is possible to force the pre-4.0 behavior and always show a # ASCII art logo in startup logs by setting the following option to yes. always-show-logo yes SNAPSHOTTING ################################ SNAPSHOTTING ################################ # # Save the DB on disk: # # save # # Will save the DB if both the given number of seconds and the given # number of write operations against the DB occurred. # # In the example below the behaviour will be to save: # after 900 sec (15 min) if at least 1 key changed # after 300 sec (5 min) if at least 10 keys changed # after 60 sec if at least 10000 keys changed # # Note: you can disable saving completely by commenting out all \"save\" lines. # # It is also possible to remove all the previously configured save # points by adding a save directive with a single empty string argument # like in the following example: # # save \"\" save 900 1 save 300 10 save 60 10000 # By default Redis will stop accepting writes if RDB snapshots are enabled # (at least one save point) and the latest background save failed. # This will make the user aware (in a hard way) that data is not persisting # on disk properly, otherwise chances are that no one will notice and some # disaster will happen. # # If the background saving process will start working again Redis will # automatically allow writes again. # # However if you have setup your proper monitoring of the Redis server # and persistence, you may want to disable this feature so that Redis will # continue to work as usual even if there are problems with disk, # permissions, and so forth. stop-writes-on-bgsave-error yes # Compress string objects using LZF when dump .rdb databases? # For default that's set to 'yes' as it's almost always a win. # If you want to save some CPU in the saving child set it to 'no' but # the dataset will likely be bigger if you have compressible values or keys. rdbcompression yes # Since version 5 of RDB a CRC64 checksum is placed at the end of the file. # This makes the format more resistant to corruption but there is a performance # hit to pay (around 10%) when saving and loading RDB files, so you can disable it # for maximum performances. # # RDB files created with checksum disabled have a checksum of zero that will # tell the loading code to skip the check. rdbchecksum yes # The filename where to dump the DB dbfilename dump.rdb # The working directory. # # The DB will be written inside this directory, with the filename specified # above using the 'dbfilename' configuration directive. # # The Append Only File will also be created inside this directory. # # Note that you must specify a directory here, not a file name. dir ./ REPLICATION ################################# REPLICATION ################################# # Master-Slave replication. Use slaveof to make a Redis instance a copy of # another Redis server. A few things to understand ASAP about Redis replication. # # 1) Redis replication is asynchronous, but you can configure a master to # stop accepting writes if it appears to be not connected with at least # a given number of slaves. # 2) Redis slaves are able to perform a partial resynchronization with the # master if the replication link is lost for a relatively small amount of # time. You may want to configure the replication backlog size (see the next # sections of this file) with a sensible value depending on your needs. # 3) Replication is automatic and does not need user intervention. After a # network partition slaves automatically try to reconnect to masters # and resynchronize with them. # # slaveof # If the master is password protected (using the \"requirepass\" configuration # directive below) it is possible to tell the slave to authenticate before # starting the replication synchronization process, otherwise the master will # refuse the slave request. # # masterauth # When a slave loses its connection with the master, or when the replication # is still in progress, the slave can act in two different ways: # # 1) if slave-serve-stale-data is set to 'yes' (the default) the slave will # still reply to client requests, possibly with out of date data, or the # data set may just be empty if this is the first synchronization. # # 2) if slave-serve-stale-data is set to 'no' the slave will reply with # an error \"SYNC with master in progress\" to all the kind of commands # but to INFO and SLAVEOF. # slave-serve-stale-data yes # You can configure a slave instance to accept writes or not. Writing against # a slave instance may be useful to store some ephemeral data (because data # written on a slave will be easily deleted after resync with the master) but # may also cause problems if clients are writing to it because of a # misconfiguration. # # Since Redis 2.6 by default slaves are read-only. # # Note: read only slaves are not designed to be exposed to untrusted clients # on the internet. It's just a protection layer against misuse of the instance. # Still a read only slave exports by default all the administrative commands # such as CONFIG, DEBUG, and so forth. To a limited extent you can improve # security of read only slaves using 'rename-command' to shadow all the # administrative / dangerous commands. slave-read-only yes # Replication SYNC strategy: disk or socket. # # ------------------------------------------------------- # WARNING: DISKLESS REPLICATION IS EXPERIMENTAL CURRENTLY # ------------------------------------------------------- # # New slaves and reconnecting slaves that are not able to continue the replication # process just receiving differences, need to do what is called a \"full # synchronization\". An RDB file is transmitted from the master to the slaves. # The transmission can happen in two different ways: # # 1) Disk-backed: The Redis master creates a new process that writes the RDB # file on disk. Later the file is transferred by the parent # process to the slaves incrementally. # 2) Diskless: The Redis master creates a new process that directly writes the # RDB file to slave sockets, without touching the disk at all. # # With disk-backed replication, while the RDB file is generated, more slaves # can be queued and served with the RDB file as soon as the current child producing # the RDB file finishes its work. With diskless replication instead once # the transfer starts, new slaves arriving will be queued and a new transfer # will start when the current one terminates. # # When diskless replication is used, the master waits a configurable amount of # time (in seconds) before starting the transfer in the hope that multiple slaves # will arrive and the transfer can be parallelized. # # With slow disks and fast (large bandwidth) networks, diskless replication # works better. repl-diskless-sync no # When diskless replication is enabled, it is possible to configure the delay # the server waits in order to spawn the child that transfers the RDB via socket # to the slaves. # # This is important since once the transfer starts, it is not possible to serve # new slaves arriving, that will be queued for the next RDB transfer, so the server # waits a delay in order to let more slaves arrive. # # The delay is specified in seconds, and by default is 5 seconds. To disable # it entirely just set it to 0 seconds and the transfer will start ASAP. repl-diskless-sync-delay 5 # Slaves send PINGs to server in a predefined interval. It's possible to change # this interval with the repl_ping_slave_period option. The default value is 10 # seconds. # # repl-ping-slave-period 10 # The following option sets the replication timeout for: # # 1) Bulk transfer I/O during SYNC, from the point of view of slave. # 2) Master timeout from the point of view of slaves (data, pings). # 3) Slave timeout from the point of view of masters (REPLCONF ACK pings). # # It is important to make sure that this value is greater than the value # specified for repl-ping-slave-period otherwise a timeout will be detected # every time there is low traffic between the master and the slave. # # repl-timeout 60 # Disable TCP_NODELAY on the slave socket after SYNC? # # If you select \"yes\" Redis will use a smaller number of TCP packets and # less bandwidth to send data to slaves. But this can add a delay for # the data to appear on the slave side, up to 40 milliseconds with # Linux kernels using a default configuration. # # If you select \"no\" the delay for data to appear on the slave side will # be reduced but more bandwidth will be used for replication. # # By default we optimize for low latency, but in very high traffic conditions # or when the master and slaves are many hops away, turning this to \"yes\" may # be a good idea. repl-disable-tcp-nodelay no # Set the replication backlog size. The backlog is a buffer that accumulates # slave data when slaves are disconnected for some time, so that when a slave # wants to reconnect again, often a full resync is not needed, but a partial # resync is enough, just passing the portion of data the slave missed while # disconnected. # # The bigger the replication backlog, the longer the time the slave can be # disconnected and later be able to perform a partial resynchronization. # # The backlog is only allocated once there is at least a slave connected. # # repl-backlog-size 1mb # After a master has no longer connected slaves for some time, the backlog # will be freed. The following option configures the amount of seconds that # need to elapse, starting from the time the last slave disconnected, for # the backlog buffer to be freed. # # Note that slaves never free the backlog for timeout, since they may be # promoted to masters later, and should be able to correctly \"partially # resynchronize\" with the slaves: hence they should always accumulate backlog. # # A value of 0 means to never release the backlog. # # repl-backlog-ttl 3600 # The slave priority is an integer number published by Redis in the INFO output. # It is used by Redis Sentinel in order to select a slave to promote into a # master if the master is no longer working correctly. # # A slave with a low priority number is considered better for promotion, so # for instance if there are three slaves with priority 10, 100, 25 Sentinel will # pick the one with priority 10, that is the lowest. # # However a special priority of 0 marks the slave as not able to perform the # role of master, so a slave with priority of 0 will never be selected by # Redis Sentinel for promotion. # # By default the priority is 100. slave-priority 100 # It is possible for a master to stop accepting writes if there are less than # N slaves connected, having a lag less or equal than M seconds. # # The N slaves need to be in \"online\" state. # # The lag in seconds, that must be SECURITY ################################## SECURITY ################################### # Require clients to issue AUTH before processing any other # commands. This might be useful in environments in which you do not trust # others with access to the host running redis-server. # # This should stay commented out for backward compatibility and because most # people do not need auth (e.g. they run their own servers). # # Warning: since Redis is pretty fast an outside user can try up to # 150k passwords per second against a good box. This means that you should # use a very strong password otherwise it will be very easy to break. # # requirepass foobared # Command renaming. # # It is possible to change the name of dangerous commands in a shared # environment. For instance the CONFIG command may be renamed into something # hard to guess so that it will still be available for internal-use tools # but not available for general clients. # # Example: # # rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 # # It is also possible to completely kill a command by renaming it into # an empty string: # # rename-command CONFIG \"\" # # Please note that changing the name of commands that are logged into the # AOF file or transmitted to slaves may cause problems. CLIENTS ################################### CLIENTS #################################### # Set the max number of connected clients at the same time. By default # this limit is set to 10000 clients, however if the Redis server is not # able to configure the process file limit to allow for the specified limit # the max number of allowed clients is set to the current file limit # minus 32 (as Redis reserves a few file descriptors for internal uses). # # Once the limit is reached Redis will close all the new connections sending # an error 'max number of clients reached'. # # maxclients 10000 MEMORY MANAGEMENT ############################## MEMORY MANAGEMENT ################################ # Set a memory usage limit to the specified amount of bytes. # When the memory limit is reached Redis will try to remove keys # according to the eviction policy selected (see maxmemory-policy). # # If Redis can't remove keys according to the policy, or if the policy is # set to 'noeviction', Redis will start to reply with errors to commands # that would use more memory, like SET, LPUSH, and so on, and will continue # to reply to read-only commands like GET. # # This option is usually useful when using Redis as an LRU or LFU cache, or to # set a hard memory limit for an instance (using the 'noeviction' policy). # # WARNING: If you have slaves attached to an instance with maxmemory on, # the size of the output buffers needed to feed the slaves are subtracted # from the used memory count, so that network problems / resyncs will # not trigger a loop where keys are evicted, and in turn the output # buffer of slaves is full with DELs of keys evicted triggering the deletion # of more keys, and so forth until the database is completely emptied. # # In short... if you have slaves attached it is suggested that you set a lower # limit for maxmemory so that there is some free RAM on the system for slave # output buffers (but this is not needed if the policy is 'noeviction'). # # maxmemory # MAXMEMORY POLICY: how Redis will select what to remove when maxmemory # is reached. You can select among five behaviors: # # volatile-lru -> Evict using approximated LRU among the keys with an expire set. # allkeys-lru -> Evict any key using approximated LRU. # volatile-lfu -> Evict using approximated LFU among the keys with an expire set. # allkeys-lfu -> Evict any key using approximated LFU. # volatile-random -> Remove a random key among the ones with an expire set. # allkeys-random -> Remove a random key, any key. # volatile-ttl -> Remove the key with the nearest expire time (minor TTL) # noeviction -> Don't evict anything, just return an error on write operations. # # LRU means Least Recently Used # LFU means Least Frequently Used # # Both LRU, LFU and volatile-ttl are implemented using approximated # randomized algorithms. # # Note: with any of the above policies, Redis will return an error on write # operations, when there are no suitable keys for eviction. # # At the date of writing these commands are: set setnx setex append # incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd # sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby # zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby # getset mset msetnx exec sort # # The default is: # # maxmemory-policy noeviction # LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated # algorithms (in order to save memory), so you can tune it for speed or # accuracy. For default Redis will check five keys and pick the one that was # used less recently, you can change the sample size using the following # configuration directive. # # The default of 5 produces good enough results. 10 Approximates very closely # true LRU but costs more CPU. 3 is faster but not very accurate. # # maxmemory-samples 5 LAZY FREEING ############################# LAZY FREEING #################################### # Redis has two primitives to delete keys. One is called DEL and is a blocking # deletion of the object. It means that the server stops processing new commands # in order to reclaim all the memory associated with an object in a synchronous # way. If the key deleted is associated with a small object, the time needed # in order to execute the DEL command is very small and comparable to most other # O(1) or O(log_N) commands in Redis. However if the key is associated with an # aggregated value containing millions of elements, the server can block for # a long time (even seconds) in order to complete the operation. # # For the above reasons Redis also offers non blocking deletion primitives # such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and # FLUSHDB commands, in order to reclaim memory in background. Those commands # are executed in constant time. Another thread will incrementally free the # object in the background as fast as possible. # # DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled. # It's up to the design of the application to understand when it is a good # idea to use one or the other. However the Redis server sometimes has to # delete keys or flush the whole database as a side effect of other operations. # Specifically Redis deletes objects independently of a user call in the # following scenarios: # # 1) On eviction, because of the maxmemory and maxmemory policy configurations, # in order to make room for new data, without going over the specified # memory limit. # 2) Because of expire: when a key with an associated time to live (see the # EXPIRE command) must be deleted from memory. # 3) Because of a side effect of a command that stores data on a key that may # already exist. For example the RENAME command may delete the old key # content when it is replaced with another one. Similarly SUNIONSTORE # or SORT with STORE option may delete existing keys. The SET command # itself removes any old content of the specified key in order to replace # it with the specified string. # 4) During replication, when a slave performs a full resynchronization with # its master, the content of the whole database is removed in order to # load the RDB file just transfered. # # In all the above cases the default is to delete objects in a blocking way, # like if DEL was called. However you can configure each case specifically # in order to instead release memory in a non-blocking way like if UNLINK # was called, using the following configuration directives: lazyfree-lazy-eviction no lazyfree-lazy-expire no lazyfree-lazy-server-del no slave-lazy-flush no APPEND ONLY MODE ############################## APPEND ONLY MODE ############################### # By default Redis asynchronously dumps the dataset on disk. This mode is # good enough in many applications, but an issue with the Redis process or # a power outage may result into a few minutes of writes lost (depending on # the configured save points). # # The Append Only File is an alternative persistence mode that provides # much better durability. For instance using the default data fsync policy # (see later in the config file) Redis can lose just one second of writes in a # dramatic event like a server power outage, or a single write if something # wrong with the Redis process itself happens, but the operating system is # still running correctly. # # AOF and RDB persistence can be enabled at the same time without problems. # If the AOF is enabled on startup Redis will load the AOF, that is the file # with the better durability guarantees. # # Please check http://redis.io/topics/persistence for more information. appendonly no # The name of the append only file (default: \"appendonly.aof\") appendfilename \"appendonly.aof\" # The fsync() call tells the Operating System to actually write data on disk # instead of waiting for more data in the output buffer. Some OS will really flush # data on disk, some other OS will just try to do it ASAP. # # Redis supports three different modes: # # no: don't fsync, just let the OS flush the data when it wants. Faster. # always: fsync after every write to the append only log. Slow, Safest. # everysec: fsync only one time every second. Compromise. # # The default is \"everysec\", as that's usually the right compromise between # speed and data safety. It's up to you to understand if you can relax this to # \"no\" that will let the operating system flush the output buffer when # it wants, for better performances (but if you can live with the idea of # some data loss consider the default persistence mode that's snapshotting), # or on the contrary, use \"always\" that's very slow but a bit safer than # everysec. # # More details please check the following article: # http://antirez.com/post/redis-persistence-demystified.html # # If unsure, use \"everysec\". # appendfsync always appendfsync everysec # appendfsync no # When the AOF fsync policy is set to always or everysec, and a background # saving process (a background save or AOF log background rewriting) is # performing a lot of I/O against the disk, in some Linux configurations # Redis may block too long on the fsync() call. Note that there is no fix for # this currently, as even performing fsync in a different thread will block # our synchronous write(2) call. # # In order to mitigate this problem it's possible to use the following option # that will prevent fsync() from being called in the main process while a # BGSAVE or BGREWRITEAOF is in progress. # # This means that while another child is saving, the durability of Redis is # the same as \"appendfsync none\". In practical terms, this means that it is # possible to lose up to 30 seconds of log in the worst scenario (with the # default Linux settings). # # If you have latency problems turn this to \"yes\". Otherwise leave it as # \"no\" that is the safest pick from the point of view of durability. no-appendfsync-on-rewrite no # Automatic rewrite of the append only file. # Redis is able to automatically rewrite the log file implicitly calling # BGREWRITEAOF when the AOF log size grows by the specified percentage. # # This is how it works: Redis remembers the size of the AOF file after the # latest rewrite (if no rewrite has happened since the restart, the size of # the AOF at startup is used). # # This base size is compared to the current size. If the current size is # bigger than the specified percentage, the rewrite is triggered. Also # you need to specify a minimal size for the AOF file to be rewritten, this # is useful to avoid rewriting the AOF file even if the percentage increase # is reached but it is still pretty small. # # Specify a percentage of zero in order to disable the automatic AOF # rewrite feature. auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb # An AOF file may be found to be truncated at the end during the Redis # startup process, when the AOF data gets loaded back into memory. # This may happen when the system where Redis is running # crashes, especially when an ext4 filesystem is mounted without the # data=ordered option (however this can't happen when Redis itself # crashes or aborts but the operating system still works correctly). # # Redis can either exit with an error when this happens, or load as much # data as possible (the default now) and start if the AOF file is found # to be truncated at the end. The following option controls this behavior. # # If aof-load-truncated is set to yes, a truncated AOF file is loaded and # the Redis server starts emitting a log to inform the user of the event. # Otherwise if the option is set to no, the server aborts with an error # and refuses to start. When the option is set to no, the user requires # to fix the AOF file using the \"redis-check-aof\" utility before to restart # the server. # # Note that if the AOF file will be found to be corrupted in the middle # the server will still exit with an error. This option only applies when # Redis will try to read more data from the AOF file but not enough bytes # will be found. aof-load-truncated yes # When rewriting the AOF file, Redis is able to use an RDB preamble in the # AOF file for faster rewrites and recoveries. When this option is turned # on the rewritten AOF file is composed of two different stanzas: # # [RDB file][AOF tail] # # When loading Redis recognizes that the AOF file starts with the \"REDIS\" # string and loads the prefixed RDB file, and continues loading the AOF # tail. # # This is currently turned off by default in order to avoid the surprise # of a format change, but will at some point be used as the default. aof-use-rdb-preamble no LUA SCRIPTING ################################ LUA SCRIPTING ############################### # Max execution time of a Lua script in milliseconds. # # If the maximum execution time is reached Redis will log that a script is # still in execution after the maximum allowed time and will start to # reply to queries with an error. # # When a long running script exceeds the maximum execution time only the # SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be # used to stop a script that did not yet called write commands. The second # is the only way to shut down the server in the case a write command was # already issued by the script but the user doesn't want to wait for the natural # termination of the script. # # Set it to 0 or a negative value for unlimited execution without warnings. lua-time-limit 5000 REDIS CLUSTER ################################ REDIS CLUSTER ############################### # # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ # WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however # in order to mark it as \"mature\" we need to wait for a non trivial percentage # of users to deploy it in production. # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ # # Normal Redis instances can't be part of a Redis Cluster; only nodes that are # started as cluster nodes can. In order to start a Redis instance as a # cluster node enable the cluster support uncommenting the following: # # cluster-enabled yes # Every cluster node has a cluster configuration file. This file is not # intended to be edited by hand. It is created and updated by Redis nodes. # Every Redis Cluster node requires a different cluster configuration file. # Make sure that instances running in the same system do not have # overlapping cluster configuration file names. # # cluster-config-file nodes-6379.conf # Cluster node timeout is the amount of milliseconds a node must be unreachable # for it to be considered in failure state. # Most other internal time limits are multiple of the node timeout. # # cluster-node-timeout 15000 # A slave of a failing master will avoid to start a failover if its data # looks too old. # # There is no simple way for a slave to actually have an exact measure of # its \"data age\", so the following two checks are performed: # # 1) If there are multiple slaves able to failover, they exchange messages # in order to try to give an advantage to the slave with the best # replication offset (more data from the master processed). # Slaves will try to get their rank by offset, and apply to the start # of the failover a delay proportional to their rank. # # 2) Every single slave computes the time of the last interaction with # its master. This can be the last ping or command received (if the master # is still in the \"connected\" state), or the time that elapsed since the # disconnection with the master (if the replication link is currently down). # If the last interaction is too old, the slave will not try to failover # at all. # # The point \"2\" can be tuned by user. Specifically a slave will not perform # the failover if, since the last interaction with the master, the time # elapsed is greater than: # # (node-timeout * slave-validity-factor) + repl-ping-slave-period # # So for example if node-timeout is 30 seconds, and the slave-validity-factor # is 10, and assuming a default repl-ping-slave-period of 10 seconds, the # slave will not try to failover if it was not able to talk with the master # for longer than 310 seconds. # # A large slave-validity-factor may allow slaves with too old data to failover # a master, while a too small value may prevent the cluster from being able to # elect a slave at all. # # For maximum availability, it is possible to set the slave-validity-factor # to a value of 0, which means, that slaves will always try to failover the # master regardless of the last time they interacted with the master. # (However they'll always try to apply a delay proportional to their # offset rank). # # Zero is the only value able to guarantee that when all the partitions heal # the cluster will always be able to continue. # # cluster-slave-validity-factor 10 # Cluster slaves are able to migrate to orphaned masters, that are masters # that are left without working slaves. This improves the cluster ability # to resist to failures as otherwise an orphaned master can't be failed over # in case of failure if it has no working slaves. # # Slaves migrate to orphaned masters only if there are still at least a # given number of other working slaves for their old master. This number # is the \"migration barrier\". A migration barrier of 1 means that a slave # will migrate only if there is at least 1 other working slave for its master # and so forth. It usually reflects the number of slaves you want for every # master in your cluster. # # Default is 1 (slaves migrate only if their masters remain with at least # one slave). To disable migration just set it to a very large value. # A value of 0 can be set but is useful only for debugging and dangerous # in production. # # cluster-migration-barrier 1 # By default Redis Cluster nodes stop accepting queries if they detect there # is at least an hash slot uncovered (no available node is serving it). # This way if the cluster is partially down (for example a range of hash slots # are no longer covered) all the cluster becomes, eventually, unavailable. # It automatically returns available as soon as all the slots are covered again. # # However sometimes you want the subset of the cluster which is working, # to continue to accept queries for the part of the key space that is still # covered. In order to do so, just set the cluster-require-full-coverage # option to no. # # cluster-require-full-coverage yes # In order to setup your cluster make sure to read the documentation # available at http://redis.io web site. CLUSTER DOCKER/NAT support ########################## CLUSTER DOCKER/NAT support ######################## # In certain deployments, Redis Cluster nodes address discovery fails, because # addresses are NAT-ted or because ports are forwarded (the typical case is # Docker and other containers). # # In order to make Redis Cluster working in such environments, a static # configuration where each node knows its public address is needed. The # following two options are used for this scope, and are: # # * cluster-announce-ip # * cluster-announce-port # * cluster-announce-bus-port # # Each instruct the node about its address, client port, and cluster message # bus port. The information is then published in the header of the bus packets # so that other nodes will be able to correctly map the address of the node # publishing the information. # # If the above options are not used, the normal Redis Cluster auto-detection # will be used instead. # # Note that when remapped, the bus port may not be at the fixed offset of # clients port + 10000, so you can specify any port and bus-port depending # on how they get remapped. If the bus-port is not set, a fixed offset of # 10000 will be used as usually. # # Example: # # cluster-announce-ip 10.1.1.5 # cluster-announce-port 6379 # cluster-announce-bus-port 6380 SLOW LOG ################################## SLOW LOG ################################### # The Redis Slow Log is a system to log queries that exceeded a specified # execution time. The execution time does not include the I/O operations # like talking with the client, sending the reply and so forth, # but just the time needed to actually execute the command (this is the only # stage of command execution where the thread is blocked and can not serve # other requests in the meantime). # # You can configure the slow log with two parameters: one tells Redis # what is the execution time, in microseconds, to exceed in order for the # command to get logged, and the other parameter is the length of the # slow log. When a new command is logged the oldest one is removed from the # queue of logged commands. # The following time is expressed in microseconds, so 1000000 is equivalent # to one second. Note that a negative number disables the slow log, while # a value of zero forces the logging of every command. slowlog-log-slower-than 10000 # There is no limit to this length. Just be aware that it will consume memory. # You can reclaim memory used by the slow log with SLOWLOG RESET. slowlog-max-len 128 LATENCY MONITOR ################################ LATENCY MONITOR ############################## # The Redis latency monitoring subsystem samples different operations # at runtime in order to collect data related to possible sources of # latency of a Redis instance. # # Via the LATENCY command this information is available to the user that can # print graphs and obtain reports. # # The system only logs operations that were performed in a time equal or # greater than the amount of milliseconds specified via the # latency-monitor-threshold configuration directive. When its value is set # to zero, the latency monitor is turned off. # # By default latency monitoring is disabled since it is mostly not needed # if you don't have latency issues, and collecting data has a performance # impact, that while very small, can be measured under big load. Latency # monitoring can easily be enabled at runtime using the command # \"CONFIG SET latency-monitor-threshold \" if needed. latency-monitor-threshold 0 EVENT NOTIFICATION ############################# EVENT NOTIFICATION ############################## # Redis can notify Pub/Sub clients about events happening in the key space. # This feature is documented at http://redis.io/topics/notifications # # For instance if keyspace events notification is enabled, and a client # performs a DEL operation on key \"foo\" stored in the Database 0, two # messages will be published via Pub/Sub: # # PUBLISH __keyspace@0__:foo del # PUBLISH __keyevent@0__:del foo # # It is possible to select the events that Redis will notify among a set # of classes. Every class is identified by a single character: # # K Keyspace events, published with __keyspace@__ prefix. # E Keyevent events, published with __keyevent@__ prefix. # g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ... # $ String commands # l List commands # s Set commands # h Hash commands # z Sorted set commands # x Expired events (events generated every time a key expires) # e Evicted events (events generated when a key is evicted for maxmemory) # A Alias for g$lshzxe, so that the \"AKE\" string means all the events. # # The \"notify-keyspace-events\" takes as argument a string that is composed # of zero or multiple characters. The empty string means that notifications # are disabled. # # Example: to enable list and generic events, from the point of view of the # event name, use: # # notify-keyspace-events Elg # # Example 2: to get the stream of the expired keys subscribing to channel # name __keyevent@0__:expired use: # # notify-keyspace-events Ex # # By default all notifications are disabled because most users don't need # this feature and the feature has some overhead. Note that if you don't # specify at least one of K or E, no events will be delivered. notify-keyspace-events \"\" ADVANCED CONFIG ############################### ADVANCED CONFIG ############################### # Hashes are encoded using a memory efficient data structure when they have a # small number of entries, and the biggest entry does not exceed a given # threshold. These thresholds can be configured using the following directives. hash-max-ziplist-entries 512 hash-max-ziplist-value 64 # Lists are also encoded in a special way to save a lot of space. # The number of entries allowed per internal list node can be specified # as a fixed maximum size or a maximum number of elements. # For a fixed maximum size, use -5 through -1, meaning: # -5: max size: 64 Kb node->node->...->node->[tail] # [head], [tail] will always be uncompressed; inner nodes will compress. # 2: [head]->[next]->node->node->...->node->[prev]->[tail] # 2 here means: don't compress head or head->next or tail->prev or tail, # but compress all nodes between them. # 3: [head]->[next]->[next]->node->node->...->node->[prev]->[prev]->[tail] # etc. list-compress-depth 0 # Sets have a special encoding in just one case: when a set is composed # of just strings that happen to be integers in radix 10 in the range # of 64 bit signed integers. # The following configuration setting sets the limit in the size of the # set in order to use this special memory saving encoding. set-max-intset-entries 512 # Similarly to hashes and lists, sorted sets are also specially encoded in # order to save a lot of space. This encoding is only used when the length and # elements of a sorted set are below the following limits: zset-max-ziplist-entries 128 zset-max-ziplist-value 64 # HyperLogLog sparse representation bytes limit. The limit includes the # 16 bytes header. When an HyperLogLog using the sparse representation crosses # this limit, it is converted into the dense representation. # # A value greater than 16000 is totally useless, since at that point the # dense representation is more memory efficient. # # The suggested value is ~ 3000 in order to have the benefits of # the space efficient encoding without slowing down too much PFADD, # which is O(N) with the sparse encoding. The value can be raised to # ~ 10000 when CPU is not a concern, but space is, and the data set is # composed of many HyperLogLogs with cardinality in the 0 - 15000 range. hll-sparse-max-bytes 3000 # Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in # order to help rehashing the main Redis hash table (the one mapping top-level # keys to values). The hash table implementation Redis uses (see dict.c) # performs a lazy rehashing: the more operation you run into a hash table # that is rehashing, the more rehashing \"steps\" are performed, so if the # server is idle the rehashing is never complete and some more memory is used # by the hash table. # # The default is to use this millisecond 10 times every second in order to # actively rehash the main dictionaries, freeing memory when possible. # # If unsure: # use \"activerehashing no\" if you have hard latency requirements and it is # not a good thing in your environment that Redis can reply from time to time # to queries with 2 milliseconds delay. # # use \"activerehashing yes\" if you don't have such hard requirements but # want to free memory asap when possible. activerehashing yes # The client output buffer limits can be used to force disconnection of clients # that are not reading data from the server fast enough for some reason (a # common reason is that a Pub/Sub client can't consume messages as fast as the # publisher can produce them). # # The limit can be set differently for the three different classes of clients: # # normal -> normal clients including MONITOR clients # slave -> slave clients # pubsub -> clients subscribed to at least one pubsub channel or pattern # # The syntax of every client-output-buffer-limit directive is the following: # # client-output-buffer-limit # # A client is immediately disconnected once the hard limit is reached, or if # the soft limit is reached and remains reached for the specified number of # seconds (continuously). # So for instance if the hard limit is 32 megabytes and the soft limit is # 16 megabytes / 10 seconds, the client will get disconnected immediately # if the size of the output buffers reach 32 megabytes, but will also get # disconnected if the client reaches 16 megabytes and continuously overcomes # the limit for 10 seconds. # # By default normal clients are not limited because they don't receive data # without asking (in a push way), but just after a request, so only # asynchronous clients may create a scenario where data is requested faster # than it can read. # # Instead there is a default limit for pubsub and slave clients, since # subscribers and slaves receive data in a push fashion. # # Both the hard or the soft limit can be disabled by setting them to zero. client-output-buffer-limit normal 0 0 0 client-output-buffer-limit slave 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 # Client query buffers accumulate new commands. They are limited to a fixed # amount by default in order to avoid that a protocol desynchronization (for # instance due to a bug in the client) will lead to unbound memory usage in # the query buffer. However you can configure it here if you have very special # needs, such us huge multi/exec requests or alike. # # client-query-buffer-limit 1gb # In the Redis protocol, bulk requests, that are, elements representing single # strings, are normally limited ot 512 mb. However you can change this limit # here. # # proto-max-bulk-len 512mb # Redis calls an internal function to perform many background tasks, like # closing connections of clients in timeout, purging expired keys that are # never requested, and so forth. # # Not all tasks are performed with the same frequency, but Redis checks for # tasks to perform according to the specified \"hz\" value. # # By default \"hz\" is set to 10. Raising the value will use more CPU when # Redis is idle, but at the same time will make Redis more responsive when # there are many keys expiring at the same time, and timeouts may be # handled with more precision. # # The range is between 1 and 500, however a value over 100 is usually not # a good idea. Most users should use the default of 10 and raise this up to # 100 only in environments where very low latency is required. hz 10 # When a child rewrites the AOF file, if the following option is enabled # the file will be fsync-ed every 32 MB of data generated. This is useful # in order to commit the file to the disk more incrementally and avoid # big latency spikes. aof-rewrite-incremental-fsync yes # Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good # idea to start with the default settings and only change them after investigating # how to improve the performances and how the keys LFU change over time, which # is possible to inspect via the OBJECT FREQ command. # # There are two tunable parameters in the Redis LFU implementation: the # counter logarithm factor and the counter decay time. It is important to # understand what the two parameters mean before changing them. # # The LFU counter is just 8 bits per key, it's maximum value is 255, so Redis # uses a probabilistic increment with logarithmic behavior. Given the value # of the old counter, when a key is accessed, the counter is incremented in # this way: # # 1. A random number R between 0 and 1 is extracted. # 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1). # 3. The counter is incremented only if R ACTIVE DEFRAGMENTATION ########################### ACTIVE DEFRAGMENTATION ####################### # # WARNING THIS FEATURE IS EXPERIMENTAL. However it was stress tested # even in production and manually tested by multiple engineers for some # time. # # What is active defragmentation? # ------------------------------- # # Active (online) defragmentation allows a Redis server to compact the # spaces left between small allocations and deallocations of data in memory, # thus allowing to reclaim back memory. # # Fragmentation is a natural process that happens with every allocator (but # less so with Jemalloc, fortunately) and certain workloads. Normally a server # restart is needed in order to lower the fragmentation, or at least to flush # away all the data and create it again. However thanks to this feature # implemented by Oran Agra for Redis 4.0 this process can happen at runtime # in an \"hot\" way, while the server is running. # # Basically when the fragmentation is over a certain level (see the # configuration options below) Redis will start to create new copies of the # values in contiguous memory regions by exploiting certain specific Jemalloc # features (in order to understand if an allocation is causing fragmentation # and to allocate it in a better place), and at the same time, will release the # old copies of the data. This process, repeated incrementally for all the keys # will cause the fragmentation to drop back to normal values. # # Important things to understand: # # 1. This feature is disabled by default, and only works if you compiled Redis # to use the copy of Jemalloc we ship with the source code of Redis. # This is the default with Linux builds. # # 2. You never need to enable this feature if you don't have fragmentation # issues. # # 3. Once you experience fragmentation, you can enable this feature when # needed with the command \"CONFIG SET activedefrag yes\". # # The configuration parameters are able to fine tune the behavior of the # defragmentation process. If you are not sure about what they mean it is # a good idea to leave the defaults untouched. # Enabled active defragmentation # activedefrag yes # Minimum amount of fragmentation waste to start active defrag # active-defrag-ignore-bytes 100mb # Minimum percentage of fragmentation to start active defrag # active-defrag-threshold-lower 10 # Maximum percentage of fragmentation at which we use maximum effort # active-defrag-threshold-upper 100 # Minimal effort for defrag in CPU percentage # active-defrag-cycle-min 25 # Maximal effort for defrag in CPU percentage # active-defrag-cycle-max 75 Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-12-29 14:31:46 "},"memcached/memcached.html":{"url":"memcached/memcached.html","title":"Memcached的使用","keywords":"","body":"1. Memcached简介 Memcached是一个开源的，高性能，分布式内存对象缓存系统。 Memcached是一种基于内存的key-value存储，用来存储小块的任意数据（字符串、对象）。这些数据可以是数据库调用、API调用或者是页面渲染的结果。 一般的使用目的是，通过缓存数据库查询结果，减少数据库访问次数，以提高动态Web应用的速度、提高可扩展性。 1.1. 特征 memcached作为高速运行的分布式缓存服务器，具有以下的特点。 协议简单 基于libevent的事件处理 内置内存存储方式 memcached不互相通信的分布式 2. 安装与运行 2.1. 自动安装 # For Redhat/Fedora yum install -y memcached # For Debian or Ubuntu apt-get install memcached 2.2. 源码安装 安装指定版本的Memcached可以从 https://github.com/memcached/memcached/wiki/ReleaseNotes 地址下载。 # Memcached depends on libevent yum install libevent-devel # install wget https://memcached.org/latest [you might need to rename the file] tar -zxf memcached-1.x.x.tar.gz cd memcached-1.x.x ./configure --prefix=/usr/local/memcached make && make test && sudo make install 问题 如遇以下报错，可再执行make install。 Signal handled: Interrupt. ok 51 - shutdown ok 52 - stop_server /bin/sh:行3: prove: 未找到命令 make: *** [test] Error 127 2.3. 验证 确认是否安装成功，可执行以下命令 /usr/local/memcached/bin/memcached -h 2.4. 运行 2.4.1. 前台运行 /usr/local/memcached/bin/memcached -p 11211 -m 64m -vv 2.4.2. 后台运行 /usr/local/memcached/bin/memcached -p 11211 -m 64m -d -c 102400 -t 8 -P /tmp/memcached.pid 2.5. 连接 $ telnet 127.0.0.1 11211 Trying 127.0.0.1... Connected to 127.0.0.1. Escape character is '^]'. set foo 0 0 3 保存命令 bar 数据 STORED 结果 get foo 取得命令 VALUE foo 0 3 数据 bar 数据 END 结束行 quit 退出 3. Memcached运行参数 # /usr/local/memcached/bin/memcached -h memcached 1.5.12 -p, --port= TCP port to listen on (default: 11211) -U, --udp-port= UDP port to listen on (default: 0, off) -s, --unix-socket= UNIX socket to listen on (disables network support) -A, --enable-shutdown enable ascii \"shutdown\" command -a, --unix-mask= access mask for UNIX socket, in octal (default: 0700) -l, --listen= interface to listen on (default: INADDR_ANY) -d, --daemon run as a daemon -r, --enable-coredumps maximize core file limit -u, --user= assume identity of (only when run as root) -m, --memory-limit= item memory in megabytes (default: 64 MB) -M, --disable-evictions return error on memory exhausted instead of evicting -c, --conn-limit= max simultaneous connections (default: 1024) -k, --lock-memory lock down all paged memory -v, --verbose verbose (print errors/warnings while in event loop) -vv very verbose (also print client commands/responses) -vvv extremely verbose (internal state transitions) -h, --help print this help and exit -i, --license print memcached and libevent license -V, --version print version and exit -P, --pidfile= save PID in , only used with -d option -f, --slab-growth-factor= chunk size growth factor (default: 1.25) -n, --slab-min-size= min space used for key+value+flags (default: 48) -L, --enable-largepages try to use large memory pages (if available) -D Use as the delimiter between key prefixes and IDs. This is used for per-prefix stats reporting. The default is \":\" (colon). If this option is specified, stats collection is turned on automatically; if not, then it may be turned on by sending the \"stats detail on\" command to the server. -t, --threads= number of threads to use (default: 4) -R, --max-reqs-per-event maximum number of requests per event, limits the requests processed per connection to prevent starvation (default: 20) -C, --disable-cas disable use of CAS -b, --listen-backlog= set the backlog queue limit (default: 1024) -B, --protocol= protocol - one of ascii, binary, or auto (default) -I, --max-item-size= adjusts max item size (default: 1mb, min: 1k, max: 128m) -F, --disable-flush-all disable flush_all command -X, --disable-dumping disable stats cachedump and lru_crawler metadump -o, --extended comma separated list of extended options most options have a 'no_' prefix to disable - maxconns_fast: immediately close new connections after limit - hashpower: an integer multiplier for how large the hash table should be. normally grows at runtime. set based on \"STAT hash_power_level\" - tail_repair_time: time in seconds for how long to wait before forcefully killing LRU tail item. disabled by default; very dangerous option. - hash_algorithm: the hash table algorithm default is murmur3 hash. options: jenkins, murmur3 - lru_crawler: enable LRU Crawler background thread - lru_crawler_sleep: microseconds to sleep between items default is 100. - lru_crawler_tocrawl: max items to crawl per slab per run default is 0 (unlimited) - lru_maintainer: enable new LRU system + background thread - hot_lru_pct: pct of slab memory to reserve for hot lru. (requires lru_maintainer) - warm_lru_pct: pct of slab memory to reserve for warm lru. (requires lru_maintainer) - hot_max_factor: items idle > cold lru age * drop from hot lru. - warm_max_factor: items idle > cold lru age * this drop from warm. - temporary_ttl: TTL's below get separate LRU, can't be evicted. (requires lru_maintainer) - idle_timeout: timeout for idle connections - slab_chunk_max: (EXPERIMENTAL) maximum slab size. use extreme care. - watcher_logbuf_size: size in kilobytes of per-watcher write buffer. - worker_logbuf_size: size in kilobytes of per-worker-thread buffer read by background thread, then written to watchers. - track_sizes: enable dynamic reports for 'stats sizes' command. - no_inline_ascii_resp: save up to 24 bytes per item. small perf hit in ASCII, no perf difference in binary protocol. speeds up all sets. - no_hashexpand: disables hash table expansion (dangerous) - modern: enables options which will be default in future. currently: nothing - no_modern: uses defaults of previous major version (1.4.x) 常用参数： -d是启动一个守护进程； -m是分配给Memcache使用的内存数量，单位是MB； -u是运行Memcache的用户； -l是监听的服务器IP地址，可以有多个地址； -p是设置Memcache监听的端口，，最好是1024以上的端口； -c是最大运行的并发连接数，默认是1024； -t是线程数，默认为4； -P是设置保存Memcache的pid文件。 4. Memcached 命令 4.1. 存储命令 4.1.1. 常用命令 命令 说明 set 新增或更新 add 新增 replace 替换 append 在后面追加 prepend 在前面追加 cas 检查并设置 以上几个命令语法格式相似，以set为例： set key flags exptime bytes [noreply] value 参数说明如下： key：键值 key-value 结构中的 key，用于查找缓存值。 flags：可以包括键值对的整型参数，客户机使用它存储关于键值对的额外信息 。 exptime：在缓存中保存键值对的时间长度（以秒为单位，0 表示永远） bytes：在缓存中存储的字节数 noreply（可选）： 该参数告知服务器不需要返回数据 value：存储的值（始终位于第二行）（可直接理解为key-value结构中的value） 实例： key → runoob flag → 0 exptime → 900 (以秒为单位) bytes → 9 (数据存储的字节数) value → memcached set runoob 0 900 9 memcached STORED get runoob VALUE runoob 0 9 memcached END 输出： 如果数据设置成功，则输出： STORED 输出信息说明： STORED：保存成功后输出。 ERROR：在保存失败后输出。 4.1.2. cas命令 Memcached CAS（Check-And-Set 或 Compare-And-Swap） 命令用于执行一个\"检查并设置\"的操作。 它仅在当前客户端最后一次取值后，该key 对应的值没有被其他客户端修改的情况下， 才能够将值写入。 检查是通过cas_token参数进行的， 这个参数是Memcach指定给已经存在的元素的一个唯一的64位值。 语法： 比以上命令多了一个unique_cas_token cas key flags exptime bytes unique_cas_token [noreply] value 参数说明如下： key：键值 key-value 结构中的 key，用于查找缓存值。 flags：可以包括键值对的整型参数，客户机使用它存储关于键值对的额外信息 。 exptime：在缓存中保存键值对的时间长度（以秒为单位，0 表示永远） bytes：在缓存中存储的字节数 unique_cas_token通过 gets 命令获取的一个唯一的64位值。 noreply（可选）： 该参数告知服务器不需要返回数据 value：存储的值（始终位于第二行）（可直接理解为key-value结构中的value） unique_cas_token通过gets命令获取。 4.2. 查找命令 命令 说明 get 获取一个或多个key gets 获取一个或多个cas token delete 删除已存在的key incr/decr 对已存在的 key(键) 的数字值进行自增或自减操作 4.3. 统计命令 命令 说明 stats 用于返回统计信息例如 PID(进程号)、版本号、连接数等。 stats items 用于显示各个 slab 中 item 的数目和存储时长(最后一次访问距离现在的秒数)。 stats slabs 用于显示各个slab的信息，包括chunk的大小、数目、使用情况等。 stats sizes 用于显示所有item的大小和个数。 flush_all 用于清理缓存中的所有 key=>value(键=>值) 对。 参考文章： https://github.com/memcached/memcached/wiki/Overview https://github.com/memcached/memcached/wiki/Install http://www.runoob.com/memcached/memcached-tutorial.html Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2019-02-13 18:23:29 "},"mysql/mysql-commands.html":{"url":"mysql/mysql-commands.html","title":"Mysql常用命令","keywords":"","body":"1. 系统管理 1.1. 连接mysql 格式： mysql -h主机地址 -u用户名 －p用户密码 #连接本地 mysql -h -u用户名 －p用户密码 #连接远程 mysql -h -u用户名 －p用户密码 #退出连接 exit 1.2. 备份数据库 1.导出整个数据库 导出文件默认是存在mysql\\bin目录下 #1）备份单个数据库 mysqldump -u 用户名 -p 数据库名 > 导出的文件名 mysqldump -u user_name -p123456 database_name > outfile_name.sql #2）同时备份多个数据库，例如database1_name，database2_name mysqldump -u user_name -p123456 --databases database1_name database2_name > outfile_name.sql #3）备份全部数据库 mysqldump -u user_name -p123456 --all-databases > outfile_name.sql 2.导出一个表 mysqldump -u 用户名 -p 数据库名 表名> 导出的文件名 mysqldump -u user_name -p database_name table_name > outfile_name.sql 3.导出一个数据库结构 mysqldump -u user_name -p -d –add-drop-table database_name > outfile_name.sql -d 没有数据 –add-drop-table 在每个create语句之前增加一个drop table 4.带语言参数导出 mysqldump -uroot -p –default-character-set=latin1 –set-charset=gbk –skip-opt database_name > outfile_name.sql 5、导入数据库 #1）多个个数据库 mysql -u root –p 1.3. 用户管理 #创建用户 create user '用户名'@'IP地址' identified by '密码'; #删除用户 drop user '用户名'@'IP地址'; delete from user where user='用户名' and host='localhost'; #修改用户 rename user '用户名'@'IP地址'; to '新用户名'@'IP地址';; #修改密码 set password for '用户名'@'IP地址' = Password('新密码') mysqladmin -u用户名 -p旧密码 password 新密码 1.4. 权限管理 1.4.1. grant 1、grant 权限 on 数据库对象 to 用户 数据库对象的格式为.。.*：表示授权数据库对象该数据库的所有表；*.*：表示授权数据库对象为所有数据库的所有表。 grant all privileges on . to @'' identified by '';如果为'%'表示不限制IP。 2、撤销权限： revoke all on . from @; 1.4.2. 普通数据库用户 查询、插入、更新、删除 数据库中所有表数据的权利 grant select, insert, update, delete on testdb.* to @''; 1.4.3. DBA 用户 #1、授权 grant all privileges on . to @'' identified by ''; #2、刷新系统权限 flush privileges; 1.4.4. 查看用户权限 #查看当前用户（自己）权限 show grants; #查看指定MySQL 用户权限 show grants for @; #查看user和host select user,host from mysql.user order by user; 1.4.5. 权限列表 权限 说明 网站使用账户是否给予 Select 可对其下所有表进行查询 建议给予 Insert 可对其下所有表进行插入 建议给予 Update 可对其下所有表进行更新 建议给予 Delete 可对其下所有表进行删除 建议给予 Create 可在此数据库下创建表或索引 建议给予 Drop 可删除此数据库及数据库下所有表 不建议给予 Grant 赋予权限选项 不建议给予 References 未来MySQL特性的占位符 不建议给予 Index 可对其下所有表进行索引 建议给予 Alter 可对其下所有表进行更改 建议给予 Create_tmp_table 创建临时表 不建议给予 Lock_tables 可对其下所有表进行锁定 不建议给予 Create_view 可在此数据下创建视图 建议给予 Show_view 可在此数据下查看视图 建议给予 Create_routine 可在此数据下创建存储过程 不建议给予 Alter_routine 可在此数据下更改存储过程 不建议给予 Execute 可在此数据下执行存储过程 不建议给予 Event 可在此数据下创建事件调度器 不建议给予 Trigger 可在此数据下创建触发器 不建议给予 1.4.6.查看主从关系 #登录主机 show slave hosts; #登录从机 show slave status; 2. 数据库操作 #创建数据库 create database #显示数据库 show databases #删除数据 drop database 3. 数据表操作 3.1. 创建表 create table 表名( 列名 类型 是否可以为空， 列名 类型 是否可以为空 )ENGINE=InnoDB DEFAULT CHARSET=utf8 默认值，创建列时可以指定默认值，当插入数据时如果未主动设置，则自动添加默认值 自增，如果为某列设置自增列，插入数据时无需设置此列，默认将自增（表中只能有一个自增列）注意：1、对于自增列，必须是索引（含主键）2、对于自增可以设置步长和起始值 主键，一种特殊的唯一索引，不允许有空值，如果主键使用单个列，则它的值必须唯一，如果是多列，则其组合必须唯一。 3.2. 查看表 show tables; # 查看数据库全部表 select * from 表名; # 查看表所有内容 3.3. 删除表 drop table 表名 3.4. 清空表内容 delete from 表名 truncate table 表名 3.5. 查看表结构 desc 表名 3.6. 修改表 列操作 #添加列 alter table 表名 add 列名 类型 #删除列 alter table 表名 drop column 列名 #修改列 alter table 表名 modify column 列名 类型; -- 类型 alter table 表名 change 原列名 新列名 类型; -- 列名，类型 主键操作 #添加主键 alter table 表名 add primary key(列名); #删除主键 alter table 表名 drop primary key; alter table 表名 modify 列名 int, drop primary key; #修改主键：先删除后添加 alter table 表名 drop primary key; alter table 表名 add primary key(列名); #添加外键 alter table 从表 add constraint 外键名称（形如：FK从表主表） foreign key 从表(外键字段) references 主表(主键字段); #删除外键 alter table 表名 drop foreign key 外键名称 默认值操作 #修改默认值： ALTER TABLE testalter_tbl ALTER i SET DEFAULT 1000; #删除默认值： ALTER TABLE testalter_tbl ALTER i DROP DEFAULT; 调整表结构字段顺序 alter table modify varchar(10) after ; alter table modify id int(10) unsigned auto_increment first; 4. 表内容操作 4.1. 增 insert into 表 (列名,列名...) values (值,值,...) insert into 表 (列名,列名...) values (值,值,...),(值,值,值...) insert into 表 (列名,列名...) select (列名,列名...) from 表 例： insert into tab1(name,email) values('zhangyanlin','zhangyanlin8851@163.com') 4.2. 删 delete from 表 # 删除表里全部数据 delete from 表 where id＝1 and name＝'zhangyanlin' # 删除ID =1 和name='zhangyanlin' 那一行数据 4.3. 改 update 表 set name ＝ 'zhangyanlin' where id>1 4.4. 查 select * from 表 select * from 表 where id > 1 select nid,name,gender as gg from 表 where id > 1 4.5. 条件判断 4.5.1. where select * from where id >1 and name!='huwh' and num =12; select * from where id between 5 and 6; select * from where id in (11,22,33); select * from where id not in (11,22,33); select * from where id in (select nid from ) 4.5.2. 通配符like select * from where name like 'hu%'; #hu开头 select * from where name like 'hu_' #hu开头后接一个字符 4.5.3. 限制limit select * from limit 5; #前5行 select * from limit 4,5 #从第四行开始的5行 select * from limit 5 offset 4;#从第四行开始的5行 4.5.4. 排序asc，desc select * from order by 列 asc; #跟据“列”从小到大排序（不指定默认为从小到大排序） select * from order by 列 desc; #根据“列”从大到小排序 select * from order by 列1 desc,列2 asc; #根据“列1”从大到小排序，如果相同则按“列2”从小到大排序 4.5.5. 分组group by group by 必须在where之后，order by之前。 select num,from group by num; select num,nid from group by num,nid; select num from where nid > 10 group by num,nid order nid desc; select num,nid,count(*),sum(score),max(score) from group by num; select num from group by num having max(id) > 10; select num from group by num; Copyright © www.huweihuang.com 2017-2018 all right reserved，powered by GitbookUpdated at 2018-10-27 18:01:27 "}}